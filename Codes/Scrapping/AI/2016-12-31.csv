title,authors,abstract,submitted_date,pdf_link
p-DLA: A Predictive System Model for Onshore Oil and Gas Pipeline Dataset Classification and Monitoring - Part 1,E. N. Osegi,"With the rise in militant activity and rogue behaviour in oil and gas regions around the world, oil pipeline disturbances is on the increase leading to huge losses to multinational operators and the countries where such facilities exist. However, this situation can be averted if adequate predictive monitoring schemes are put in place. We propose in the first part of this paper, an artificial intelligence predictive monitoring system capable of predictive classification and pattern recognition of pipeline datasets. The predictive system is based on a highly sparse predictive Deviant Learning Algorithm (p-DLA) designed to synthesize a sequence of memory predictive clusters for eventual monitoring, control and decision making. The DLA (p-DLA) is compared with a popular machine learning algorithm, the Long Short-Term Memory (LSTM) which is based on a temporal version of the standard feed-forward back-propagation trained artificial neural networks (ANNs). The results of simulations study show impressive results and validates the sparse memory predictive approach which favours the sub-synthesis of a highly compressed and low dimensional knowledge discovery and information prediction scheme. It also shows that the proposed new approach is competitive with a well-known and proven AI approach such as the LSTM. △ Less","30 December, 2016",https://arxiv.org/pdf/1701.00040
Counterfactual Prediction with Deep Instrumental Variables Networks,Jason Hartford;Greg Lewis;Kevin Leyton-Brown;Matt Taddy,"We are in the middle of a remarkable rise in the use and capability of artificial intelligence. Much of this growth has been fueled by the success of deep learning architectures: models that map from observables to outputs via multiple layers of latent representations. These deep learning algorithms are effective tools for unstructured prediction, and they can be combined in AI systems to solve complex automated reasoning problems. This paper provides a recipe for combining ML algorithms to solve for causal effects in the presence of instrumental variables -- sources of treatment randomization that are conditionally independent from the response. We show that a flexible IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework imposes some specific structure on the stochastic gradient descent routine used for training, but it is general enough that we can take advantage of off-the-shelf ML capabilities and avoid extensive algorithm customization. We outline how to obtain out-of-sample causal validation in order to avoid over-fit. We also introduce schemes for both Bayesian and frequentist inference: the former via a novel adaptation of dropout training, and the latter via a data splitting routine. △ Less","30 December, 2016",https://arxiv.org/pdf/1612.09596
Accelerated Convolutions for Efficient Multi-Scale Time to Contact Computation in Julia,Alexander Amini;Berthold Horn;Alan Edelman,"Convolutions have long been regarded as fundamental to applied mathematics, physics and engineering. Their mathematical elegance allows for common tasks such as numerical differentiation to be computed efficiently on large data sets. Efficient computation of convolutions is critical to artificial intelligence in real-time applications, like machine vision, where convolutions must be continuously and efficiently computed on tens to hundreds of kilobytes per second. In this paper, we explore how convolutions are used in fundamental machine vision applications. We present an accelerated n-dimensional convolution package in the high performance computing language, Julia, and demonstrate its efficacy in solving the time to contact problem for machine vision. Results are measured against synthetically generated videos and quantitatively assessed according to their mean squared error from the ground truth. We achieve over an order of magnitude decrease in compute time and allocated memory for comparable machine vision applications. All code is packaged and integrated into the official Julia Package Manager to be used in various other scenarios. △ Less","28 December, 2016",https://arxiv.org/pdf/1612.08825
Solving Set Optimization Problems by Cardinality Optimization via Weak Constraints with an Application to Argumentation,Wolfgang Faber;Mauro Vallati;Federico Cerutti;Massimiliano Giacomin,"Optimization - minimization or maximization - in the lattice of subsets is a frequent operation in Artificial Intelligence tasks. Examples are subset-minimal model-based diagnosis, nonmonotonic reasoning by means of circumscription, or preferred extensions in abstract argumentation. Finding the optimum among many admissible solutions is often harder than finding admissible solutions with respect to both computational complexity and methodology. This paper addresses the former issue by means of an effective method for finding subset-optimal solutions. It is based on the relationship between cardinality-optimal and subset-optimal solutions, and the fact that many logic-based declarative programming systems provide constructs for finding cardinality-optimal solutions, for example maximum satisfiability (MaxSAT) or weak constraints in Answer Set Programming (ASP). Clearly each cardinality-optimal solution is also a subset-optimal one, and if the language also allows for the addition of particular restricting constructs (both MaxSAT and ASP do) then all subset-optimal solutions can be found by an iterative computation of cardinality-optimal solutions. As a showcase, the computation of preferred extensions of abstract argumentation frameworks using the proposed method is studied. △ Less","22 December, 2016",https://arxiv.org/pdf/1612.07589
"The SP Theory of Intelligence as a Foundation for the Development of a General, Human-Level Thinking Machine",J Gerard Wolff,"This paper summarises how the ""SP theory of intelligence"" and its realisation in the ""SP computer model"" simplifies and integrates concepts across artificial intelligence and related areas, and thus provides a promising foundation for the development of a general, human-level thinking machine, in accordance with the main goal of research in artificial general intelligence. The key to this simplification and integration is the powerful concept of ""multiple alignment"", borrowed and adapted from bioinformatics. This concept has the potential to be the ""double helix"" of intelligence, with as much significance for human-level intelligence as has DNA for biological sciences. Strengths of the SP system include: versatility in the representation of diverse kinds of knowledge; versatility in aspects of intelligence (including: strengths in unsupervised learning; the processing of natural language; pattern recognition at multiple levels of abstraction that is robust in the face of errors in data; several kinds of reasoning (including: one-step `deductive' reasoning; chains of reasoning; abductive reasoning; reasoning with probabilistic networks and trees; reasoning with 'rules'; nonmonotonic reasoning and reasoning with default values; Bayesian reasoning with 'explaining away'; and more); planning; problem solving; and more); seamless integration of diverse kinds of knowledge and diverse aspects of intelligence in any combination; and potential for application in several areas (including: helping to solve nine problems with big data; helping to develop human-level intelligence in autonomous robots; serving as a database with intelligence and with versatility in the representation and integration of several forms of knowledge; serving as a vehicle for medical knowledge and as an aid to medical diagnosis; and several more). △ Less","22 December, 2016",https://arxiv.org/pdf/1612.07555
CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning,Justin Johnson;Bharath Hariharan;Laurens van der Maaten;Li Fei-Fei;C. Lawrence Zitnick;Ross Girshick,"When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations. △ Less","20 December, 2016",https://arxiv.org/pdf/1612.06890
Machine Reading with Background Knowledge,Ndapandula Nakashole;Tom M. Mitchell,"Intelligent systems capable of automatically understanding natural language text are important for many artificial intelligence applications including mobile phone voice assistants, computer vision, and robotics. Understanding language often constitutes fitting new information into a previously acquired view of the world. However, many machine reading systems rely on the text alone to infer its meaning. In this paper, we pursue a different approach; machine reading methods that make use of background knowledge to facilitate language understanding. To this end, we have developed two methods: The first method addresses prepositional phrase attachment ambiguity. It uses background knowledge within a semi-supervised machine learning algorithm that learns from both labeled and unlabeled data. This approach yields state-of-the-art results on two datasets against strong baselines; The second method extracts relationships from compound nouns. Our knowledge-aware method for compound noun analysis accurately extracts relationships and significantly outperforms a baseline that does not make use of background knowledge. △ Less","15 December, 2016",https://arxiv.org/pdf/1612.05348
A Survey of Inductive Biases for Factorial Representation-Learning,Karl Ridgeway,"With the resurgence of interest in neural networks, representation learning has re-emerged as a central focus in artificial intelligence. Representation learning refers to the discovery of useful encodings of data that make domain-relevant information explicit. Factorial representations identify underlying independent causal factors of variation in data. A factorial representation is compact and faithful, makes the causal factors explicit, and facilitates human interpretation of data. Factorial representations support a variety of applications, including the generation of novel examples, indexing and search, novelty detection, and transfer learning. This article surveys various constraints that encourage a learning algorithm to discover factorial representations. I dichotomize the constraints in terms of unsupervised and supervised inductive bias. Unsupervised inductive biases exploit assumptions about the environment, such as the statistical distribution of factor coefficients, assumptions about the perturbations a factor should be invariant to (e.g. a representation of an object can be invariant to rotation, translation or scaling), and assumptions about how factors are combined to synthesize an observation. Supervised inductive biases are constraints on the representations based on additional information connected to observations. Supervisory labels come in variety of types, which vary in how strongly they constrain the representation, how many factors are labeled, how many observations are labeled, and whether or not we know the associations between the constraints and the factors they are related to. This survey brings together a wide variety of models that all touch on the problem of learning factorial representations and lays out a framework for comparing these models based on the strengths of the underlying supervised and unsupervised inductive biases. △ Less","15 December, 2016",https://arxiv.org/pdf/1612.05299
Interpretable Semantic Textual Similarity: Finding and explaining differences between sentences,I. Lopez-Gazpio;M. Maritxalar;A. Gonzalez-Agirre;G. Rigau;L. Uria;E. Agirre,"User acceptance of artificial intelligence agents might depend on their ability to explain their reasoning, which requires adding an interpretability layer that fa- cilitates users to understand their behavior. This paper focuses on adding an in- terpretable layer on top of Semantic Textual Similarity (STS), which measures the degree of semantic equivalence between two sentences. The interpretability layer is formalized as the alignment between pairs of segments across the two sentences, where the relation between the segments is labeled with a relation type and a similarity score. We present a publicly available dataset of sentence pairs annotated following the formalization. We then develop a system trained on this dataset which, given a sentence pair, explains what is similar and different, in the form of graded and typed segment alignments. When evaluated on the dataset, the system performs better than an informed baseline, showing that the dataset and task are well-defined and feasible. Most importantly, two user studies show how the system output can be used to automatically produce explanations in natural language. Users performed better when having access to the explanations, pro- viding preliminary evidence that our dataset and method to automatically produce explanations is useful in real applications. △ Less","14 December, 2016",https://arxiv.org/pdf/1612.04868
DeepMind Lab,Charles Beattie;Joel Z. Leibo;Denis Teplyashin;Tom Ward;Marcus Wainwright;Heinrich Küttler;Andrew Lefrancq;Simon Green;Víctor Valdés;Amir Sadik;Julian Schrittwieser;Keith Anderson;Sarah York;Max Cant;Adam Cain;Adrian Bolton;Stephen Gaffney;Helen King;Demis Hassabis;Shane Legg;Stig Petersen,"DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community. △ Less","13 December, 2016",https://arxiv.org/pdf/1612.03801
Evaluating the Performance of ANN Prediction System at Shanghai Stock Market in the Period 21-Sep-2016 to 11-Oct-2016,Barack Wamkaya Wanjawa,"This research evaluates the performance of an Artificial Neural Network based prediction system that was employed on the Shanghai Stock Exchange for the period 21-Sep-2016 to 11-Oct-2016. It is a follow-up to a previous paper in which the prices were predicted and published before September 21. Stock market price prediction remains an important quest for investors and researchers. This research used an Artificial Intelligence system, being an Artificial Neural Network that is feedforward multi-layer perceptron with error backpropagation for prediction, unlike other methods such as technical, fundamental or time series analysis. While these alternative methods tend to guide on trends and not the exact likely prices, neural networks on the other hand have the ability to predict the real value prices, as was done on this research. Nonetheless, determination of suitable network parameters remains a challenge in neural network design, with this research settling on a configuration of 5:21:21:1 with 80% training data or 4-year of training data as a good enough model for stock prediction, as already determined in a previous research by the author. The comparative results indicate that neural network can predict typical stock market prices with mean absolute percentage errors that are as low as 1.95% over the ten prediction instances that was studied in this research. △ Less","5 December, 2016",https://arxiv.org/pdf/1612.02666
"AI Researchers, Video Games Are Your Friends!",Julian Togelius,"If you are an artificial intelligence researcher, you should look to video games as ideal testbeds for the work you do. If you are a video game developer, you should look to AI for the technology that makes completely new types of games possible. This chapter lays out the case for both of these propositions. It asks the question ""what can video games do for AI"", and discusses how in particular general video game playing is the ideal testbed for artificial general intelligence research. It then asks the question ""what can AI do for video games"", and lays out a vision for what video games might look like if we had significantly more advanced AI at our disposal. The chapter is based on my keynote at IJCCI 2015, and is written in an attempt to be accessible to a broad audience. △ Less","5 December, 2016",https://arxiv.org/pdf/1612.01608
Message Passing Multi-Agent GANs,Arnab Ghosh;Viveka Kulharia;Vinay Namboodiri,"Communicating and sharing intelligence among agents is an important facet of achieving Artificial General Intelligence. As a first step towards this challenge, we introduce a novel framework for image generation: Message Passing Multi-Agent Generative Adversarial Networks (MPM GANs). While GANs have recently been shown to be very effective for image generation and other tasks, these networks have been limited to mostly single generator-discriminator networks. We show that we can obtain multi-agent GANs that communicate through message passing to achieve better image generation. The objectives of the individual agents in this framework are two fold: a co-operation objective and a competing objective. The co-operation objective ensures that the message sharing mechanism guides the other generator to generate better than itself while the competing objective encourages each generator to generate better than its counterpart. We analyze and visualize the messages that these GANs share among themselves in various scenarios. We quantitatively show that the message sharing formulation serves as a regularizer for the adversarial training. Qualitatively, we show that the different generators capture different traits of the underlying data distribution. △ Less","5 December, 2016",https://arxiv.org/pdf/1612.01294
Short-term traffic flow forecasting with spatial-temporal correlation in a hybrid deep learning framework,Yuankai Wu;Huachun Tan,"Deep learning approaches have reached a celebrity status in artificial intelligence field, its success have mostly relied on Convolutional Networks (CNN) and Recurrent Networks. By exploiting fundamental spatial properties of images and videos, the CNN always achieves dominant performance on visual tasks. And the Recurrent Networks (RNN) especially long short-term memory methods (LSTM) can successfully characterize the temporal correlation, thus exhibits superior capability for time series tasks. Traffic flow data have plentiful characteristics on both time and space domain. However, applications of CNN and LSTM approaches on traffic flow are limited. In this paper, we propose a novel deep architecture combined CNN and LSTM to forecast future traffic flow (CLTFP). An 1-dimension CNN is exploited to capture spatial features of traffic flow, and two LSTMs are utilized to mine the short-term variability and periodicities of traffic flow. Given those meaningful features, the feature-level fusion is performed to achieve short-term forecasting. The proposed CLTFP is compared with other popular forecasting methods on an open datasets. Experimental results indicate that the CLTFP has considerable advantages in traffic flow forecasting. in additional, the proposed CLTFP is analyzed from the view of Granger Causality, and several interesting properties of CLTFP are discovered and discussed . △ Less","3 December, 2016",https://arxiv.org/pdf/1612.01022
"Interaction Networks for Learning about Objects, Relations and Physics",Peter W. Battaglia;Razvan Pascanu;Matthew Lai;Danilo Rezende;Koray Kavukcuoglu,"Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains. △ Less","1 December, 2016",https://arxiv.org/pdf/1612.00222
Machine Learning for Dental Image Analysis,Young-jun Yu,"In order to study the application of artificial intelligence (AI) to dental imaging, we applied AI technology to classify a set of panoramic radiographs using (a) a convolutional neural network (CNN) which is a form of an artificial neural network (ANN), (b) representative image cognition algorithms that implement scale-invariant feature transform (SIFT), and (c) histogram of oriented gradients (HOG). △ Less","2 December, 2016",https://arxiv.org/pdf/1611.09958
Quantum Enhanced Inference in Markov Logic Networks,Peter Wittek;Christian Gogolin,"Markov logic networks (MLNs) reconcile two opposing schools in machine learning and artificial intelligence: causal networks, which account for uncertainty extremely well, and first-order logic, which allows for formal deduction. An MLN is essentially a first-order logic template to generate Markov networks. Inference in MLNs is probabilistic and it is often performed by approximate methods such as Markov chain Monte Carlo (MCMC) Gibbs sampling. An MLN has many regular, symmetric structures that can be exploited at both first-order level and in the generated Markov network. We analyze the graph structures that are produced by various lifting methods and investigate the extent to which quantum protocols can be used to speed up Gibbs sampling with state preparation and measurement schemes. We review different such approaches, discuss their advantages, theoretical limitations, and their appeal to implementations. We find that a straightforward application of a recent result yields exponential speedup compared to classical heuristics in approximate probabilistic inference, thereby demonstrating another example where advanced quantum resources can potentially prove useful in machine learning. △ Less","24 November, 2016",https://arxiv.org/pdf/1611.08104
"Double-quantitative γ^{\ast}-
fuzzy coverings approximation operators",Guangming Lang,"In digital-based information boom, the fuzzy covering rough set model is an important mathematical tool for artificial intelligence, and how to build the bridge between the fuzzy covering rough set theory and Pawlak's model is becoming a hot research topic. In this paper, we first present the γ-fuzzy covering based probabilistic and grade approximation operators and double-quantitative approximation operators. We also study the relationships among the three types of γ-fuzzy covering based approximation operators. Second, we propose the γ^{\ast}-fuzzy coverings based multi-granulation probabilistic and grade lower and upper approximation operators and multi-granulation double-quantitative lower and upper approximation operators. We also investigate the relationships among these types of γ-fuzzy coverings based approximation operators. Finally, we employ several examples to illustrate how to construct the lower and upper approximations of fuzzy sets with the absolute and relative quantitative information. △ Less","24 November, 2016",https://arxiv.org/pdf/1611.08103
A Survey of Methods for Collective Communication Optimization and Tuning,Udayanga Wickramasinghe;Andrew Lumsdaine,"New developments in HPC technology in terms of increasing computing power on multi/many core processors, high-bandwidth memory/IO subsystems and communication interconnects, pose a direct impact on software and runtime system development. These advancements have become useful in producing high-performance collective communication interfaces that integrate efficiently on a wide variety of platforms and environments. However, number of optimization options that shows up with each new technology or software framework has resulted in a \emph{combinatorial explosion} in feature space for tuning collective parameters such that finding the optimal set has become a nearly impossible task. Applicability of algorithmic choices available for optimizing collective communication depends largely on the scalability requirement for a particular usecase. This problem can be further exasperated by any requirement to run collective problems at very large scales such as in the case of exascale computing, at which impractical tuning by brute force may require many months of resources. Therefore application of statistical, data mining and artificial Intelligence or more general hybrid learning models seems essential in many collectives parameter optimization problems. We hope to explore current and the cutting edge of collective communication optimization and tuning methods and culminate with possible future directions towards this problem. △ Less","19 November, 2016",https://arxiv.org/pdf/1611.06334
Generalized LR parsing and the shuffle operator,John Maraist,"We adapt Tomita's Generalized LR algorithm to languages generated by context-free grammars enriched with a shuffle operator. The change involves extensions to the underlying handle-finding finite automaton, construction of parser tables, and the necessary optimizations in constructing a deterministic parser. Our system is motivated by an application from artificial intelligence plan recognition. We argue for the correctness of the system, and discuss future extensions of this work. △ Less","17 November, 2016",https://arxiv.org/pdf/1611.05831
Composing Music with Grammar Argumented Neural Networks and Note-Level Encoding,Zheng Sun;Jiaqi Liu;Zewang Zhang;Jingwen Chen;Zhao Huo;Ching Hua Lee;Xiao Zhang,"Creating aesthetically pleasing pieces of art, including music, has been a long-term goal for artificial intelligence research. Despite recent successes of long-short term memory (LSTM) recurrent neural networks (RNNs) in sequential learning, LSTM neural networks have not, by themselves, been able to generate natural-sounding music conforming to music theory. To transcend this inadequacy, we put forward a novel method for music composition that combines the LSTM with Grammars motivated by music theory. The main tenets of music theory are encoded as grammar argumented (GA) filters on the training data, such that the machine can be trained to generate music inheriting the naturalness of human-composed pieces from the original dataset while adhering to the rules of music theory. Unlike previous approaches, pitches and durations are encoded as one semantic entity, which we refer to as note-level encoding. This allows easy implementation of music theory grammars, as well as closer emulation of the thinking pattern of a musician. Although the GA rules are applied to the training data and never directly to the LSTM music generation, our machine still composes music that possess high incidences of diatonic scale notes, small pitch intervals and chords, in deference to music theory. △ Less","7 December, 2016",https://arxiv.org/pdf/1611.05416
PCT and Beyond: Towards a Computational Framework for `Intelligent' Communicative Systems,Prof. Roger K. Moore,"Recent years have witnessed increasing interest in the potential benefits of `intelligent' autonomous machines such as robots. Honda's Asimo humanoid robot, iRobot's Roomba robot vacuum cleaner and Google's driverless cars have fired the imagination of the general public, and social media buzz with speculation about a utopian world of helpful robot assistants or the coming robot apocalypse! However, there is a long way to go before autonomous systems reach the level of capabilities required for even the simplest of tasks involving human-robot interaction - especially if it involves communicative behaviour such as speech and language. Of course the field of Artificial Intelligence (AI) has made great strides in these areas, and has moved on from abstract high-level rule-based paradigms to embodied architectures whose operations are grounded in real physical environments. What is still missing, however, is an overarching theory of intelligent communicative behaviour that informs system-level design decisions in order to provide a more coherent approach to system integration. This chapter introduces the beginnings of such a framework inspired by the principles of Perceptual Control Theory (PCT). In particular, it is observed that PCT has hitherto tended to view perceptual processes as a relatively straightforward series of transformations from sensation to perception, and has overlooked the potential of powerful generative model-based solutions that have emerged in practical fields such as visual or auditory scene analysis. Starting from first principles, a sequence of arguments is presented which not only shows how these ideas might be integrated into PCT, but which also extend PCT towards a remarkably symmetric architecture for a needs-driven communicative agent. It is concluded that, if behaviour is the control of perception, then perception is the simulation of behaviour. △ Less","16 November, 2016",https://arxiv.org/pdf/1611.05379
A Framework for Searching for General Artificial Intelligence,Marek Rosa;Jan Feyereisl;The GoodAI Collective,"There is a significant lack of unified approaches to building generally intelligent machines. The majority of current artificial intelligence research operates within a very narrow field of focus, frequently without considering the importance of the 'big picture'. In this document, we seek to describe and unify principles that guide the basis of our development of general artificial intelligence. These principles revolve around the idea that intelligence is a tool for searching for general solutions to problems. We define intelligence as the ability to acquire skills that narrow this search, diversify it and help steer it to more promising areas. We also provide suggestions for studying, measuring, and testing the various skills and abilities that a human-level intelligent machine needs to acquire. The document aims to be both implementation agnostic, and to provide an analytic, systematic, and scalable way to generate hypotheses that we believe are needed to meet the necessary conditions in the search for general artificial intelligence. We believe that such a framework is an important stepping stone for bringing together definitions, highlighting open problems, connecting researchers willing to collaborate, and for unifying the arguably most significant search of this century. △ Less","2 November, 2016",https://arxiv.org/pdf/1611.00685
Quantum-enhanced machine learning,Vedran Dunjko;Jacob M. Taylor;Hans J. Briegel,"The emerging field of quantum machine learning has the potential to substantially aid in the problems and scope of artificial intelligence. This is only enhanced by recent successes in the field of classical machine learning. In this work we propose an approach for the systematic treatment of machine learning, from the perspective of quantum information. Our approach is general and covers all three main branches of machine learning: supervised, unsupervised and reinforcement learning. While quantum improvements in supervised and unsupervised learning have been reported, reinforcement learning has received much less attention. Within our approach, we tackle the problem of quantum enhancements in reinforcement learning as well, and propose a systematic scheme for providing improvements. As an example, we show that quadratic improvements in learning efficiency, and exponential improvements in performance over limited time periods, can be obtained for a broad class of learning problems. △ Less","26 October, 2016",https://arxiv.org/pdf/1610.08251
Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures,Roman V. Yampolskiy;M. S. Spellchecker,"In this work, we present and analyze reported failures of artificially intelligent systems and extrapolate our analysis to future AIs. We suggest that both the frequency and the seriousness of future AI failures will steadily increase. AI Safety can be improved based on ideas developed by cybersecurity experts. For narrow AIs safety failures are at the same, moderate, level of criticality as in cybersecurity, however for general AI, failures have a fundamentally different impact. A single failure of a superintelligent system may cause a catastrophic event without a chance for recovery. The goal of cybersecurity is to reduce the number of successful attacks on the system; the goal of AI Safety is to make sure zero attacks succeed in bypassing the safety mechanisms. Unfortunately, such a level of performance is unachievable. Every security system will eventually fail; there is no such thing as a 100% secure system. △ Less","25 October, 2016",https://arxiv.org/pdf/1610.07997
Intelligence in Artificial Intelligence,Shoumen Palit Austin Datta,"The elusive quest for intelligence in artificial intelligence prompts us to consider that instituting human-level intelligence in systems may be (still) in the realm of utopia. In about a quarter century, we have witnessed the winter of AI (1990) being transformed and transported to the zenith of tabloid fodder about AI (2015). The discussion at hand is about the elements that constitute the canonical idea of intelligence. The delivery of intelligence as a pay-per-use-service, popping out of an app or from a shrink-wrapped software defined point solution, is in contrast to the bio-inspired view of intelligence as an outcome, perhaps formed from a tapestry of events, cross-pollinated by instances, each with its own microcosm of experiences and learning, which may not be discrete all-or-none functions but continuous, over space and time. The enterprise world may not require, aspire or desire such an engaged solution to improve its services for enabling digital transformation through the deployment of digital twins, for example. One might ask whether the ""work-flow on steroids"" version of decision support may suffice for intelligence? Are we harking back to the era of rule based expert systems? The image conjured by the publicity machines offers deep solutions with human-level AI and preposterous claims about capturing the ""brain in a box"" by 2020. Even emulating insects may be difficult in terms of real progress. Perhaps we can try to focus on worms (Caenorhabditis elegans) which may be better suited for what business needs to quench its thirst for so-called intelligence in AI. △ Less","25 October, 2016",https://arxiv.org/pdf/1610.07862
Embodiment of Learning in Electro-Optical Signal Processors,Michiel Hermans;Piotr Antonik;Marc Haelterman;Serge Massar,"Delay-coupled electro-optical systems have received much attention for their dynamical properties and their potential use in signal processing. In particular it has recently been demonstrated, using the artificial intelligence algorithm known as reservoir computing, that photonic implementations of such systems solve complex tasks such as speech recognition. Here we show how the backpropagation algorithm can be physically implemented on the same electro-optical delay-coupled architecture used for computation with only minor changes to the original design. We find that, compared when the backpropagation algorithm is not used, the error rate of the resulting computing device, evaluated on three benchmark tasks, decreases considerably. This demonstrates that electro-optical analog computers can embody a large part of their own training process, allowing them to be applied to new, more difficult tasks. △ Less","27 October, 2016",https://arxiv.org/pdf/1610.06269
Revisiting Multiple Instance Neural Networks,Xinggang Wang;Yongluan Yan;Peng Tang;Xiang Bai;Wenyu Liu,"Recently neural networks and multiple instance learning are both attractive topics in Artificial Intelligence related research fields. Deep neural networks have achieved great success in supervised learning problems, and multiple instance learning as a typical weakly-supervised learning method is effective for many applications in computer vision, biometrics, nature language processing, etc. In this paper, we revisit the problem of solving multiple instance learning problems using neural networks. Neural networks are appealing for solving multiple instance learning problem. The multiple instance neural networks perform multiple instance learning in an end-to-end way, which take a bag with various number of instances as input and directly output bag label. All of the parameters in a multiple instance network are able to be optimized via back-propagation. We propose a new multiple instance neural network to learn bag representations, which is different from the existing multiple instance neural networks that focus on estimating instance label. In addition, recent tricks developed in deep learning have been studied in multiple instance networks, we find deep supervision is effective for boosting bag classification accuracy. In the experiments, the proposed multiple instance networks achieve state-of-the-art or competitive performance on several MIL benchmarks. Moreover, it is extremely fast for both testing and training, e.g., it takes only 0.0003 second to predict a bag and a few seconds to train on a MIL datasets on a moderate CPU. △ Less","8 October, 2016",https://arxiv.org/pdf/1610.02501
Metaheuristic Algorithms for Convolution Neural Network,L. M. Rasdi Rere;Mohamad Ivan Fanany;Aniati Murni Arymurthy,"A typical modern optimization technique is usually either heuristic or metaheuristic. This technique has managed to solve some optimization problems in the research area of science, engineering, and industry. However, implementation strategy of metaheuristic for accuracy improvement on convolution neural networks (CNN), a famous deep learning method, is still rarely investigated. Deep learning relates to a type of machine learning technique, where its aim is to move closer to the goal of artificial intelligence of creating a machine that could successfully perform any intellectual tasks that can be carried out by a human. In this paper, we propose the implementation strategy of three popular metaheuristic approaches, that is, simulated annealing, differential evolution, and harmony search, to optimize CNN. The performances of these metaheuristic methods in optimizing CNN on classifying MNIST and CIFAR dataset were evaluated and compared. Furthermore, the proposed methods are also compared with the original CNN. Although the proposed methods show an increase in the computation time, their accuracy has also been improved (up to 7.14 percent). △ Less","6 October, 2016",https://arxiv.org/pdf/1610.01925
Computer Network Defense Through Radial Wave Functions,Ian Malloy,"The purpose of this research was to synthesize basic and fundamental findings in quantum computing, as applied to the attack and defense of conventional computer networks. The concept focuses on uses of radio waves as a shield for, and attack against traditional computers. A logic bomb is analogous to a landmine in a computer network, and if one was to implement it as non-trivial mitigation, it will aid computer network defense. As has been seen in kinetic warfare, the use of landmines has been devastating to geopolitical regions in that they are severely difficult for a civilian to avoid triggering given the unknown position of a landmine. Thus, the importance of understanding a logic bomb is relevant and has corollaries to quantum mechanics as well. The research synthesizes quantum logic phase shifts in certain respects using the Dynamic Data Exchange protocol in software written for this work, as well as a C-NOT gate applied to a virtual quantum circuit environment by implementing a Quantum Fourier Transform. The research focus applies the principles of coherence and entanglement from quantum physics, the concept of expert systems in artificial intelligence, principles of prime number based cryptography with trapdoor functions, and modeling radio wave propagation against an event from unknown parameters. This comes as a program relying on the artificial intelligence concept of an expert system in conjunction with trigger events for a trapdoor function relying on infinite recursion, as well as system mechanics for elliptic curve cryptography along orbital angular momenta. Here trapdoor both denotes the form of cipher, as well as the implied relationship to logic bombs. △ Less","6 October, 2016",https://arxiv.org/pdf/1610.01734
A Tour of TensorFlow,Peter Goldsborough,"Deep learning is a branch of artificial intelligence employing deep neural network architectures that has significantly advanced the state-of-the-art in computer vision, speech recognition, natural language processing and other domains. In November 2015, Google released \textit{TensorFlow}, an open source deep learning software library for defining, training and deploying machine learning models. In this paper, we review TensorFlow and put it in context of modern deep learning concepts and software. We discuss its basic computational paradigms and distributed execution model, its programming interface as well as accompanying visualization toolkits. We then compare TensorFlow to alternative libraries such as Theano, Torch or Caffe on a qualitative as well as quantitative basis and finally comment on observed use-cases of TensorFlow in academia and industry. △ Less","1 October, 2016",https://arxiv.org/pdf/1610.01178
Contextual RNN-GANs for Abstract Reasoning Diagram Generation,Arnab Ghosh;Viveka Kulharia;Amitabha Mukerjee;Vinay Namboodiri;Mohit Bansal,"Understanding, predicting, and generating object motions and transformations is a core problem in artificial intelligence. Modeling sequences of evolving images may provide better representations and models of motion and may ultimately be used for forecasting, simulation, or video generation. Diagrammatic Abstract Reasoning is an avenue in which diagrams evolve in complex patterns and one needs to infer the underlying pattern sequence and generate the next image in the sequence. For this, we develop a novel Contextual Generative Adversarial Network based on Recurrent Neural Networks (Context-RNN-GANs), where both the generator and the discriminator modules are based on contextual history (modeled as RNNs) and the adversarial discriminator guides the generator to produce realistic images for the particular time step in the image sequence. We evaluate the Context-RNN-GAN model (and its variants) on a novel dataset of Diagrammatic Abstract Reasoning, where it performs competitively with 10th-grade human performance but there is still scope for interesting improvements as compared to college-grade human performance. We also evaluate our model on a standard video next-frame prediction task, achieving improved performance over comparable state-of-the-art. △ Less","6 December, 2016",https://arxiv.org/pdf/1609.09444
Comprehensive Evaluation of OpenCL-based Convolutional Neural Network Accelerators in Xilinx and Altera FPGAs,R. Tapiador;A. Rios-Navarro;A. Linares-Barranco;Minkyu Kim;Deepak Kadetotad;Jae-sun Seo,"Deep learning has significantly advanced the state of the art in artificial intelligence, gaining wide popularity from both industry and academia. Special interest is around Convolutional Neural Networks (CNN), which take inspiration from the hierarchical structure of the visual cortex, to form deep layers of convolutional operations, along with fully connected classifiers. Hardware implementations of these deep CNN architectures are challenged with memory bottlenecks that require many convolution and fully-connected layers demanding large amount of communication for parallel computation. Multi-core CPU based solutions have demonstrated their inadequacy for this problem due to the memory wall and low parallelism. Many-core GPU architectures show superior performance but they consume high power and also have memory constraints due to inconsistencies between cache and main memory. FPGA design solutions are also actively being explored, which allow implementing the memory hierarchy using embedded BlockRAM. This boosts the parallel use of shared memory elements between multiple processing units, avoiding data replicability and inconsistencies. This makes FPGAs potentially powerful solutions for real-time classification of CNNs. Both Altera and Xilinx have adopted OpenCL co-design framework from GPU for FPGA designs as a pseudo-automatic development solution. In this paper, a comprehensive evaluation and comparison of Altera and Xilinx OpenCL frameworks for a 5-layer deep CNN is presented. Hardware resources, temporal performance and the OpenCL architecture for CNNs are discussed. Xilinx demonstrates faster synthesis, better FPGA resource utilization and more compact boards. Altera provides multi-platforms tools, mature design community and better execution times. △ Less","29 September, 2016",https://arxiv.org/pdf/1609.09296
Topic Browsing for Research Papers with Hierarchical Latent Tree Analysis,Leonard K. M. Poon;Nevin L. Zhang,"Academic researchers often need to face with a large collection of research papers in the literature. This problem may be even worse for postgraduate students who are new to a field and may not know where to start. To address this problem, we have developed an online catalog of research papers where the papers have been automatically categorized by a topic model. The catalog contains 7719 papers from the proceedings of two artificial intelligence conferences from 2000 to 2015. Rather than the commonly used Latent Dirichlet Allocation, we use a recently proposed method called hierarchical latent tree analysis for topic modeling. The resulting topic model contains a hierarchy of topics so that users can browse the topics from the top level to the bottom level. The topic model contains a manageable number of general topics at the top level and allows thousands of fine-grained topics at the bottom level. It also can detect topics that have emerged recently. △ Less","28 September, 2016",https://arxiv.org/pdf/1609.09188
Correct classification for big/smart/fast data machine learning,Sander Stepanov,"Table (database) / Relational database Classification for big/smart/fast data machine learning is one of the most important tasks of predictive analytics and extracting valuable information from data. It is core applied technique for what now understood under data science and/or artificial intelligence. Widely used Decision Tree (Random Forest) and rare used rule based PRISM , VFST, etc classifiers are empirical substitutions of theoretically correct to use Boolean functions minimization. Developing Minimization of Boolean functions algorithms is started long time ago by Edward Veitch's 1952. Since it, big efforts by wide scientific/industrial community was done to find feasible solution of Boolean functions minimization. In this paper we propose consider table data classification from mathematical point of view, as minimization of Boolean functions. It is shown that data representation may be transformed to Boolean functions form and how to use known algorithms. For simplicity, binary output function is used for development, what opens doors for multivalued outputs developments. △ Less","27 September, 2016",https://arxiv.org/pdf/1609.08550
Sooner than Expected: Hitting the Wall of Complexity in Evolution,Thomas Schmickl;Payam Zahadat;Heiko Hamann,"In evolutionary robotics an encoding of the control software, which maps sensor data (input) to motor control values (output), is shaped by stochastic optimization methods to complete a predefined task. This approach is assumed to be beneficial compared to standard methods of controller design in those cases where no a-priori model is available that could help to optimize performance. Also for robots that have to operate in unpredictable environments, an evolutionary robotics approach is favorable. We demonstrate here that such a model-free approach is not a free lunch, as already simple tasks can represent unsolvable barriers for fully open-ended uninformed evolutionary computation techniques. We propose here the 'Wankelmut' task as an objective for an evolutionary approach that starts from scratch without pre-shaped controller software or any other informed approach that would force the behavior to be evolved in a desired way. Our focal claim is that 'Wankelmut' represents the simplest set of problems that makes plain-vanilla evolutionary computation fail. We demonstrate this by a series of simple standard evolutionary approaches using different fitness functions and standard artificial neural networks as well as continuous-time recurrent neural networks. All our tested approaches failed. We claim that any other evolutionary approach will also fail that does per-se not favor or enforce modularity and does not freeze or protect already evolved functionalities. Thus we propose a hard-to-pass benchmark and make a strong statement for self-complexifying and generative approaches in evolutionary computation. We anticipate that defining such a 'simplest task to fail' is a valuable benchmark for promoting future development in the field of artificial intelligence, evolutionary robotics and artificial life. △ Less","25 September, 2016",https://arxiv.org/pdf/1609.07722
The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA),Andrew Shin;Yoshitaka Ushiku;Tatsuya Harada,"Visual Question Answering (VQA) task has showcased a new stage of interaction between language and vision, two of the most pivotal components of artificial intelligence. However, it has mostly focused on generating short and repetitive answers, mostly single words, which fall short of rich linguistic capabilities of humans. We introduce Full-Sentence Visual Question Answering (FSVQA) dataset, consisting of nearly 1 million pairs of questions and full-sentence answers for images, built by applying a number of rule-based natural language processing techniques to original VQA dataset and captions in the MS COCO dataset. This poses many additional complexities to conventional VQA task, and we provide a baseline for approaching and evaluating the task, on top of which we invite the research community to build further improvements. △ Less","21 September, 2016",https://arxiv.org/pdf/1609.06657
Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge,Oriol Vinyals;Alexander Toshev;Samy Bengio;Dumitru Erhan,"Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. Finally, given the recent surge of interest in this task, a competition was organized in 2015 using the newly released COCO dataset. We describe and analyze the various improvements we applied to our own baseline and show the resulting performance in the competition, which we won ex-aequo with a team from Microsoft Research, and provide an open source implementation in TensorFlow. △ Less","21 September, 2016",https://arxiv.org/pdf/1609.06647
Predicting Future Shanghai Stock Market Price using ANN in the Period 21-Sep-2016 to 11-Oct-2016,Barack Wamkaya Wanjawa,"Predicting the prices of stocks at any stock market remains a quest for many investors and researchers. Those who trade at the stock market tend to use technical, fundamental or time series analysis in their predictions. These methods usually guide on trends and not the exact likely prices. It is for this reason that Artificial Intelligence systems, such as Artificial Neural Network, that is feedforward multi-layer perceptron with error backpropagation, can be used for such predictions. A difficulty in neural network application is the determination of suitable network parameters. A previous research by the author already determined the network parameters as 5:21:21:1 with 80% training data or 4-year of training data as a good enough model for stock prediction. This model has been put to the test in predicting selected Shanghai Stock Exchange stocks in the future period of 21-Sep-2016 to 11-Oct-2016, about one week after the publication of these predictions. The research aims at confirming that simple neural network systems can be quite powerful in typical stock market predictions. △ Less","17 September, 2016",https://arxiv.org/pdf/1609.05394
Long-Term Trends in the Public Perception of Artificial Intelligence,Ethan Fast;Eric Horvitz,"Analyses of text corpora over time can reveal trends in beliefs, interest, and sentiment about a topic. We focus on views expressed about artificial intelligence (AI) in the New York Times over a 30-year period. General interest, awareness, and discussion about AI has waxed and waned since the field was founded in 1956. We present a set of measures that captures levels of engagement, measures of pessimism and optimism, the prevalence of specific hopes and concerns, and topics that are linked to discussions about AI over decades. We find that discussion of AI has increased sharply since 2009, and that these discussions have been consistently more optimistic than pessimistic. However, when we examine specific concerns, we find that worries of loss of control of AI, ethical concerns for AI, and the negative impact of AI on work have grown in recent years. We also find that hopes for AI in healthcare and education have increased over time. △ Less","2 December, 2016",https://arxiv.org/pdf/1609.04904
A light-stimulated neuromorphic device based on graphene hybrid phototransistor,Shuchao Qin;Fengqiu Wang;Yujie Liu;Qing Wan;Xinran Wang;Yongbing Xu;Yi Shi;Xiaomu Wang;Rong Zhang,"Neuromorphic chip refers to an unconventional computing architecture that is modelled on biological brains. It is ideally suited for processing sensory data for intelligence computing, decision-making or context cognition. Despite rapid development, conventional artificial synapses exhibit poor connection flexibility and require separate data acquisition circuitry, resulting in limited functionalities and significant hardware redundancy. Here we report a novel light-stimulated artificial synapse based on a graphene-nanotube hybrid phototransistor that can directly convert optical stimuli into a ""neural image"" for further neuronal analysis. Our optically-driven synapses involve multiple steps of plasticity mechanisms and importantly exhibit flexible tuning of both short- and long-term plasticity. Furthermore, our neuromorphic phototransistor can take multiple pre-synaptic light stimuli via wavelength-division multiplexing and allows advanced optical processing through charge-trap-mediated optical coupling. The capability of complex neuromorphic functionalities in a simple silicon-compatible device paves the way for novel neuromorphic computing architectures involving photonics. △ Less","7 September, 2016",https://arxiv.org/pdf/1609.02554
Latent Dependency Forest Models,Shanbo Chu;Yong Jiang;Kewei Tu,"Probabilistic modeling is one of the foundations of modern machine learning and artificial intelligence. In this paper, we propose a novel type of probabilistic models named latent dependency forest models (LDFMs). A LDFM models the dependencies between random variables with a forest structure that can change dynamically based on the variable values. It is therefore capable of modeling context-specific independence. We parameterize a LDFM using a first-order non-projective dependency grammar. Learning LDFMs from data can be formulated purely as a parameter learning problem, and hence the difficult problem of model structure learning is circumvented. Our experimental results show that LDFMs are competitive with existing probabilistic models. △ Less","20 November, 2016",https://arxiv.org/pdf/1609.02236
"Non-Evolutionary Superintelligences Do Nothing, Eventually",Telmo Menezes,"There is overwhelming evidence that human intelligence is a product of Darwinian evolution. Investigating the consequences of self-modification, and more precisely, the consequences of utility function self-modification, leads to the stronger claim that not only human, but any form of intelligence is ultimately only possible within evolutionary processes. Human-designed artificial intelligences can only remain stable until they discover how to manipulate their own utility function. By definition, a human designer cannot prevent a superhuman intelligence from modifying itself, even if protection mechanisms against this action are put in place. Without evolutionary pressure, sufficiently advanced artificial intelligences become inert by simplifying their own utility function. Within evolutionary processes, the implicit utility function is always reducible to persistence, and the control of superhuman intelligences embedded in evolutionary processes is not possible. Mechanisms against utility function self-modification are ultimately futile. Instead, scientific effort toward the mitigation of existential risks from the development of superintelligences should be in two directions: understanding consciousness, and the complex dynamics of evolutionary systems. △ Less","7 September, 2016",https://arxiv.org/pdf/1609.02009
Reprowd: Crowdsourced Data Processing Made Reproducible,Ruochen Jiang;Jiannan Wang,"Crowdsourcing is a multidisciplinary research area including disciplines like artificial intelligence, human-computer interaction, database, and social science. To facilitate cooperation across disciplines, reproducibility is a crucial factor, but unfortunately, it has not gotten enough attention in the HCOMP community. In this paper, we present Reprowd, a system aiming to make it easy to reproduce crowdsourced data processing research. We have open sourced Reprowd at http://sfu-db.github.io/reprowd/. △ Less","3 September, 2016",https://arxiv.org/pdf/1609.00791
Single photon in hierarchical architecture for physical reinforcement learning: Photon intelligence,Makoto Naruse;Martin Berthel;Aurélien Drezet;Serge Huant;Hirokazu Hori;Song-Ju Kim,"Understanding and using natural processes for intelligent functionalities, referred to as natural intelligence, has recently attracted interest from a variety of fields, including post-silicon computing for artificial intelligence and decision making in the behavioural sciences. In a past study, we successfully used the wave-particle duality of single photons to solve the two-armed bandit problem, which constitutes the foundation of reinforcement learning and decision making. In this study, we propose and confirm a hierarchical architecture for single-photon-based reinforcement learning and decision making that verifies the scalability of the principle. Specifically, the four-armed bandit problem is solved given zero prior knowledge in a two-layer hierarchical architecture, where polarization is autonomously adapted in order to effect adequate decision making using single-photon measurements. In the hierarchical structure, the notion of layer-dependent decisions emerges. The optimal solutions in the coarse layer and in the fine layer, however, conflict with each other in some contradictive problems. We show that while what we call a tournament strategy resolves such contradictions, the probabilistic nature of single photons allows for the direct location of the optimal solution even for contradictive problems, hence manifesting the exploration ability of single photons. This study provides insights into photon intelligence in hierarchical architectures for future artificial intelligence as well as the potential of natural processes for intelligent functionalities. △ Less","1 September, 2016",https://arxiv.org/pdf/1609.00686
Smart Policies for Artificial Intelligence,Miles Brundage;Joanna Bryson,"We argue that there already exists de facto artificial intelligence policy - a patchwork of policies impacting the field of AI's development in myriad ways. The key question related to AI policy, then, is not whether AI should be governed at all, but how it is currently being governed, and how that governance might become more informed, integrated, effective, and anticipatory. We describe the main components of de facto AI policy and make some recommendations for how AI policy can be improved, drawing on lessons from other scientific and technological domains. △ Less","29 August, 2016",https://arxiv.org/pdf/1608.08196
A Bi-LSTM-RNN Model for Relation Classification Using Low-Cost Sequence Features,Fei Li;Meishan Zhang;Guohong Fu;Tao Qian;Donghong Ji,"Relation classification is associated with many potential applications in the artificial intelligence area. Recent approaches usually leverage neural networks based on structure features such as syntactic or dependency features to solve this problem. However, high-cost structure features make such approaches inconvenient to be directly used. In addition, structure features are probably domain-dependent. Therefore, this paper proposes a bi-directional long-short-term-memory recurrent-neural-network (Bi-LSTM-RNN) model based on low-cost sequence features to address relation classification. This model divides a sentence or text segment into five parts, namely two target entities and their three contexts. It learns the representations of entities and their contexts, and uses them to classify relations. We evaluate our model on two standard benchmark datasets in different domains, namely SemEval-2010 Task 8 and BioNLP-ST 2016 Task BB3. In the former dataset, our model achieves comparable performance compared with other models using sequence features. In the latter dataset, our model obtains the third best results compared with other models in the official evaluation. Moreover, we find that the context between two target entities plays the most important role in relation classification. Furthermore, statistic experiments show that the context between two target entities can be used as an approximate replacement of the shortest dependency path when dependency parsing is not used. △ Less","27 August, 2016",https://arxiv.org/pdf/1608.07720
Fathom: Reference Workloads for Modern Deep Learning Methods,Robert Adolf;Saketh Rama;Brandon Reagen;Gu-Yeon Wei;David Brooks,"Deep learning has been popularized by its recent successes on challenging artificial intelligence problems. One of the reasons for its dominance is also an ongoing challenge: the need for immense amounts of computational power. Hardware architects have responded by proposing a wide array of promising ideas, but to date, the majority of the work has focused on specific algorithms in somewhat narrow application domains. While their specificity does not diminish these approaches, there is a clear need for more flexible solutions. We believe the first step is to examine the characteristics of cutting edge models from across the deep learning community. Consequently, we have assembled Fathom: a collection of eight archetypal deep learning workloads for study. Each of these models comes from a seminal work in the deep learning community, ranging from the familiar deep convolutional neural network of Krizhevsky et al., to the more exotic memory networks from Facebook's AI research group. Fathom has been released online, and this paper focuses on understanding the fundamental performance characteristics of each model. We use a set of application-level modeling tools built around the TensorFlow deep learning framework in order to analyze the behavior of the Fathom workloads. We present a breakdown of where time is spent, the similarities between the performance profiles of our models, an analysis of behavior in inference and training, and the effects of parallelism on scaling. △ Less","23 August, 2016",https://arxiv.org/pdf/1608.06581
Planning With Discrete Harmonic Potential Fields,Ahmad A. Masoud,"In this work a discrete counterpart to the continuous harmonic potential field approach is suggested. The extension to the discrete case makes use of the strong relation HPF-based planning has to connectionist artificial intelligence (AI). Connectionist AI systems are networks of simple, interconnected processors running in parallel within the confines of the environment in which the planning action is to be synthesized. It is not hard to see that such a paradigm naturally lends itself to planning on weighted graphs where the processors may be seen as the vertices of the graph and the relations among them as its edges. Electrical networks are an effective realization of connectionist AI. The utility of the discrete HPF (DHPF) approach is demonstrated in three ways. First, the capability of the DHPF approach to generate new, abstract, planning techniques is demonstrated by constructing a novel, efficient, optimal, discrete planning method called the M* algorithm. Also, its ability to augment the capabilities of existing planners is demonstrated by suggesting a generic solution to the lower bound problem faced by the A* algorithm. The DHPF approach is shown to be useful in solving specific planning problems in communication. It is demonstrated that the discrete HPF paradigm can support routing on-the-fly while the network is still in a transient state. It is shown by simulation that if a path to the target always exist and the switching delays in the routers are negligible, a packet will reach its destination despite the changes in the network which may simultaneously take place while the packet is being routed. △ Less","21 August, 2016",https://arxiv.org/pdf/1608.05931
Pilot Testing an Artificial Intelligence Algorithm That Selects Homeless Youth Peer Leaders Who Promote HIV Testing,Eric Rice;Robin Petering;Jaih Craddock;Amanda Yoshioka-Maxwell;Amulya Yadav;Milind Tambe,"Objective. To pilot test an artificial intelligence (AI) algorithm that selects peer change agents (PCA) to disseminate HIV testing messaging in a population of homeless youth. Methods. We recruited and assessed 62 youth at baseline, 1 month (n = 48), and 3 months (n = 38). A Facebook app collected preliminary social network data. Eleven PCAs selected by AI attended a 1-day training and 7 weekly booster sessions. Mixed-effects models with random effects were used to assess change over time. Results. Significant change over time was observed in past 6-month HIV testing (57.9%, 82.4%, 76.3%; p < .05) but not condom use (63.9%, 65.7%, 65.8%). Most youth reported speaking to a PCA about HIV prevention (72.0% at 1 month, 61.5% at 3 months). Conclusions. AI is a promising avenue for implementing PCA models for homeless youth. Increasing rates of regular HIV testing is critical to HIV prevention and linking homeless youth to treatment. △ Less","19 August, 2016",https://arxiv.org/pdf/1608.05701
Essentials of an Integrated Crowd Management Support System Based on Collective Artificial Intelligence,Giuseppe Vizzari;Stefania Bandini,"The simulation of the dynamical behavior of pedestrians and crowds in spatial structures is a consolidated research and application context that still presents challenges for researchers in different fields and disciplines. Despite currently available commercial systems for this kind of simulation are growingly employed by designers and planners for the evaluation of alternative solutions, this class of systems is generally not integrated with existing monitoring and control infrastructures, usually employed by crowd managers and field operators for security reasons. This paper introduces the essentials and the related computational frame- work of an Integrated Crowd Management Support System based on a Collective Artificial Intelligence approach encompassing (i) interfaces from and to monitored and controlled environments (respectively, sen- sors and actuators), (ii) a set of software tools supporting the analysis of pedestrians and crowd phenomena taking place in the environment to feed a (iii) faster than real-time simulation of the plausible evolution of the current situation in order to support forms of inference provid- ing decision support to crowd managers, potentially directly controlling elements of the environment (e.g. blocking turnstiles, escalators), com- municating orders to operators on the field or trying to influence the pedestrians by means of dynamic signage or audible messages. △ Less","17 August, 2016",https://arxiv.org/pdf/1608.04851
Natural Language Processing using Hadoop and KOSHIK,Emre Erturk;Hong Shi,"Natural language processing, as a data analytics related technology, is used widely in many research areas such as artificial intelligence, human language processing, and translation. At present, due to explosive growth of data, there are many challenges for natural language processing. Hadoop is one of the platforms that can process the large amount of data required for natural language processing. KOSHIK is one of the natural language processing architectures, and utilizes Hadoop and contains language processing components such as Stanford CoreNLP and OpenNLP. This study describes how to build a KOSHIK platform with the relevant tools, and provides the steps to analyze wiki data. Finally, it evaluates and discusses the advantages and disadvantages of the KOSHIK architecture, and gives recommendations on improving the processing performance. △ Less","15 August, 2016",https://arxiv.org/pdf/1608.04434
The Machine that Builds Itself: How the Strengths of Lisp Family Languages Facilitate Building Complex and Flexible Bioinformatic Models,Bohdan B. Khomtchouk;Edmund Weitz;Claes Wahlestedt,"We address the need for expanding the presence of the Lisp family of programming languages in bioinformatics and computational biology research. Languages of this family, like Common Lisp, Scheme, or Clojure, facilitate the creation of powerful and flexible software models that are required for complex and rapidly evolving domains like biology. We will point out several important key features that distinguish languages of the Lisp family from other programming languages and we will explain how these features can aid researchers in becoming more productive and creating better code. We will also show how these features make these languages ideal tools for artificial intelligence and machine learning applications. We will specifically stress the advantages of domain-specific languages (DSL): languages which are specialized to a particular area and thus not only facilitate easier research problem formulation, but also aid in the establishment of standards and best programming practices as applied to the specific research field at hand. DSLs are particularly easy to build in Common Lisp, the most comprehensive Lisp dialect, which is commonly referred to as the ""programmable programming language."" We are convinced that Lisp grants programmers unprecedented power to build increasingly sophisticated artificial intelligence systems that may ultimately transform machine learning and AI research in bioinformatics and computational biology. △ Less","18 September, 2016",https://arxiv.org/pdf/1608.02621
Learning a Driving Simulator,Eder Santana;George Hotz,"Comma.ai's approach to Artificial Intelligence for self-driving cars is based on an agent that learns to clone driver behaviors and plans maneuvers by simulating future events in the road. This paper illustrates one of our research approaches for driving simulation. One where we learn to simulate. Here we investigate variational autoencoders with classical and learned cost functions using generative adversarial networks for embedding road frames. Afterwards, we learn a transition model in the embedded space using action conditioned Recurrent Neural Networks. We show that our approach can keep predicting realistic looking video for several frames despite the transition model being optimized without a cost function in the pixel space. △ Less","3 August, 2016",https://arxiv.org/pdf/1608.01230
Psychologically inspired planning method for smart relocation task,Aleksandr I. Panov;Konstantin Yakovlev,"Behavior planning is known to be one of the basic cognitive functions, which is essential for any cognitive architecture of any control system used in robotics. At the same time most of the widespread planning algorithms employed in those systems are developed using only approaches and models of Artificial Intelligence and don't take into account numerous results of cognitive experiments. As a result, there is a strong need for novel methods of behavior planning suitable for modern cognitive architectures aimed at robot control. One such method is presented in this work and is studied within a special class of navigation task called smart relocation task. The method is based on the hierarchical two-level model of abstraction and knowledge representation, e.g. symbolic and subsymbolic. On the symbolic level sign world model is used for knowledge representation and hierarchical planning algorithm, PMA, is utilized for planning. On the subsymbolic level the task of path planning is considered and solved as a graph search problem. Interaction between both planners is examined and inter-level interfaces and feedback loops are described. Preliminary experimental results are presented. △ Less","27 July, 2016",https://arxiv.org/pdf/1607.08181
Automatically Reinforcing a Game AI,David L. St-Pierre;Jean-Baptiste Hoock;Jialin Liu;Fabien Teytaud;Olivier Teytaud,"A recent research trend in Artificial Intelligence (AI) is the combination of several programs into one single, stronger, program; this is termed portfolio methods. We here investigate the application of such methods to Game Playing Programs (GPPs). In addition, we consider the case in which only one GPP is available - by decomposing this single GPP into several ones through the use of parameters or even simply random seeds. These portfolio methods are trained in a learning phase. We propose two different offline approaches. The simplest one, BestArm, is a straightforward optimization of seeds or parame- ters; it performs quite well against the original GPP, but performs poorly against an opponent which repeats games and learns. The second one, namely Nash-portfolio, performs similarly in a ""one game"" test, and is much more robust against an opponent who learns. We also propose an online learning portfolio, which tests several of the GPP repeatedly and progressively switches to the best one - using a bandit algorithm. △ Less","27 July, 2016",https://arxiv.org/pdf/1607.08100
A Model of Pathways to Artificial Superintelligence Catastrophe for Risk and Decision Analysis,Anthony M. Barrett;Seth D. Baum,"An artificial superintelligence (ASI) is artificial intelligence that is significantly more intelligent than humans in all respects. While ASI does not currently exist, some scholars propose that it could be created sometime in the future, and furthermore that its creation could cause a severe global catastrophe, possibly even resulting in human extinction. Given the high stakes, it is important to analyze ASI risk and factor the risk into decisions related to ASI research and development. This paper presents a graphical model of major pathways to ASI catastrophe, focusing on ASI created via recursive self-improvement. The model uses the established risk and decision analysis modeling paradigms of fault trees and influence diagrams in order to depict combinations of events and conditions that could lead to AI catastrophe, as well as intervention options that could decrease risks. The events and conditions include select aspects of the ASI itself as well as the human process of ASI research, development, and management. Model structure is derived from published literature on ASI risk. The model offers a foundation for rigorous quantitative evaluation and decision making on the long-term risk of ASI catastrophe. △ Less","25 July, 2016",https://arxiv.org/pdf/1607.07730
Adaptive Data Communication Interface: A User-Centric Visual Data Interpretation Framework,Grazziela P. Figueredo;Christian Wagner;Jonathan M. Garibaldi;Uwe Aickelin,"In this position paper, we present ideas about creating a next generation framework towards an adaptive interface for data communication and visualisation systems. Our objective is to develop a system that accepts large data sets as inputs and provides user-centric, meaningful visual information to assist owners to make sense of their data collection. The proposed framework comprises four stages: (i) the knowledge base compilation, where we search and collect existing state-ofthe-art visualisation techniques per domain and user preferences; (ii) the development of the learning and inference system, where we apply artificial intelligence techniques to learn, predict and recommend new graphic interpretations (iii) results evaluation; and (iv) reinforcement and adaptation, where valid outputs are stored in our knowledge base and the system is iteratively tuned to address new demands. These stages, as well as our overall vision, limitations and possible challenges are introduced in this article. We also discuss further extensions of this framework for other knowledge discovery tasks. △ Less","20 July, 2016",https://arxiv.org/pdf/1607.05895
Generating Images Part by Part with Composite Generative Adversarial Networks,Hanock Kwak;Byoung-Tak Zhang,"Image generation remains a fundamental problem in artificial intelligence in general and deep learning in specific. The generative adversarial network (GAN) was successful in generating high quality samples of natural images. We propose a model called composite generative adversarial network, that reveals the complex structure of images with multiple generators in which each generator generates some part of the image. Those parts are combined by alpha blending process to create a new single image. It can generate, for example, background and face sequentially with two generators, after training on face dataset. Training was done in an unsupervised way without any labels about what each generator should generate. We found possibilities of learning the structure by using this generative model empirically. △ Less","14 November, 2016",https://arxiv.org/pdf/1607.05387
"Adaptive Artificial Intelligence in Games: Issues, Requirements, and a Solution through Behavlets-based General Player Modelling",Benjamin Ultan Cowley;Darryl Charles,"We present the last of a series of three academic essays which deal with the question of how and why to build a generalized player model. We propose that a general player model needs parameters for subjective experience of play, including: player psychology, game structure, and actions of play. Based on this proposition, we pose three linked research questions: RQ1 what is a necessary and sufficient foundation to a general player model?; RQ2 can such a foundation improve performance of a computational intelligence- based player model?; and RQ3 can such a player model improve efficacy of adaptive artificial intelligence in games? We set out the arguments behind these research questions in each of the three essays, presented as three preprints. The third essay, in this preprint, presents the argument that adaptive game artificial intelligence will be enhanced by a generalised player model. This is because games are inherently human artefacts which therefore, require some encoding of the human perspective in order to effectively autonomously respond to the individual player. The player model informs the necessary constraints on the adaptive artificial intelligence. A generalised player model is not only more efficient than a per-game solution, but also allows comparison between games which makes it a useful tool for studying play in general. We describe the concept and meaning of an adaptive game. We propose requirements for functional adaptive AI, arguing from first principles drawn from the games research literature. We propose solutions to these requirements, based on a formal model approach to our existing 'Behavlets' method for psychologically-derived player modelling: Cowley, B., & Charles, D. (2016). Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modeling and User-Adapted Interaction, 26(2), 257-306. △ Less","19 July, 2016",https://arxiv.org/pdf/1607.05028
Design and implementation of computational platform for social-humanoid robot Lumen as an exhibition guide in Electrical Engineering Days 2015,Ahmad Syarif;Ary Setijadi Prihatmanto,"Social Robot Lumen is an Artificial Intelligence development project that aims to create an Artificial Intelligence (AI) which allows a humanoid robot to communicate with human being naturally. In this study, Lumen will be developed to be a tour guide in Electrical Engineering Days 2015 exhibition. In developing an AI, there are a lot of modules that need to be developed separately. To make the development easier, we need a computational platform which becomes basis for all developers to give easiness in developing the modules in parallel way. That computational platform that developed by the writer is called Lumen Server. Lumen Server has two main function, which are to be a bridge between all Lumen intelligence modules with NAO robot, and to be the communication bridge between those Lumen intelligence modules. For the second function, Lumen Server implements the AMQP protocol using RabbitMQ. Besides that, writer also developed a control system for robot movement called Lumen Motion. Lumen motion is implemented by modelling the movement of NAO robot and also by creating a control system using fuzzy logic controller. Writer also developed a program that connects all Lumen intelligence modules so that Lumen can act like a tour guide. The implementation of this program uses FSM and event-driven program. From implementation result, all the features which were designed are successfully implemented. By the developing of this computational platform, it can ease the development of Lumen in the future. For next development, it must be focused on creating integration system so that Lumen can be more responsive to the environment. ----- Sosial Robot Lumen adalah proyek pengembangan kecerdasan buatan yang bertujuan untuk menciptakan kecerdasan buatan atau artificial intelligence (AI) yang memungkinkan robot untuk dapat berkomunikasi dengan manusia secara alami. △ Less","16 July, 2016",https://arxiv.org/pdf/1607.04763
Resource Planning For Rescue Operations,Mona Khaffaf;Arshia Khaffaf,"After an earthquake, disaster sites pose a multitude of health and safety concerns. A rescue operation of people trapped in the ruins after an earthquake disaster requires a series of intelligent behavior, including planning. For a successful rescue operation, given a limited number of available actions and regulations, the role of planning in rescue operations is crucial. Fortunately, recent developments in automated planning by artificial intelligence community can help different organization in this crucial task. Due to the number of rules and regulations, we believe that a rule based system for planning can be helpful for this specific planning problem. In this research work, we use logic rules to represent rescue and related regular regulations, together with a logic based planner to solve this complicated problem. Although this research is still in the prototyping and modeling stage, it clearly shows that rule based languages can be a good infrastructure for this computational task. The results of this research can be used by different organizations, such as Iranian Red Crescent Society and International Institute of Seismology and Earthquake Engineering (IISEE). △ Less","13 July, 2016",https://arxiv.org/pdf/1607.03979
Automatic Bridge Bidding Using Deep Reinforcement Learning,Chih-Kuan Yeh;Hsuan-Tien Lin,"Bridge is among the zero-sum games for which artificial intelligence has not yet outperformed expert human players. The main difficulty lies in the bidding phase of bridge, which requires cooperative decision making under partial information. Existing artificial intelligence systems for bridge bidding rely on and are thus restricted by human-designed bidding systems or features. In this work, we propose a pioneering bridge bidding system without the aid of human domain knowledge. The system is based on a novel deep reinforcement learning model, which extracts sophisticated features and learns to bid automatically based on raw card data. The model includes an upper-confidence-bound algorithm and additional techniques to achieve a balance between exploration and exploitation. Our experiments validate the promising performance of our proposed model. In particular, the model advances from having no knowledge about bidding to achieving superior performance when compared with a champion-winning computer bridge program that implements a human-designed bidding system. △ Less","12 July, 2016",https://arxiv.org/pdf/1607.03290
Learning opening books in partially observable games: using random seeds in Phantom Go,Tristan Cazenave;Jialin Liu;Fabien Teytaud;Olivier Teytaud,"Many artificial intelligences (AIs) are randomized. One can be lucky or unlucky with the random seed; we quantify this effect and show that, maybe contrarily to intuition, this is far from being negligible. Then, we apply two different existing algorithms for selecting good seeds and good probability distributions over seeds. This mainly leads to learning an opening book. We apply this to Phantom Go, which, as all phantom games, is hard for opening book learning. We improve the winning rate from 50% to 70% in 5x5 against the same AI, and from approximately 0% to 40% in 5x5, 7x7 and 9x9 against a stronger (learning) opponent. △ Less","8 July, 2016",https://arxiv.org/pdf/1607.02431
Analysis of Double Covers of Factor Graphs,Pascal O. Vontobel,"Many quantities of interest in communications, signal processing, artificial intelligence, and other areas can be expressed as the partition sum of some factor graph. Although the exact calculation of the partition sum is in many cases intractable, it can often be approximated rather well by the Bethe partition sum. In earlier work, we have shown that graph covers are a useful tool for expressing and analyzing the Bethe approximation. In this paper, we present a novel technique for analyzing double covers, a technique which ultimately leads to a deeper understanding of the Bethe approximation. △ Less","5 July, 2016",https://arxiv.org/pdf/1607.01124
Visualizing Natural Language Descriptions: A Survey,Kaveh Hassani;Won-Sook Lee,A natural language interface exploits the conceptual simplicity and naturalness of the language to create a high-level user-friendly communication channel between humans and machines. One of the promising applications of such interfaces is generating visual interpretations of semantic content of a given natural language that can be then visualized either as a static scene or a dynamic animation. This survey discusses requirements and challenges of developing such systems and reports 26 graphical systems that exploit natural language interfaces and addresses both artificial intelligence and visualization aspects. This work serves as a frame of reference to researchers and to enable further advances in the field. △ Less,"3 July, 2016",https://arxiv.org/pdf/1607.00623
Performance Based Evaluation of Various Machine Learning Classification Techniques for Chronic Kidney Disease Diagnosis,Sahil Sharma;Vinod Sharma;Atul Sharma,"Areas where Artificial Intelligence (AI) & related fields are finding their applications are increasing day by day, moving from core areas of computer science they are finding their applications in various other domains.In recent times Machine Learning i.e. a sub-domain of AI has been widely used in order to assist medical experts and doctors in the prediction, diagnosis and prognosis of various diseases and other medical disorders. In this manuscript the authors applied various machine learning algorithms to a problem in the domain of medical diagnosis and analyzed their efficiency in predicting the results. The problem selected for the study is the diagnosis of the Chronic Kidney Disease.The dataset used for the study consists of 400 instances and 24 attributes. The authors evaluated 12 classification techniques by applying them to the Chronic Kidney Disease data. In order to calculate efficiency, results of the prediction by candidate methods were compared with the actual medical results of the subject.The various metrics used for performance evaluation are predictive accuracy, precision, sensitivity and specificity. The results indicate that decision-tree performed best with nearly the accuracy of 98.6%, sensitivity of 0.9720, precision of 1 and specificity of 1. △ Less","18 July, 2016",https://arxiv.org/pdf/1606.09581
On the Semantic Relationship between Probabilistic Soft Logic and Markov Logic,Joohyung Lee;Yi Wang,"Markov Logic Networks (MLN) and Probabilistic Soft Logic (PSL) are widely applied formalisms in Statistical Relational Learning, an emerging area in Artificial Intelligence that is concerned with combining logical and statistical AI. Despite their resemblance, the relationship has not been formally stated. In this paper, we describe the precise semantic relationship between them from a logical perspective. This is facilitated by first extending fuzzy logic to allow weights, which can be also viewed as a generalization of PSL, and then relate that generalization to MLN. We observe that the relationship between PSL and MLN is analogous to the known relationship between fuzzy logic and Boolean logic, and furthermore the weight scheme of PSL is essentially a generalization of the weight scheme of MLN for the many-valued setting. △ Less","28 June, 2016",https://arxiv.org/pdf/1606.08896
Can Turing machine be curious about its Turing test results? Three informal lectures on physics of intelligence,Alex Ushveridze,"What is the nature of curiosity? Is there any scientific way to understand the origin of this mysterious force that drives the behavior of even the stupidest naturally intelligent systems and is completely absent in their smartest artificial analogs? Can we build AI systems that could be curious about something, systems that would have an intrinsic motivation to learn? Is such a motivation quantifiable? Is it implementable? I will discuss this problem from the standpoint of physics. The relationship between physics and intelligence is a consequence of the fact that correctly predicted information is nothing but an energy resource, and the process of thinking can be viewed as a process of accumulating and spending this resource through the acts of perception and, respectively, decision making. The natural motivation of any autonomous system to keep this accumulation/spending balance as high as possible allows one to treat the problem of describing the dynamics of thinking processes as a resource optimization problem. Here I will propose and discuss a simple theoretical model of such an autonomous system which I call the Autonomous Turing Machine (ATM). The potential attractiveness of ATM lies in the fact that it is the model of a self-propelled AI for which the only available energy resource is the information itself. For ATM, the problem of optimal thinking, learning, and decision-making becomes conceptually simple and mathematically well tractable. This circumstance makes the ATM an ideal playground for studying the dynamics of intelligent behavior and allows one to quantify many seemingly unquantifiable features of genuine intelligence. △ Less","26 June, 2016",https://arxiv.org/pdf/1606.08109
Building the Web of Knowledge with Smart IoT Applications (Extended Version),Amelie Gyrard;Pankesh Patel;Amit Sheth;Martin Serrano,"The Internet of Things (IoT) is experiencing fast adoption in the society, from industrial to home applications. The number of deployed sensors and connected devices to the Internet is changing our perspective and the way we understand the world. The development and generation of IoT applications is just starting and they will modify our physical and virtual lives, from how we control remotely appliances at home to how we deal with insurance companies in order to start insurance schemes via smart cards. This massive deployment of IoT devices represents a tremendous economic impact and at the same time offers multiple opportunities. However, the potential of IoT is underexploited and day by day this gap between devices and useful applications is getting bigger. Additionally, the physical and cyber worlds are largely disconnected, requiring a lot of manual efforts to integrate, find, and use information in a meaningful way. To build a connection between the physical and the virtual, we need a knowledge framework that allow bilateral understandings, devices producing data, information systems managing the data and applications transforming information into meaningful knowledge. The first column in this series in the previous issue of this magazine titled ""Internet of Things to Smart IoT Through Semantic, Cognitive, and Perceptual Computing,"" reviews IoT growth and potential that have energized research and technology development, centered on aspects of Artificial Intelligence to build future intelligent system. This column steps back and demonstrates the benefits of using semantic web technologies to get meaningful knowledge from sensor data to design smart systems. △ Less","25 June, 2016",https://arxiv.org/pdf/1606.07988
Concrete Problems in AI Safety,Dario Amodei;Chris Olah;Jacob Steinhardt;Paul Christiano;John Schulman;Dan Mané,"Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (""avoiding side effects"" and ""avoiding reward hacking""), an objective function that is too expensive to evaluate frequently (""scalable supervision""), or undesirable behavior during the learning process (""safe exploration"" and ""distributional shift""). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI. △ Less","25 July, 2016",https://arxiv.org/pdf/1606.06565
Knowledge-Defined Networking,Albert Mestres;Alberto Rodriguez-Natal;Josep Carner;Pere Barlet-Ros;Eduard Alarcón;Marc Solé;Victor Muntés;David Meyer;Sharon Barkai;Mike J Hibbett;Giovani Estrada;Khaldun Ma`ruf;Florin Coras;Vina Ermagan;Hugo Latapie;Chris Cassar;John Evans;Fabio Maino;Jean Walrand;Albert Cabellos,"The research community has considered in the past the application of Artificial Intelligence (AI) techniques to control and operate networks. A notable example is the Knowledge Plane proposed by D.Clark et al. However, such techniques have not been extensively prototyped or deployed in the field yet. In this paper, we explore the reasons for the lack of adoption and posit that the rise of two recent paradigms: Software-Defined Networking (SDN) and Network Analytics (NA), will facilitate the adoption of AI techniques in the context of network operation and control. We describe a new paradigm that accommodates and exploits SDN, NA and AI, and provide use cases that illustrate its applicability and benefits. We also present simple experimental results that support its feasibility. We refer to this new paradigm as Knowledge-Defined Networking (KDN). △ Less","23 June, 2016",https://arxiv.org/pdf/1606.06222
A framework for detecting fraudulent activities in edo state tax collection system using investigative data mining,Felix M. Okoro;Emmanuel O. Oshoiribhor;Adetokunbo M. John-Otumu,"The Inland Revenue Services is overwhelmed with gigabyte of disk capacity containing data about tax payers in the state. The data stored on the database increases in size at an alarming rate. This has resulted in a data rich but information poor situation where there is a widening gap between the explosive growth of data and its types, and the ability to analyze and interpret it effectively, hence the need for a new generation of automated and intelligent tools and techniques known as investigative data mining, to look for patterns in data. These patterns can lead to new insights, competitive advantages for business, and tangible benefits for the State Revenue services. This research work focuses on designing effective fraud detection and deterring architecture using investigative data mining technique. The proposed system architecture is designed to reason using Artificial Neural Network and Machine learning algorithm in order to detect and deter fraudulent activities. We recommend that the architectural framework be developed using Object Oriented Programming and Agent Oriented Programming Languages. △ Less","11 June, 2016",https://arxiv.org/pdf/1606.03569
"Towards Anthropo-inspired Computational Systems: the P^3
Model",Michael W. Bridges;Salvatore Distefano;Manuel Mazzara;Marat Minlebaev;Max Talanov;Jordi Vallverdú,"This paper proposes a model which aim is providing a more coherent framework for agents design. We identify three closely related anthropo-centered domains working on separate functional levels. Abstracting from human physiology, psychology, and philosophy we create the P^3 model to be used as a multi-tier approach to deal with complex class of problems. The three layers identified in this model have been named PhysioComputing, MindComputing, and MetaComputing. Several instantiations of this model are finally presented related to different IT areas such as artificial intelligence, distributed computing, software and service engineering. △ Less","10 June, 2016",https://arxiv.org/pdf/1606.03229
The Dark Side of Ethical Robots,Dieter Vanderelst;Alan Winfield,"Concerns over the risks associated with advances in Artificial Intelligence have prompted calls for greater efforts toward robust and beneficial AI, including machine ethics. Recently, roboticists have responded by initiating the development of so-called ethical robots. These robots would, ideally, evaluate the consequences of their actions and morally justify their choices. This emerging field promises to develop extensively over the next years. However, in this paper, we point out an inherent limitation of the emerging field of ethical robots. We show that building ethical robots also necessarily facilitates the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot so that it behaves competitively, or even aggressively. The reason for this is that the specific AI, required to make an ethical robot, can always be exploited to make unethical robots. Hence, the development of ethical robots will not guarantee the responsible deployment of AI. While advocating for ethical robots, we conclude that preventing the misuse of robots is beyond the scope of engineering, and requires instead governance frameworks underpinned by legislation. Without this, the development of ethical robots will serve to increase the risks of robotic malpractice instead of diminishing it. △ Less","8 June, 2016",https://arxiv.org/pdf/1606.02583
Human vs. Computer Go: Review and Prospect,Chang-Shing Lee;Mei-Hui Wang;Shi-Jim Yen;Ting-Han Wei;I-Chen Wu;Ping-Chiang Chou;Chun-Hsun Chou;Ming-Wan Wang;Tai-Hsiung Yang,"The Google DeepMind challenge match in March 2016 was a historic achievement for computer Go development. This article discusses the development of computational intelligence (CI) and its relative strength in comparison with human intelligence for the game of Go. We first summarize the milestones achieved for computer Go from 1998 to 2016. Then, the computer Go programs that have participated in previous IEEE CIS competitions as well as methods and techniques used in AlphaGo are briefly introduced. Commentaries from three high-level professional Go players on the five AlphaGo versus Lee Sedol games are also included. We conclude that AlphaGo beating Lee Sedol is a huge achievement in artificial intelligence (AI) based largely on CI methods. In the future, powerful computer Go programs such as AlphaGo are expected to be instrumental in promoting Go education and AI real-world applications. △ Less","7 June, 2016",https://arxiv.org/pdf/1606.02032
Death and Suicide in Universal Artificial Intelligence,Jarryd Martin;Tom Everitt;Marcus Hutter,"Reinforcement learning (RL) is a general paradigm for studying intelligent behaviour, with applications ranging from artificial intelligence to psychology and economics. AIXI is a universal solution to the RL problem; it can learn any computable environment. A technical subtlety of AIXI is that it is defined using a mixture over semimeasures that need not sum to 1, rather than over proper probability measures. In this work we argue that the shortfall of a semimeasure can naturally be interpreted as the agent's estimate of the probability of its death. We formally define death for generally intelligent agents like AIXI, and prove a number of related theorems about their behaviour. Notable discoveries include that agent behaviour can change radically under positive linear transformations of the reward signal (from suicidal to dogmatically self-preserving), and that the agent's posterior belief that it will survive increases over time. △ Less","2 June, 2016",https://arxiv.org/pdf/1606.00652
On the equivalence between Kolmogorov-Smirnov and ROC curve metrics for binary classification,Paulo J. L. Adeodato;Sílvio B. Melo,"Binary decisions are very common in artificial intelligence. Applying a threshold on the continuous score gives the human decider the power to control the operating point to separate the two classes. The classifier,s discriminating power is measured along the continuous range of the score by the Area Under the ROC curve (AUC_ROC) in most application fields. Only finances uses the poor single point metric maximum Kolmogorov-Smirnov (KS) distance. This paper proposes the Area Under the KS curve (AUC_KS) for performance assessment and proves AUC_ROC = 0.5 + AUC_KS, as a simpler way to calculate the AUC_ROC. That is even more important for ROC averaging in ensembles of classifiers or n fold cross-validation. The proof is geometrically inspired on rotating all KS curve to make it lie on the top of the ROC chance diagonal. On the practical side, the independent variable on the abscissa on the KS curve simplifies the calculation of the AUC_ROC. On the theoretical side, this research gives insights on probabilistic interpretations of classifiers assessment and integrates the existing body of knowledge of the information theoretical ROC approach with the proposed statistical approach based on the thoroughly known KS distribution. △ Less","1 June, 2016",https://arxiv.org/pdf/1606.00496
How to advance general game playing artificial intelligence by player modelling,Benjamin Ultan Cowley,"General game playing artificial intelligence has recently seen important advances due to the various techniques known as 'deep learning'. However the advances conceal equally important limitations in their reliance on: massive data sets; fortuitously constructed problems; and absence of any human-level complexity, including other human opponents. On the other hand, deep learning systems which do beat human champions, such as in Go, do not generalise well. The power of deep learning simultaneously exposes its weakness. Given that deep learning is mostly clever reconfigurations of well-established methods, moving beyond the state of art calls for forward-thinking visionary solutions, not just more of the same. I present the argument that general game playing artificial intelligence will require a generalised player model. This is because games are inherently human artefacts which therefore, as a class of problems, contain cases which require a human-style problem solving approach. I relate this argument to the performance of state of art general game playing agents. I then describe a concept for a formal category theoretic basis to a generalised player model. This formal model approach integrates my existing 'Behavlets' method for psychologically-derived player modelling: Cowley, B., Charles, D. (2016). Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modeling and User-Adapted Interaction, 26(2), 257-306. △ Less","21 June, 2016",https://arxiv.org/pdf/1606.00401
Ruling Out Static Latent Homophily in Citation Networks,Peter Wittek;Sándor Darányi;Gustaf Nelhans,"Citation and coauthor networks offer an insight into the dynamics of scientific progress. We can also view them as representations of a causal structure, a logical process captured in a graph. From a causal perspective, we can ask questions such as whether authors form groups primarily due to their prior shared interest, or if their favourite topics are 'contagious' and spread through co-authorship. Such networks have been widely studied by the artificial intelligence community, and recently a connection has been made to nonlocal correlations produced by entangled particles in quantum physics -- the impact of latent hidden variables can be analyzed by the same algebraic geometric methodology that relies on a sequence of semidefinite programming (SDP) relaxations. Following this trail, we treat our sample coauthor network as a causal graph and, using SDP relaxations, rule out latent homophily as a manifestation of prior shared interest leading to the observed patternedness. By introducing algebraic geometry to citation studies, we add a new tool to existing methods for the analysis of content-related social influences. △ Less","8 December, 2016",https://arxiv.org/pdf/1605.08185
Automatic Extraction of Causal Relations from Natural Language Texts: A Comprehensive Survey,Nabiha Asghar,"Automatic extraction of cause-effect relationships from natural language texts is a challenging open problem in Artificial Intelligence. Most of the early attempts at its solution used manually constructed linguistic and syntactic rules on small and domain-specific data sets. However, with the advent of big data, the availability of affordable computing power and the recent popularization of machine learning, the paradigm to tackle this problem has slowly shifted. Machines are now expected to learn generic causal extraction rules from labelled data with minimal supervision, in a domain independent-manner. In this paper, we provide a comprehensive survey of causal relation extraction techniques from both paradigms, and analyse their relative strengths and weaknesses, with recommendations for future work. △ Less","25 May, 2016",https://arxiv.org/pdf/1605.07895
Learning Purposeful Behaviour in the Absence of Rewards,Marlos C. Machado;Michael Bowling,"Artificial intelligence is commonly defined as the ability to achieve goals in the world. In the reinforcement learning framework, goals are encoded as reward functions that guide agent behaviour, and the sum of observed rewards provide a notion of progress. However, some domains have no such reward signal, or have a reward signal so sparse as to appear absent. Without reward feedback, agent behaviour is typically random, often dithering aimlessly and lacking intentionality. In this paper we present an algorithm capable of learning purposeful behaviour in the absence of rewards. The algorithm proceeds by constructing temporally extended actions (options), through the identification of purposes that are ""just out of reach"" of the agent's current behaviour. These purposes establish intrinsic goals for the agent to learn, ultimately resulting in a suite of behaviours that encourage the agent to visit different parts of the state space. Moreover, the approach is particularly suited for settings where rewards are very sparse, and such behaviours can help in the exploration of the environment until reward is observed. △ Less","24 May, 2016",https://arxiv.org/pdf/1605.07700
Detecting Novel Processes with CANDIES -- An Holistic Novelty Detection Technique based on Probabilistic Models,Christian Gruhl;Bernhard Sick,"In this article, we propose CANDIES (Combined Approach for Novelty Detection in Intelligent Embedded Systems), a new approach to novelty detection in technical systems. We assume that in a technical system several processes interact. If we observe these processes with sensors, we are able to model the observations (samples) with a probabilistic model, where, in an ideal case, the components of the parametric mixture density model we use, correspond to the processes in the real world. Eventually, at run-time, novel processes emerge in the technical systems such as in the case of an unpredictable failure. As a consequence, new kinds of samples are observed that require an adaptation of the model. CANDIES relies on mixtures of Gaussians which can be used for classification purposes, too. New processes may emerge in regions of the models' input spaces where few samples were observed before (low-density regions) or in regions where already many samples were available (high-density regions). The latter case is more difficult, but most existing solutions focus on the former. Novelty detection in low- and high-density regions requires different detection strategies. With CANDIES, we introduce a new technique to detect novel processes in high-density regions by means of a fast online goodness-of-fit test. For detection in low-density regions we combine this approach with a 2SND (Two-Stage-Novelty-Detector) which we presented in preliminary work. The properties of CANDIES are evaluated using artificial data and benchmark data from the field of intrusion detection in computer networks, where the task is to detect new kinds of attacks. △ Less","18 May, 2016",https://arxiv.org/pdf/1605.05628
A New Method for Parallel Monte Carlo Tree Search,S. Ali Mirsoleimani;Aske Plaat;Jaap van den Herik;Jos Vermaseren,"In recent years there has been much interest in the Monte Carlo tree search algorithm, a new, adaptive, randomized optimization algorithm. In fields as diverse as Artificial Intelligence, Operations Research, and High Energy Physics, research has established that Monte Carlo tree search can find good solutions without domain dependent heuristics. However, practice shows that reaching high performance on large parallel machines is not so successful as expected. This paper proposes a new method for parallel Monte Carlo tree search based on the pipeline computation pattern. △ Less","14 May, 2016",https://arxiv.org/pdf/1605.04447
Consciousness is Pattern Recognition,Ray Van De Walker,"This is a proof of the strong AI hypothesis, i.e. that machines can be conscious. It is a phenomenological proof that pattern-recognition and subjective consciousness are the same activity in different terms. Therefore, it proves that essential subjective processes of consciousness are computable, and identifies significant traits and requirements of a conscious system. Since Husserl, many philosophers have accepted that consciousness consists of memories of logical connections between an ego and external objects. These connections are called ""intentions."" Pattern recognition systems are achievable technical artifacts. The proof links this respected introspective philosophical theory of consciousness with technical art. The proof therefore endorses the strong AI hypothesis and may therefore also enable a theoretically-grounded form of artificial intelligence called a ""synthetic intentionality,"" able to synthesize, generalize, select and repeat intentions. If the pattern recognition is reflexive, able to operate on the set of intentions, and flexible, with several methods of synthesizing intentions, an SI may be a particularly strong form of AI. Similarities and possible applications to several AI paradigms are discussed. The article then addresses some problems: The proof's limitations, reflexive cognition, Searles' Chinese room, and how an SI could ""understand"" ""meanings"" and ""be creative."" △ Less","28 June, 2016",https://arxiv.org/pdf/1605.03009
Unethical Research: How to Create a Malevolent Artificial Intelligence,Federico Pistono;Roman V. Yampolskiy,"Cybersecurity research involves publishing papers about malicious exploits as much as publishing information on how to design tools to protect cyber-infrastructure. It is this information exchange between ethical hackers and security experts, which results in a well-balanced cyber-ecosystem. In the blooming domain of AI Safety Engineering, hundreds of papers have been published on different proposals geared at the creation of a safe machine, yet nothing, to our knowledge, has been published on how to design a malevolent machine. Availability of such information would be of great value particularly to computer scientists, mathematicians, and others who have an interest in AI safety, and who are attempting to avoid the spontaneous emergence or the deliberate creation of a dangerous AI, which can negatively affect human activities and in the worst case cause the complete obliteration of the human species. This paper provides some general guidelines for the creation of a Malevolent Artificial Intelligence (MAI). △ Less","1 September, 2016",https://arxiv.org/pdf/1605.02817
A Self-Taught Artificial Agent for Multi-Physics Computational Model Personalization,Dominik Neumann;Tommaso Mansi;Lucian Itu;Bogdan Georgescu;Elham Kayvanpour;Farbod Sedaghat-Hamedani;Ali Amr;Jan Haas;Hugo Katus;Benjamin Meder;Stefan Steidl;Joachim Hornegger;Dorin Comaniciu,"Personalization is the process of fitting a model to patient data, a critical step towards application of multi-physics computational models in clinical practice. Designing robust personalization algorithms is often a tedious, time-consuming, model- and data-specific process. We propose to use artificial intelligence concepts to learn this task, inspired by how human experts manually perform it. The problem is reformulated in terms of reinforcement learning. In an off-line phase, Vito, our self-taught artificial agent, learns a representative decision process model through exploration of the computational model: it learns how the model behaves under change of parameters. The agent then automatically learns an optimal strategy for on-line personalization. The algorithm is model-independent; applying it to a new model requires only adjusting few hyper-parameters of the agent and defining the observations to match. The full knowledge of the model itself is not required. Vito was tested in a synthetic scenario, showing that it could learn how to optimize cost functions generically. Then Vito was applied to the inverse problem of cardiac electrophysiology and the personalization of a whole-body circulation model. The obtained results suggested that Vito could achieve equivalent, if not better goodness of fit than standard methods, while being more robust (up to 11% higher success rates) and with faster (up to seven times) convergence rate. Our artificial intelligence approach could thus make personalization algorithms generalizable and self-adaptable to any patient and any model. △ Less","1 May, 2016",https://arxiv.org/pdf/1605.00303
Teaching natural language to computers,Joseph Corneli;Miriam Corneli,"""Natural Language,"" whether spoken and attended to by humans, or processed and generated by computers, requires networked structures that reflect creative processes in semantic, syntactic, phonetic, linguistic, social, emotional, and cultural modules. Being able to produce novel and useful behavior following repeated practice gets to the root of both artificial intelligence and human language. This paper investigates the modalities involved in language-like applications that computers -- and programmers -- engage with, and aims to fine tune the questions we ask to better account for context, self-awareness, and embodiment. △ Less","28 June, 2016",https://arxiv.org/pdf/1604.08781
Propositional Abduction with Implicit Hitting Sets,Alexey Ignatiev;Antonio Morgado;Joao Marques-Silva,"Logic-based abduction finds important applications in artificial intelligence and related areas. One application example is in finding explanations for observed phenomena. Propositional abduction is a restriction of abduction to the propositional domain, and complexity-wise is in the second level of the polynomial hierarchy. Recent work has shown that exploiting implicit hitting sets and propositional satisfiability (SAT) solvers provides an efficient approach for propositional abduction. This paper investigates this earlier work and proposes a number of algorithmic improvements. These improvements are shown to yield exponential reductions in the number of SAT solver calls. More importantly, the experimental results show significant performance improvements compared to the the best approaches for propositional abduction. △ Less","27 April, 2016",https://arxiv.org/pdf/1604.08229
Procedural Generation of Angry Birds Levels using Building Constructive Grammar with Chinese-Style and/or Japanese-Style Models,YuXuan Jiang;Misaki Kaidan;Chun Yin Chu;Tomohiro Harada;Ruck Thawonmas,"This paper presents a procedural generation method that creates visually attractive levels for the Angry Birds game. Besides being an immensely popular mobile game, Angry Birds has recently become a test bed for various artificial intelligence technologies. We propose a new approach for procedurally generating Angry Birds levels using Chinese style and Japanese style building structures. A conducted experiment confirms the effectiveness of our approach with statistical significance. △ Less","26 April, 2016",https://arxiv.org/pdf/1604.07906
Limits to Verification and Validation of Agentic Behavior,David J. Jilk,"Verification and validation of agentic behavior have been suggested as important research priorities in efforts to reduce risks associated with the creation of general artificial intelligence (Russell et al 2015). In this paper we question the appropriateness of using language of certainty with respect to efforts to manage that risk. We begin by establishing a very general formalism to characterize agentic behavior and to describe standards of acceptable behavior. We show that determination of whether an agent meets any particular standard is not computable. We discuss the extent of the burden associated with verification by manual proof and by automated behavioral governance. We show that to ensure decidability of the behavioral standard itself, one must further limit the capabilities of the agent. We then demonstrate that if our concerns relate to outcomes in the physical world, attempts at validation are futile. Finally, we show that layered architectures aimed at making these challenges tractable mistakenly equate intentions with actions or outcomes, thereby failing to provide any guarantees. We conclude with a discussion of why language of certainty should be eradicated from the conversation about the safety of general artificial intelligence. △ Less","10 October, 2016",https://arxiv.org/pdf/1604.06963
Memory shapes time perception and intertemporal choices,Pedro A. Ortega;Naftali Tishby,"There is a consensus that human and non-human subjects experience temporal distortions in many stages of their perceptual and decision-making systems. Similarly, intertemporal choice research has shown that decision-makers undervalue future outcomes relative to immediate ones. Here we combine techniques from information theory and artificial intelligence to show how both temporal distortions and intertemporal choice preferences can be explained as a consequence of the coding efficiency of sensorimotor representation. In particular, the model implies that interactions that constrain future behavior are perceived as being both longer in duration and more valuable. Furthermore, using simulations of artificial agents, we investigate how memory constraints enforce a renormalization of the perceived timescales. Our results show that qualitatively different discount functions, such as exponential and hyperbolic discounting, arise as a consequence of an agent's probabilistic model of the world. △ Less","29 May, 2016",https://arxiv.org/pdf/1604.05129
An artificial intelligence tool for heterogeneous team formation in the classroom,Juan M. Alberola;Elena Del Val;Victor Sanchez-Anguix;Alberto Palomares;Maria Dolores Teruel,"Nowadays, there is increasing interest in the development of teamwork skills in the educational context. This growing interest is motivated by its pedagogical effectiveness and the fact that, in labour contexts, enterprises organize their employees in teams to carry out complex projects. Despite its crucial importance in the classroom and industry, there is a lack of support for the team formation process. Not only do many factors influence team performance, but the problem becomes exponentially costly if teams are to be optimized. In this article, we propose a tool whose aim it is to cover such a gap. It combines artificial intelligence techniques such as coalition structure generation, Bayesian learning, and Belbin's role theory to facilitate the generation of working groups in an educational context. This tool improves current state of the art proposals in three ways: i) it takes into account the feedback of other teammates in order to establish the most predominant role of a student instead of self-perception questionnaires; ii) it handles uncertainty with regard to each student's predominant team role; iii) it is iterative since it considers information from several interactions in order to improve the estimation of role assignments. We tested the performance of the proposed tool in an experiment involving students that took part in three different team activities. The experiments suggest that the proposed tool is able to improve different teamwork aspects such as team dynamics and student satisfaction. △ Less","16 April, 2016",https://arxiv.org/pdf/1604.04721
Why Artificial Intelligence Needs a Task Theory --- And What It Might Look Like,Kristinn R. Thórisson;Jordi Bieger;Thröstur Thorarensen;Jóna S. Sigurðardóttir;Bas R. Steunebrink,"The concept of ""task"" is at the core of artificial intelligence (AI): Tasks are used for training and evaluating AI systems, which are built in order to perform and automatize tasks we deem useful. In other fields of engineering theoretical foundations allow thorough evaluation of designs by methodical manipulation of well understood parameters with a known role and importance; this allows an aeronautics engineer, for instance, to systematically assess the effects of wind speed on an airplane's performance and stability. No framework exists in AI that allows this kind of methodical manipulation: Performance results on the few tasks in current use (cf. board games, question-answering) cannot be easily compared, however similar or different. The issue is even more acute with respect to artificial *general* intelligence systems, which must handle unanticipated tasks whose specifics cannot be known beforehand. A *task theory* would enable addressing tasks at the *class* level, bypassing their specifics, providing the appropriate formalization and classification of tasks, environments, and their parameters, resulting in more rigorous ways of measuring, comparing, and evaluating intelligent behavior. Even modest improvements in this direction would surpass the current ad-hoc nature of machine learning and AI evaluation. Here we discuss the main elements of the argument for a task theory and present an outline of what it might look like for physical tasks. △ Less","12 May, 2016",https://arxiv.org/pdf/1604.04660
The STRANDS Project: Long-Term Autonomy in Everyday Environments,Nick Hawes;Chris Burbridge;Ferdian Jovan;Lars Kunze;Bruno Lacerda;Lenka Mudrová;Jay Young;Jeremy Wyatt;Denise Hebesberger;Tobias Körtner;Rares Ambrus;Nils Bore;John Folkesson;Patric Jensfelt;Lucas Beyer;Alexander Hermans;Bastian Leibe;Aitor Aldoma;Thomas Fäulhammer;Michael Zillich;Markus Vincze;Eris Chinellato;Muhannad Al-Omari;Paul Duckworth;Yiannis Gatsoulis,"Thanks to the efforts of the robotics and autonomous systems community, robots are becoming ever more capable. There is also an increasing demand from end-users for autonomous service robots that can operate in real environments for extended periods. In the STRANDS project we are tackling this demand head-on by integrating state-of-the-art artificial intelligence and robotics research into mobile service robots, and deploying these systems for long-term installations in security and care environments. Over four deployments, our robots have been operational for a combined duration of 104 days autonomously performing end-user defined tasks, covering 116km in the process. In this article we describe the approach we have used to enable long-term autonomous operation in everyday environments, and how our robots are able to use their long run times to improve their own performance. △ Less","14 October, 2016",https://arxiv.org/pdf/1604.04384
Visual Storytelling,Ting-Hao;Huang;Francis Ferraro;Nasrin Mostafazadeh;Ishan Misra;Aishwarya Agrawal;Jacob Devlin;Ross Girshick;Xiaodong He;Pushmeet Kohli;Dhruv Batra;C. Lawrence Zitnick;Devi Parikh;Lucy Vanderwende;Michel Galley;Margaret Mitchell,"We introduce the first dataset for sequential vision-to-language, and explore how this data may be used for the task of visual storytelling. The first release of this dataset, SIND v.1, includes 81,743 unique photos in 20,211 sequences, aligned to both descriptive (caption) and story language. We establish several strong baselines for the storytelling task, and motivate an automatic metric to benchmark progress. Modelling concrete description as well as figurative and social language, as provided in this dataset and the storytelling task, has the potential to move artificial intelligence from basic understandings of typical visual scenes towards more and more human-like understanding of grounded event structure and subjective expression. △ Less","13 April, 2016",https://arxiv.org/pdf/1604.03968
"Patterns on data described by vague limits, vague colimits and vague commutativity",Carlos Leandro;Luís Monteiro,"The development of machine learning in particular and artificial intelligent in general has been strongly conditioned by the lack of an appropriated framework to specify and integrate learning processes, data transformation processes and data models. In this work we extend traditional algebraic specification methods to this type of framework. Limits and colimits of diagrams are universal constructions fundamental in different mathematical domains importance in semantic modeling. The aim of our work is to study the possibility of extending these algebraic frameworks to the specification of vague structures and to the description of vague patterns on data. △ Less","11 April, 2016",https://arxiv.org/pdf/1604.03098
Knowledge Extraction and Knowledge Integration governed by Łukasiewicz Logics,Carlos Leandro,"The development of machine learning in particular and artificial intelligent in general has been strongly conditioned by the lack of an appropriate interface layer between deduction, abduction and induction. In this work we extend traditional algebraic specification methods in this direction. Here we assume that such interface for AI emerges from an adequate Neural-Symbolic integration. This integration is made for universe of discourse described on a Topos governed by a many-valued Łukasiewicz logic. Sentences are integrated in a symbolic knowledge base describing the problem domain, codified using a graphic-based language, wherein every logic connective is defined by a neuron in an artificial network. This allows the integration of first-order formulas into a network architecture as background knowledge, and simplifies symbolic rule extraction from trained networks. For the train of such neural networks we changed the Levenderg-Marquardt algorithm, restricting the knowledge dissemination in the network structure using soft crystallization. This procedure reduces neural network plasticity without drastically damaging the learning performance, allowing the emergence of symbolic patterns. This makes the descriptive power of produced neural networks similar to the descriptive power of Łukasiewicz logic language, reducing the information lost on translation between symbolic and connectionist structures. We tested this method on the extraction of knowledge from specified structures. For it, we present the notion of fuzzy state automata, and we use automata behaviour to infer its structure. We use this type of automata on the generation of models for relations specified as symbolic background knowledge. △ Less","10 April, 2016",https://arxiv.org/pdf/1604.02780
A Review of Theoretical and Practical Challenges of Trusted Autonomy in Big Data,Hussein A. Abbass;George Leu;Kathryn Merrick,"Despite the advances made in artificial intelligence, software agents, and robotics, there is little we see today that we can truly call a fully autonomous system. We conjecture that the main inhibitor for advancing autonomy is lack of trust. Trusted autonomy is the scientific and engineering field to establish the foundations and ground work for developing trusted autonomous systems (robotics and software agents) that can be used in our daily life, and can be integrated with humans seamlessly, naturally and efficiently. In this paper, we review this literature to reveal opportunities for researchers and practitioners to work on topics that can create a leap forward in advancing the field of trusted autonomy. We focus the paper on the `trust' component as the uniting technology between humans and machines. Our inquiry into this topic revolves around three sub-topics: (1) reviewing and positioning the trust modelling literature for the purpose of trusted autonomy; (2) reviewing a critical subset of sensor technologies that allow a machine to sense human states; and (3) distilling some critical questions for advancing the field of trusted autonomy. The inquiry is augmented with conceptual models that we propose along the way by recompiling and reshaping the literature into forms that enables trusted autonomous systems to become a reality. The paper offers a vision for a Trusted Cyborg Swarm, an extension of our previous Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in a harmonious, seamless, and coordinated manner. △ Less","16 March, 2016",https://arxiv.org/pdf/1604.00921
An electronic-game framework for evaluating coevolutionary algorithms,Karine da Silva Miras de Araújo;Fabrício Olivetti de França,"One of the common artificial intelligence applications in electronic games consists of making an artificial agent learn how to execute some determined task successfully in a game environment. One way to perform this task is through machine learning algorithms capable of learning the sequence of actions required to win in a given game environment. There are several supervised learning techniques able to learn the correct answer for a problem through examples. However, when learning how to play electronic games, the correct answer might only be known by the end of the game, after all the actions were already taken. Thus, not being possible to measure the accuracy of each individual action to be taken at each time step. A way for dealing with this problem is through Neuroevolution, a method which trains Artificial Neural Networks using evolutionary algorithms. In this article, we introduce a framework for testing optimization algorithms with artificial agent controllers in electronic games, called EvoMan, which is inspired in the action-platformer game Mega Man II. The environment can be configured to run in different experiment modes, as single evolution, coevolution and others. To demonstrate some challenges regarding the proposed platform, as initial experiments we applied Neuroevolution using Genetic Algorithms and the NEAT algorithm, in the context of competitively coevolving two distinct agents in this game. △ Less","11 April, 2016",https://arxiv.org/pdf/1604.00644
Building Machines That Learn and Think Like People,Brenden M. Lake;Tomer D. Ullman;Joshua B. Tenenbaum;Samuel J. Gershman,"Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models. △ Less","2 November, 2016",https://arxiv.org/pdf/1604.00289
Greedy Strategies and Larger Islands of Tractability for Conjunctive Queries and Constraint Satisfaction Problems,Gianluigi Greco;Francesco Scarcello,"Structural decomposition methods have been developed for identifying tractable classes of instances of fundamental problems in databases, such as conjunctive queries and query containment, of the constraint satisfaction problem in artificial intelligence, or more generally of the homomorphism problem over relational structures. Most structural decomposition methods can be characterized through hypergraph games that are variations of the Robber and Cops graph game that characterizes the notion of treewidth. In particular, decomposition trees somehow correspond to monotone winning strategies, where the escape space of the robber on the hypergraph is shrunk monotonically by the cops. In fact, unlike the treewidth case, there are hypergraphs where monotonic strategies do not exist, while the robber can be captured by means of more complex non-monotonic strategies. However, these powerful strategies do not correspond in general to valid decompositions. The paper provides a general way to exploit the power of non-monotonic strategies, by allowing a ""disciplined"" form of non-monotonicity, characteristic of cops playing in a greedy way. It is shown that deciding the existence of a (non-monotone) greedy winning strategy (and compute one, if any) is tractable. Moreover, despite their non-monotonicity, such strategies always induce valid decomposition trees, which can be computed efficiently based on them. As a consequence, greedy strategies allow us to define new islands of tractability for the considered problems properly including all previously known classes of tractable instances. △ Less","4 July, 2016",https://arxiv.org/pdf/1603.09617
Utility of a Behavlets approach to a Decision theoretic predictive player model,Benjamin Ultan Cowley;Darryl Charles,"We present the second in a series of three academic essays which deal with the question of how to build a generalized player model. We begin with a proposition: a general model of players requires parameters for the subjective experience of play, including at least three areas: a) player psychology, b) game structure, and c) actions of play. Based on this proposition, we pose three linked research questions, which make incomplete progress toward a generalized player model: RQ1 what is a necessary and sufficient foundation to a general player model?; RQ2 can such a foundation improve performance of a computational intelligence-based player model?; and RQ3 can such a player model improve efficacy of adaptive artificial intelligence in games? We set out the arguments for each research question in each of the three essays, presented as three preprints. The second essay, in this preprint, illustrates how our 'Behavlets' method can improve the performance and accuracy of a predictive player model in the well-known Pac-Man game, by providing a simple foundation for areas a) to c) above. We then propose a plan for future work to address RQ2 by conclusively testing the Behavlets approach. This plan builds on the work proposed in the first preprint essay to address RQ1, and in turn provides support for work on RQ3. The Behavlets approach was described previously; therefore if citing this work please use the correct citation: Cowley B, Charles D. Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modelling and User-Adapted Interaction. 2016 Feb 8; online (Special Issue on Personality in Personalized Systems):1-50. △ Less","19 July, 2016",https://arxiv.org/pdf/1603.08973
Niépce-Bell or Turing: How to Test Odor Reproduction?,David Harel,"In a 1950 article in Mind, decades before the existence of anything resembling an artificial intelligence system, Alan Turing addressed the question of how to test whether machines can think, or in modern terminology, whether a computer claimed to exhibit intelligence indeed does so. The current paper raises the analogous issue for olfaction: how to test the validity of a system claimed to reproduce arbitrary odors artificially, in a way recognizable to humans, in face of the unavailability of a general naming method for odors. Although odor reproduction systems are still far from being viable, the question of how to test candidates thereof is claimed to be interesting and nontrivial, and a novel method is proposed. To some extent, the method is inspired by Turing`s test for AI, in that it involves a human challenger and the real and artificial entities, yet it is very different: our test is conditional, requiring from the artificial no more than is required from the original, and it employs a novel method of immersion that takes advantage of the availability of near-perfect reproduction methods for sight and sound. △ Less","10 November, 2016",https://arxiv.org/pdf/1603.08666
Probabilistic Reasoning via Deep Learning: Neural Association Models,Quan Liu;Hui Jiang;Andrew Evdokimov;Zhen-Hua Ling;Xiaodan Zhu;Si Wei;Yu Hu,"In this paper, we propose a new deep learning approach, called neural association model (NAM), for probabilistic reasoning in artificial intelligence. We propose to use neural networks to model association between any two events in a domain. Neural networks take one event as input and compute a conditional probability of the other event to model how likely these two events are to be associated. The actual meaning of the conditional probabilities varies between applications and depends on how the models are trained. In this work, as two case studies, we have investigated two NAM structures, namely deep neural networks (DNN) and relation-modulated neural nets (RMNN), on several probabilistic reasoning tasks in AI, including recognizing textual entailment, triple classification in multi-relational knowledge bases and commonsense reasoning. Experimental results on several popular datasets derived from WordNet, FreeBase and ConceptNet have all demonstrated that both DNNs and RMNNs perform equally well and they can significantly outperform the conventional methods available for these reasoning tasks. Moreover, compared with DNNs, RMNNs are superior in knowledge transfer, where a pre-trained model can be quickly extended to an unseen relation after observing only a few training samples. To further prove the effectiveness of the proposed models, in this work, we have applied NAMs to solving challenging Winograd Schema (WS) problems. Experiments conducted on a set of WS problems prove that the proposed models have the potential for commonsense reasoning. △ Less","3 August, 2016",https://arxiv.org/pdf/1603.07704
A Tutorial on Deep Neural Networks for Intelligent Systems,Juan C. Cuevas-Tello;Manuel Valenzuela-Rendon;Juan A. Nolazco-Flores,"Developing Intelligent Systems involves artificial intelligence approaches including artificial neural networks. Here, we present a tutorial of Deep Neural Networks (DNNs), and some insights about the origin of the term ""deep""; references to deep learning are also given. Restricted Boltzmann Machines, which are the core of DNNs, are discussed in detail. An example of a simple two-layer network, performing unsupervised learning for unlabeled data, is shown. Deep Belief Networks (DBNs), which are used to build networks with more than two layers, are also described. Moreover, examples for supervised learning with DNNs performing simple prediction and classification tasks, are presented and explained. This tutorial includes two intelligent pattern recognition applications: hand- written digits (benchmark known as MNIST) and speech recognition. △ Less","23 March, 2016",https://arxiv.org/pdf/1603.07249
Short Literature Review for a General Player Model Based on Behavlets,Benjamin Ultan Cowley;Darryl Charles,"We present the first in a series of three academic essays which deal with the question of how to build a generalized player model. We begin with a proposition: a general model of players requires parameters for the subjective experience of play, including at least: player psychology, game structure, and actions of play. Based on this proposition, we pose three linked research questions, which make incomplete progress toward a generalised player model: RQ1 what is a necessary and sufficient foundation to a general player model?; RQ2 can such a foundation improve performance of a computational intelligence-based player model?; and RQ3 can such a player model improve efficacy of adaptive artificial intelligence in games? We set out the arguments behind these research questions in each of the three essays, presented as three preprints. The first essay, in this preprint, reviews the literature for the core foundations for a general player model. We then propose a plan for future work to systematically extend the review and thus provide an empirical answer to RQ1 above. This work will directly support the proposed approach to address RQ2 and RQ3 above. This review was developed to support our 'Behavlets' approach to player modelling; therefore if citing this work, please use the relevant citation: Cowley B, Charles D. Behavlets: a Method for Practical Player Modelling using Psychology-Based Player Traits and Domain Specific Features. User Modelling and User-Adapted Interaction. 2016 Feb 8; online (Special Issue on Personality in Personalized Systems):1-50. △ Less","19 July, 2016",https://arxiv.org/pdf/1603.06996
Image Captioning with Semantic Attention,Quanzeng You;Hailin Jin;Zhaowen Wang;Chen Fang;Jiebo Luo,"Automatically generating a natural language description of an image has attracted interests recently both because of its importance in practical applications and because it connects two major artificial intelligence fields: computer vision and natural language processing. Existing approaches are either top-down, which start from a gist of an image and convert it into words, or bottom-up, which come up with words describing various aspects of an image and then combine them. In this paper, we propose a new algorithm that combines both approaches through a model of semantic attention. Our algorithm learns to selectively attend to semantic concept proposals and fuse them into hidden states and outputs of recurrent neural networks. The selection and fusion form a feedback connecting the top-down and bottom-up computation. We evaluate our algorithm on two public benchmarks: Microsoft COCO and Flickr30K. Experimental results show that our algorithm significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics. △ Less","12 March, 2016",https://arxiv.org/pdf/1603.03925
Revisiting Active Perception,Ruzena Bajcsy;Yiannis Aloimonos;John K. Tsotsos,"Despite the recent successes in robotics, artificial intelligence and computer vision, a complete artificial agent necessarily must include active perception. A multitude of ideas and methods for how to accomplish this have already appeared in the past, their broader utility perhaps impeded by insufficient computational power or costly hardware. The history of these ideas, perhaps selective due to our perspectives, is presented with the goal of organizing the past literature and highlighting the seminal contributions. We argue that those contributions are as relevant today as they were decades ago and, with the state of modern computational tools, are poised to find new life in the robotic perception systems of the next decade. △ Less","13 March, 2016",https://arxiv.org/pdf/1603.02729
"Model-Based Testing, Using Belief-Desire-Intentions Agents, of Control Code for Robots in Collaborative Human-Robot Interactions",Dejanira Araiza-Illan;Tony Pipe;Kerstin Eder,"The software of robotic assistants needs to be verified, to ensure its safety and functional correctness. Testing in simulation allows a high degree of realism in the verification. However, generating tests that cover both interesting foreseen and unforeseen scenarios in human-robot interaction (HRI) tasks, while executing most of the code, remains a challenge. We propose the use of belief-desire-intention (BDI) agents in the test environment, to increase the level of realism and human-like stimulation of simulated robots. Artificial intelligence, such as agent theory, can be exploited for more intelligent test generation. An automated testbench was implemented for a simulation in Robot Operating System (ROS) and Gazebo, of a cooperative table assembly task between a humanoid robot and a person. Requirements were verified for this task, and some unexpected design issues were discovered, leading to possible code improvements. Our results highlight the practicality of BDI agents to automatically generate valid and human-like tests to get high code coverage, compared to hand-written directed tests, pseudorandom generation, and other variants of model-based test generation. Also, BDI agents allow the coverage of combined behaviours of the HRI system with more ease than writing temporal logic properties for model checking. △ Less","2 March, 2016",https://arxiv.org/pdf/1603.00656
Harnessing disordered quantum dynamics for machine learning,Keisuke Fujii;Kohei Nakajima,"Quantum computer has an amazing potential of fast information processing. However, realisation of a digital quantum computer is still a challenging problem requiring highly accurate controls and key application strategies. Here we propose a novel platform, quantum reservoir computing, to solve these issues successfully by exploiting natural quantum dynamics, which is ubiquitous in laboratories nowadays, for machine learning. In this framework, nonlinear dynamics including classical chaos can be universally emulated in quantum systems. A number of numerical experiments show that quantum systems consisting of at most seven qubits possess computational capabilities comparable to conventional recurrent neural networks of 500 nodes. This discovery opens up a new paradigm for information processing with artificial intelligence powered by quantum physics. △ Less","9 November, 2016",https://arxiv.org/pdf/1602.08159
Meta-learning within Projective Simulation,Adi Makmal;Alexey A. Melnikov;Vedran Dunjko;Hans J. Briegel,"Learning models of artificial intelligence can nowadays perform very well on a large variety of tasks. However, in practice different task environments are best handled by different learning models, rather than a single, universal, approach. Most non-trivial models thus require the adjustment of several to many learning parameters, which is often done on a case-by-case basis by an external party. Meta-learning refers to the ability of an agent to autonomously and dynamically adjust its own learning parameters, or meta-parameters. In this work we show how projective simulation, a recently developed model of artificial intelligence, can naturally be extended to account for meta-learning in reinforcement learning settings. The projective simulation approach is based on a random walk process over a network of clips. The suggested meta-learning scheme builds upon the same design and employs clip networks to monitor the agent's performance and to adjust its meta-parameters ""on the fly"". We distinguish between ""reflexive adaptation"" and ""adaptation through learning"", and show the utility of both approaches. In addition, a trade-off between flexibility and learning-time is addressed. The extended model is examined on three different kinds of reinforcement learning tasks, in which the agent has different optimal values of the meta-parameters, and is shown to perform well, reaching near-optimal to optimal success rates in all of them, without ever needing to manually adjust any meta-parameter. △ Less","25 February, 2016",https://arxiv.org/pdf/1602.08017
Philosophical Fictionalism and Problem of Artificial Intelligence,Sergey B. Kulikov,"The artificial intelligence received broad interpretation as a literary image. This approach did not have unambiguous refering to the scopes of logical studies and mathematical investigations. An author applied methods peculiar to the semiotic approach, offered by Boris Uspensky and Yury Lotman. In addition, the article presented the criticism of modern versions of educational technologies, which led to the unconditional expectations for possibilities of information and telecommunication technologies. Methodological culture's growth, which was described on the base of semiotics and functional approach to word formation of new meanings for the description of the studied subjects, provided the development of pupils' thought. As a result, the research opened new prospects on understanding of artificial intelligence within educational practice. △ Less","23 February, 2016",https://arxiv.org/pdf/1602.07259
Computational Narrative Intelligence: A Human-Centered Goal for Artificial Intelligence,Mark O. Riedl,"Narrative intelligence is the ability to craft, tell, understand, and respond affectively to stories. We argue that instilling artificial intelligences with computational narrative intelligence affords a number of applications beneficial to humans. We lay out some of the machine learning challenges necessary to solve to achieve computational narrative intelligence. Finally, we argue that computational narrative is a practical step towards machine enculturation, the teaching of sociocultural values to machines. △ Less","20 February, 2016",https://arxiv.org/pdf/1602.06484
The Singularity May Never Be Near,Toby Walsh,"There is both much optimism and pessimism around artificial intelligence (AI) today. The optimists are investing millions of dollars, and even in some cases billions of dollars into AI. The pessimists, on the other hand, predict that AI will end many things: jobs, warfare, and even the human race. Both the optimists and the pessimists often appeal to the idea of a technological singularity, a point in time where machine intelligence starts to run away, and a new, more intelligent species starts to inhabit the earth. If the optimists are right, this will be a moment that fundamentally changes our economy and our society. If the pessimists are right, this will be a moment that also fundamentally changes our economy and our society. It is therefore very worthwhile spending some time deciding if either of them might be right. △ Less","20 February, 2016",https://arxiv.org/pdf/1602.06462
Reinforcement Learning approach for Real Time Strategy Games Battle city and S3,Harshit Sethy;Amit Patel,"In this paper we proposed reinforcement learning algorithms with the generalized reward function. In our proposed method we use Q-learning and SARSA algorithms with generalised reward function to train the reinforcement learning agent. We evaluated the performance of our proposed algorithms on two real-time strategy games called BattleCity and S3. There are two main advantages of having such an approach as compared to other works in RTS. (1) We can ignore the concept of a simulator which is often game specific and is usually hard coded in any type of RTS games (2) our system can learn from interaction with any opponents and quickly change the strategy according to the opponents and do not need any human traces as used in previous works. Keywords : Reinforcement learning, Machine learning, Real time strategy, Artificial intelligence. △ Less","16 February, 2016",https://arxiv.org/pdf/1602.04936
Designing Intelligent Instruments,Kevin H. Knuth;Philip M. Erner;Scott Frasso,"Remote science operations require automated systems that can both act and react with minimal human intervention. One such vision is that of an intelligent instrument that collects data in an automated fashion, and based on what it learns, decides which new measurements to take. This innovation implements experimental design and unites it with data analysis in such a way that it completes the cycle of learning. This cycle is the basis of the Scientific Method. The three basic steps of this cycle are hypothesis generation, inquiry, and inference. Hypothesis generation is implemented by artificially supplying the instrument with a parameterized set of possible hypotheses that might be used to describe the physical system. The act of inquiry is handled by an inquiry engine that relies on Bayesian adaptive exploration where the optimal experiment is chosen as the one which maximizes the expected information gain. The inference engine is implemented using the nested sampling algorithm, which provides the inquiry engine with a set of posterior samples from which the expected information gain can be estimated. With these computational structures in place, the instrument will refine its hypotheses, and repeat the learning cycle by taking measurements until the system under study is described within a pre-specified tolerance. We will demonstrate our first attempts toward achieving this goal with an intelligent instrument constructed using the LEGO MINDSTORMS NXT robotics platform. △ Less","13 February, 2016",https://arxiv.org/pdf/1602.04290
"Deep Learning on FPGAs: Past, Present, and Future",Griffin Lacey;Graham W. Taylor;Shawki Areibi,"The rapid growth of data size and accessibility in recent years has instigated a shift of philosophy in algorithm design for artificial intelligence. Instead of engineering algorithms by hand, the ability to learn composable systems automatically from massive amounts of data has led to ground-breaking performance in important domains such as computer vision, speech recognition, and natural language processing. The most popular class of techniques used in these domains is called deep learning, and is seeing significant attention from industry. However, these models require incredible amounts of data and compute power to train, and are limited by the need for better hardware acceleration to accommodate scaling beyond current data and model sizes. While the current solution has been to use clusters of graphics processing units (GPU) as general purpose processors (GPGPU), the use of field programmable gate arrays (FPGA) provide an interesting alternative. Current trends in design tools for FPGAs have made them more compatible with the high-level software practices typically practiced in the deep learning community, making FPGAs more accessible to those who build and deploy models. Since FPGA architectures are flexible, this could also allow researchers the ability to explore model-level optimizations beyond what is possible on fixed architectures such as GPUs. As well, FPGAs tend to provide high performance per watt of power consumption, which is of particular importance for application scientists interested in large scale server-based deployment or resource-limited embedded applications. This review takes a look at deep learning and FPGAs from a hardware acceleration perspective, identifying trends and innovations that make these technologies a natural fit, and motivates a discussion on how FPGAs may best serve the needs of the deep learning community moving forward. △ Less","12 February, 2016",https://arxiv.org/pdf/1602.04283
Energetics of the brain and AI,Anders Sandberg,"Does the energy requirements for the human brain give energy constraints that give reason to doubt the feasibility of artificial intelligence? This report will review some relevant estimates of brain bioenergetics and analyze some of the methods of estimating brain emulation energy requirements. Turning to AI, there are reasons to believe the energy requirements for de novo AI to have little correlation with brain (emulation) energy requirements since cost could depend merely of the cost of processing higher-level representations rather than billions of neural firings. Unless one thinks the human way of thinking is the most optimal or most easily implementable way of achieving software intelligence, we should expect de novo AI to make use of different, potentially very compressed and fast, processes. △ Less","12 February, 2016",https://arxiv.org/pdf/1602.04019
Research Priorities for Robust and Beneficial Artificial Intelligence,Stuart Russell;Daniel Dewey;Max Tegmark,"Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial. △ Less","10 February, 2016",https://arxiv.org/pdf/1602.03506
GECKA3D: A 3D Game Engine for Commonsense Knowledge Acquisition,Erik Cambria;Tam V. Nguyen;Brian Cheng;Kenneth Kwok;Jose Sepulveda,"Commonsense knowledge representation and reasoning is key for tasks such as artificial intelligence and natural language understanding. Since commonsense consists of information that humans take for granted, gathering it is an extremely difficult task. In this paper, we introduce a novel 3D game engine for commonsense knowledge acquisition (GECKA3D) which aims to collect commonsense from game designers through the development of serious games. GECKA3D integrates the potential of serious games and games with a purpose. This provides a platform for the acquisition of re-usable and multi-purpose knowledge, and also enables the development of games that can provide entertainment value and teach players something meaningful about the actual world they live in. △ Less","2 February, 2016",https://arxiv.org/pdf/1602.01178
Adaptive Subgradient Methods for Online AUC Maximization,Yi Ding;Peilin Zhao;Steven C. H. Hoi;Yew-Soon Ong,"Learning for maximizing AUC performance is an important research problem in Machine Learning and Artificial Intelligence. Unlike traditional batch learning methods for maximizing AUC which often suffer from poor scalability, recent years have witnessed some emerging studies that attempt to maximize AUC by single-pass online learning approaches. Despite their encouraging results reported, the existing online AUC maximization algorithms often adopt simple online gradient descent approaches that fail to exploit the geometrical knowledge of the data observed during the online learning process, and thus could suffer from relatively larger regret. To address the above limitation, in this work, we explore a novel algorithm of Adaptive Online AUC Maximization (AdaOAM) which employs an adaptive gradient method that exploits the knowledge of historical gradients to perform more informative online learning. The new adaptive updating strategy of the AdaOAM is less sensitive to the parameter settings and maintains the same time complexity as previous non-adaptive counterparts. Additionally, we extend the algorithm to handle high-dimensional sparse data (SAdaOAM) and address sparsity in the solution by performing lazy gradient updating. We analyze the theoretical bounds and evaluate their empirical performance on various types of data sets. The encouraging empirical results obtained clearly highlighted the effectiveness and efficiency of the proposed algorithms. △ Less","31 January, 2016",https://arxiv.org/pdf/1602.00351
Persuasive Teachable Agent for Intergenerational Learning,Su Fang Lim,"Teachable agents are computer agents based on the pedagogical concept of learning-by-teaching. During the tutoring process, where students take on the role of the tutor to teach a computer agent tutee, learners have been observed to gain deeper understanding of the subject matter. Teachable agents are commonly used in the areas of science and mathematics learning where learners are able to learn complex concepts and deep reasoning by teaching the teachable agent through graphic representation such as concept maps. Literature review on teachable agents as well as observations during field studies conducted by the researcher, have shown that many current teachable agents lack the interaction abilities required to keep learners engage in learning tasks. The result of this is learners deviating from the teaching process, and thus the learners are unable to benefit fully from learning with the teachable agent. The applications of teachable agents are restricted to the learning of academic subjects such as mathematics and science. In this book, we have proposed the Persuasive Teachable Agent (PTA), a teachable agent based on the theoretical framework of persuasion, computational and goal-oriented agent modelling. We argue that the PTA, an autonomous agent, capable of encouraging attitude and behavioural change can offer a more meaningful and engaging learning experiences for learners from different age groups. Based on the findings from our research we argue that persuasive feedback actions generated by the PTA provide significant influence over learner's decision to participate in intergenerational learning. The PTA plays a crucial role in the development of future persuasive technologies in artificially intelligent agents. △ Less","27 January, 2016",https://arxiv.org/pdf/1601.07264
"Bachelor's thesis on generative probabilistic programming (in Russian language, June 2014)",Yura N Perov,"This Bachelor's thesis, written in Russian, is devoted to a relatively new direction in the field of machine learning and artificial intelligence, namely probabilistic programming. The thesis gives a brief overview to the already existing probabilistic programming languages: Church, Venture, and Anglican. It also describes the results of the first experiments on the automatic induction of probabilistic programs. The thesis was submitted, in June 2014, in partial fulfilment of the requirements for the degree of Bachelor of Science in Mathematics in the Department of Mathematics and Computer Science, Siberian Federal University, Krasnoyarsk, Russia. The work, which is described in this thesis, has been performing in 2012-2014 in the Massachusetts Institute of Technology and in the University of Oxford by the colleagues of the author and by himself. △ Less","26 January, 2016",https://arxiv.org/pdf/1601.07224
Intelligent Conversational Bot for Massive Online Open Courses (MOOCs),Ser Ling Lim;Ong Sing Goh,"Massive Online Open Courses (MOOCs) which were introduced in 2008 has since drawn attention around the world for both its advantages as well as criticism on its drawbacks. One of the issues in MOOCs which is the lack of interactivity with the instructor has brought conversational bot into the picture to fill in this gap. In this study, a prototype of MOOCs conversational bot, MOOC-bot is being developed and integrated into MOOCs website to respond to the learner inquiries using text or speech input. MOOC-bot is using the popular Artificial Intelligence Markup Language (AIML) to develop its knowledge base, leverage from AIML capability to deliver appropriate responses and can be quickly adapted to new knowledge domains. The system architecture of MOOC-bot consists of knowledge base along with AIML interpreter, chat interface, MOOCs website and Web Speech API to provide speech recognition and speech synthesis capability. The initial MOOC-bot prototype has the general knowledge from the past Loebner Prize winner - ALICE, frequent asked questions, and a content offered by Universiti Teknikal Malaysia Melaka (UTeM). The evaluation of MOOC-bot based on the past competition questions from Chatterbox Challenge (CBC) and Loebner Prize has shown that it was able to provide correct answers most of the time during the test and demonstrated the capability to prolong the conversation. The advantages of MOOC-bot such as able to provide 24-hour service that can serve different time zones, able to have knowledge in multiple domains, and can be shared by multiple sites simultaneously have outweighed its existing limitations. △ Less","26 January, 2016",https://arxiv.org/pdf/1601.07065
A Survey on Artificial Intelligence and Data Mining for MOOCs,Simon Fauvel;Han Yu,"Massive Open Online Courses (MOOCs) have gained tremendous popularity in the last few years. Thanks to MOOCs, millions of learners from all over the world have taken thousands of high-quality courses for free. Putting together an excellent MOOC ecosystem is a multidisciplinary endeavour that requires contributions from many different fields. Artificial intelligence (AI) and data mining (DM) are two such fields that have played a significant role in making MOOCs what they are today. By exploiting the vast amount of data generated by learners engaging in MOOCs, DM improves our understanding of the MOOC ecosystem and enables MOOC practitioners to deliver better courses. Similarly, AI, supported by DM, can greatly improve student experience and learning outcomes. In this survey paper, we first review the state-of-the-art artificial intelligence and data mining research applied to MOOCs, emphasising the use of AI and DM tools and techniques to improve student engagement, learning outcomes, and our understanding of the MOOC ecosystem. We then offer an overview of key trends and important research to carry out in the fields of AI and DM so that MOOCs can reach their full potential. △ Less","25 January, 2016",https://arxiv.org/pdf/1601.06862
Complexity of ITL model checking: some well-behaved fragments of the interval logic HS,A. Molinari;A. Montanari;A. Peron,"Model checking has been successfully used in many computer science fields, including artificial intelligence, theoretical computer science, and databases. Most of the proposed solutions make use of classical, point-based temporal logics, while little work has been done in the interval temporal logic setting. Recently, a non-elementary model checking algorithm for Halpern and Shoham's modal logic of time intervals HS over finite Kripke structures (under the homogeneity assumption) and an EXPSPACE model checking procedure for two meaningful fragments of it have been proposed. In this paper, we show that more efficient model checking procedures can be developed for some expressive enough fragments of HS. △ Less","13 January, 2016",https://arxiv.org/pdf/1601.03202
SDDs are Exponentially More Succinct than OBDDs,Simone Bova,"Introduced by Darwiche (2011), sentential decision diagrams (SDDs) are essentially as tractable as ordered binary decision diagrams (OBDDs), but tend to be more succinct in practice. This makes SDDs a prominent representation language, with many applications in artificial intelligence and knowledge compilation. We prove that SDDs are more succinct than OBDDs also in theory, by constructing a family of boolean functions where each member has polynomial SDD size but exponential OBDD size. This exponential separation improves a quasipolynomial separation recently established by Razgon (2013), and settles an open problem in knowledge compilation. △ Less","4 January, 2016",https://arxiv.org/pdf/1601.00501
A Planning based Framework for Essay Generation,Bing Qin;Duyu Tang;Xinwei Geng;Dandan Ning;Jiahao Liu;Ting Liu,"Generating an article automatically with computer program is a challenging task in artificial intelligence and natural language processing. In this paper, we target at essay generation, which takes as input a topic word in mind and generates an organized article under the theme of the topic. We follow the idea of text planning \cite{Reiter1997} and develop an essay generation framework. The framework consists of three components, including topic understanding, sentence extraction and sentence reordering. For each component, we studied several statistical algorithms and empirically compared between them in terms of qualitative or quantitative analysis. Although we run experiments on Chinese corpus, the method is language independent and can be easily adapted to other language. We lay out the remaining challenges and suggest avenues for future research. △ Less","6 January, 2016",https://arxiv.org/pdf/1512.05919
Better Computer Go Player with Neural Network and Long-term Prediction,Yuandong Tian;Yan Zhu,"Competing with top human players in the ancient game of Go has been a long-term goal of artificial intelligence. Go's high branching factor makes traditional search techniques ineffective, even on leading-edge hardware, and Go's evaluation function could change drastically with one stone change. Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis & Gailly (2012)] if its search budget is limited. We extend this idea in our bot named darkforest, which relies on a DCNN designed for long-term predictions. Darkforest substantially improves the win rate for pattern-matching approaches against MCTS-based approaches, even with looser search budgets. Against human players, the newest versions, darkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, a substantial improvement upon the estimated 4k-5k ranks for DCNN reported in Clark & Storkey (2015) based on games against other machine players. Adding MCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000 rollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rollouts it achieves a stable 5d level in KGS server, on par with state-of-the-art Go AIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al. (2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament. △ Less","29 February, 2016",https://arxiv.org/pdf/1511.06410
The Use of Machine Learning Algorithms in Recommender Systems: A Systematic Review,Ivens Portugal;Paulo Alencar;Donald Cowan,"Recommender systems use algorithms to provide users with product or service recommendations. Recently, these systems have been using machine learning algorithms from the field of artificial intelligence. However, choosing a suitable machine learning algorithm for a recommender system is difficult because of the number of algorithms described in the literature. Researchers and practitioners developing recommender systems are left with little information about the current approaches in algorithm usage. Moreover, the development of a recommender system using a machine learning algorithm often has problems and open questions that must be evaluated, so software engineers know where to focus research efforts. This paper presents a systematic review of the literature that analyzes the use of machine learning algorithms in recommender systems and identifies research opportunities for software engineering research. The study concludes that Bayesian and decision tree algorithms are widely used in recommender systems because of their relative simplicity, and that requirement and design phases of recommender system development appear to offer opportunities for further research. △ Less","24 February, 2016",https://arxiv.org/pdf/1511.05263
Training Deep Networks with Structured Layers by Matrix Backpropagation,Catalin Ionescu;Orestis Vantzos;Cristian Sminchisescu,"Deep neural network architectures have recently produced excellent results in a variety of areas in artificial intelligence and visual recognition, well surpassing traditional shallow architectures trained using hand-designed features. The power of deep networks stems both from their ability to perform local computations followed by pointwise non-linearities over increasingly larger receptive fields, and from the simplicity and scalability of the gradient-descent training procedure based on backpropagation. An open problem is the inclusion of layers that perform global, structured matrix computations like segmentation (e.g. normalized cuts) or higher-order pooling (e.g. log-tangent space metrics defined over the manifold of symmetric positive definite matrices) while preserving the validity and efficiency of an end-to-end deep training framework. In this paper we propose a sound mathematical apparatus to formally integrate global structured computation into deep computation architectures. At the heart of our methodology is the development of the theory and practice of backpropagation that generalizes to the calculus of adjoint matrix variations. The proposed matrix backpropagation methodology applies broadly to a variety of problems in machine learning or computational perception. Here we illustrate it by performing visual segmentation experiments using the BSDS and MSCOCO benchmarks, where we show that deep networks relying on second-order pooling and normalized cuts layers, trained end-to-end using matrix backpropagation, outperform counterparts that do not take advantage of such global layers. △ Less","14 April, 2016",https://arxiv.org/pdf/1509.07838
Belief and Truth in Hypothesised Behaviours,Stefano V. Albrecht;Jacob W. Crandall;Subramanian Ramamoorthy,"There is a long history in game theory on the topic of Bayesian or ""rational"" learning, in which each player maintains beliefs over a set of alternative behaviours, or types, for the other players. This idea has gained increasing interest in the artificial intelligence (AI) community, where it is used as a method to control a single agent in a system composed of multiple agents with unknown behaviours. The idea is to hypothesise a set of types, each specifying a possible behaviour for the other agents, and to plan our own actions with respect to those types which we believe are most likely, given the observed actions of the agents. The game theory literature studies this idea primarily in the context of equilibrium attainment. In contrast, many AI applications have a focus on task completion and payoff maximisation. With this perspective in mind, we identify and address a spectrum of questions pertaining to belief and truth in hypothesised types. We formulate three basic ways to incorporate evidence into posterior beliefs and show when the resulting beliefs are correct, and when they may fail to be correct. Moreover, we demonstrate that prior beliefs can have a significant impact on our ability to maximise payoffs in the long-term, and that they can be computed automatically with consistent performance effects. Furthermore, we analyse the conditions under which we are able complete our task optimally, despite inaccuracies in the hypothesised types. Finally, we show how the correctness of hypothesised types can be ascertained during the interaction via an automated statistical analysis. △ Less","2 March, 2016",https://arxiv.org/pdf/1507.07688
The Digital Synaptic Neural Substrate: A New Approach to Computational Creativity,Azlan Iqbal;Matej Guid;Simon Colton;Jana Krivec;Shazril Azman;Boshra Haghighi,"We introduce a new artificial intelligence (AI) approach called, the 'Digital Synaptic Neural Substrate' (DSNS). It uses selected attributes from objects in various domains (e.g. chess problems, classical music, renowned artworks) and recombines them in such a way as to generate new attributes that can then, in principle, be used to create novel objects of creative value to humans relating to any one of the source domains. This allows some of the burden of creative content generation to be passed from humans to machines. The approach was tested in the domain of chess problem composition. We used it to automatically compose numerous sets of chess problems based on attributes extracted and recombined from chess problems and tournament games by humans, renowned paintings, computer-evolved abstract art, photographs of people, and classical music tracks. The quality of these generated chess problems was then assessed automatically using an existing and experimentally-validated computational chess aesthetics model. They were also assessed by human experts in the domain. The results suggest that attributes collected and recombined from chess and other domains using the DSNS approach can indeed be used to automatically generate chess problems of reasonably high aesthetic quality. In particular, a low quality chess source (i.e. tournament game sequences between weak players) used in combination with actual photographs of people was able to produce three-move chess problems of comparable quality or better to those generated using a high quality chess source (i.e. published compositions by human experts), and more efficiently as well. Why information from a foreign domain can be integrated and functional in this way remains an open question for now. The DSNS approach is, in principle, scalable and applicable to any domain in which objects have attributes that can be represented using real numbers. △ Less","20 September, 2016",https://arxiv.org/pdf/1507.07058
Solving Verbal Comprehension Questions in IQ Test by Knowledge-Powered Word Embedding,Huazheng Wang;Fei Tian;Bin Gao;Jiang Bian;Tie-Yan Liu,"Intelligence Quotient (IQ) Test is a set of standardized questions designed to evaluate human intelligence. Verbal comprehension questions appear very frequently in IQ tests, which measure human's verbal ability including the understanding of the words with multiple senses, the synonyms and antonyms, and the analogies among words. In this work, we explore whether such tests can be solved automatically by artificial intelligence technologies, especially the deep learning technologies that are recently developed and successfully applied in a number of fields. However, we found that the task was quite challenging, and simply applying existing technologies (e.g., word embedding) could not achieve a good performance, mainly due to the multiple senses of words and the complex relations among words. To tackle these challenges, we propose a novel framework consisting of three components. First, we build a classifier to recognize the specific type of a verbal question (e.g., analogy, classification, synonym, or antonym). Second, we obtain distributed representations of words and relations by leveraging a novel word embedding method that considers the multi-sense nature of words and the relational knowledge among words (or their senses) contained in dictionaries. Third, for each type of questions, we propose a specific solver based on the obtained distributed word representations and relation representations. Experimental results have shown that the proposed framework can not only outperform existing methods for solving verbal comprehension questions but also exceed the average performance of the Amazon Mechanical Turk workers involved in the study. The results indicate that with appropriate uses of the deep learning technologies we might be a further step closer to the human intelligence. △ Less","26 April, 2016",https://arxiv.org/pdf/1505.07909
"Discovery of the D
-basis in binary tables based on hypergraph dualization",Kira Adaricheva;J. B. Nation,"Discovery of (strong) association rules, or implications, is an important task in data management, and it finds application in artificial intelligence, data mining and the semantic web. We introduce a novel approach for the discovery of a specific set of implications, called the D-basis, that provides a representation for a reduced binary table, based on the structure of its Galois lattice. At the core of the method are the D-relation defined in the lattice theory framework, and the hypergraph dualization algorithm that allows us to effectively produce the set of transversals for a given Sperner hypergraph. The latter algorithm, first developed by specialists from Rutgers Center for Operations Research, has already found numerous applications in solving optimization problems in data base theory, artificial intelligence and game theory. One application of the method is for analysis of gene expression data related to a particular phenotypic variable, and some initial testing is done for the data provided by the University of Hawaii Cancer Center. △ Less","31 January, 2016",https://arxiv.org/pdf/1504.02875
"ASPeRiX, a First Order Forward Chaining Approach for Answer Set Computing",Claire Lefèvre;Christopher Béatrix;Igor Stéphan;Laurent Garcia,"The natural way to use Answer Set Programming (ASP) to represent knowledge in Artificial Intelligence or to solve a combinatorial problem is to elaborate a first order logic program with default negation. In a preliminary step this program with variables is translated in an equivalent propositional one by a first tool: the grounder. Then, the propositional program is given to a second tool: the solver. This last one computes (if they exist) one or many answer sets (stable models) of the program, each answer set encoding one solution of the initial problem. Until today, almost all ASP systems apply this two steps computation. In this article, the project ASPeRiX is presented as a first order forward chaining approach for Answer Set Computing. This project was amongst the first to introduce an approach of answer set computing that escapes the preliminary phase of rule instantiation by integrating it in the search process. The methodology applies a forward chaining of first order rules that are grounded on the fly by means of previously produced atoms. Theoretical foundations of the approach are presented, the main algorithms of the ASP solver ASPeRiX are detailed and some experiments and comparisons with existing systems are provided. △ Less","16 November, 2016",https://arxiv.org/pdf/1503.07717
"AI Evaluation: past, present and future",Jose Hernandez-Orallo,"Artificial intelligence develops techniques and systems whose performance must be evaluated on a regular basis in order to certify and foster progress in the discipline. We will describe and critically assess the different ways AI systems are evaluated. We first focus on the traditional task-oriented evaluation approach. We see that black-box (behavioural evaluation) is becoming more and more common, as AI systems are becoming more complex and unpredictable. We identify three kinds of evaluation: Human discrimination, problem benchmarks and peer confrontation. We describe the limitations of the many evaluation settings and competitions in these three categories and propose several ideas for a more systematic and robust evaluation. We then focus on a less customary (and challenging) ability-oriented evaluation approach, where a system is characterised by its (cognitive) abilities, rather than by the tasks it is designed to solve. We discuss several possibilities: the adaptation of cognitive tests used for humans and animals, the development of tests derived from algorithmic information theory or more general approaches under the perspective of universal psychometrics. △ Less","21 August, 2016",https://arxiv.org/pdf/1408.6908
"Semantic Measures for the Comparison of Units of Language, Concepts or Instances from Text and Knowledge Base Analysis",Sébastien Harispe;Sylvie Ranwez;Stefan Janaqi;Jacky Montmain,"Semantic measures are widely used today to estimate the strength of the semantic relationship between elements of various types: units of language (e.g., words, sentences, documents), concepts or even instances semantically characterized (e.g., diseases, genes, geographical locations). Semantic measures play an important role to compare such elements according to semantic proxies: texts and knowledge representations, which support their meaning or describe their nature. Semantic measures are therefore essential for designing intelligent agents which will for example take advantage of semantic analysis to mimic human ability to compare abstract or concrete objects. This paper proposes a comprehensive survey of the broad notion of semantic measure for the comparison of units of language, concepts or instances based on semantic proxy analyses. Semantic measures generalize the well-known notions of semantic similarity, semantic relatedness and semantic distance, which have been extensively studied by various communities over the last decades (e.g., Cognitive Sciences, Linguistics, and Artificial Intelligence to mention a few). △ Less","24 October, 2016",https://arxiv.org/pdf/1310.1285
In Love With a Robot: the Dawn of Machine-To-Machine Marketing,Emil Kotomin,"The article looks at mass market artificial intelligence tools in the context of their ever-growing sophistication, availability and market penetration. The subject is especially relevant today for these exact reasons - if a few years ago AI was the subject of high tech research and science fiction novels, today, we increasingly rely on cloud robotics to cater to our daily needs - to trade stock, predict weather, manage diaries, find friends and buy presents online. △ Less","3 August, 2016",https://arxiv.org/pdf/1302.4475
Completeness of Flat Coalgebraic Fixpoint Logics,Lutz Schröder;Yde Venema,"Modal fixpoint logics traditionally play a central role in computer science, in particular in artificial intelligence and concurrency. The mu-calculus and its relatives are among the most expressive logics of this type. However, popular fixpoint logics tend to trade expressivity for simplicity and readability, and in fact often live within the single variable fragment of the mu-calculus. The family of such flat fixpoint logics includes, e.g., LTL, CTL, and the logic of common knowledge. Extending this notion to the generic semantic framework of coalgebraic logic enables covering a wide range of logics beyond the standard mu-calculus including, e.g., flat fragments of the graded mu-calculus and the alternating-time mu-calculus (such as alternating-time temporal logic ATL), as well as probabilistic and monotone fixpoint logics. We give a generic proof of completeness of the Kozen-Park axiomatization for such flat coalgebraic fixpoint logics. △ Less","9 June, 2016",https://arxiv.org/pdf/1004.2717
