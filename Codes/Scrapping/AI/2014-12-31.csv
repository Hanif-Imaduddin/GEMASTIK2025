title,authors,abstract,submitted_date,pdf_link
Quantifying Natural and Artificial Intelligence in Robots and Natural Systems with an Algorithmic Behavioural Test,Hector Zenil,"One of the most important aims of the fields of robotics, artificial intelligence and artificial life is the design and construction of systems and machines as versatile and as reliable as living organisms at performing high level human-like tasks. But how are we to evaluate artificial systems if we are not certain how to measure these capacities in living systems, let alone how to define life or intelligence? Here I survey a concrete metric towards measuring abstract properties of natural and artificial systems, such as the ability to react to the environment and to control one's own behaviour. △ Less","23 December, 2014",https://arxiv.org/pdf/1412.6703
GraATP: A Graph Theoretic Approach for Automated Theorem Proving in Plane Geometry,Mohammad Murtaza Mahmud;Swakkhar Shatabda;Mohammad Nurul Huda,"Automated Theorem Proving (ATP) is an established branch of Artificial Intelligence. The purpose of ATP is to design a system which can automatically figure out an algorithm either to prove or disprove a mathematical claim, on the basis of a set of given premises, using a set of fundamental postulates and following the method of logical inference. In this paper, we propose GraATP, a generalized framework for automated theorem proving in plane geometry. Our proposed method translates the geometric entities into nodes of a graph and the relations between them as edges of that graph. The automated system searches for different ways to reach the conclusion for a claim via graph traversal by which the validity of the geometric theorem is examined. △ Less","18 December, 2014",https://arxiv.org/pdf/1412.5980
Learning Word Representations from Relational Graphs,Danushka Bollegala;Takanori Maehara;Yuichi Yoshida;Ken-ichi Kawarabayashi,"Attributes of words and relations between two words are central to numerous tasks in Artificial Intelligence such as knowledge representation, similarity measurement, and analogy detection. Often when two words share one or more attributes in common, they are connected by some semantic relations. On the other hand, if there are numerous semantic relations between two words, we can expect some of the attributes of one of the words to be inherited by the other. Motivated by this close connection between attributes and relations, given a relational graph in which words are inter- connected via numerous semantic relations, we propose a method to learn a latent representation for the individual words. The proposed method considers not only the co-occurrences of words as done by existing approaches for word representation learning, but also the semantic relations in which two words co-occur. To evaluate the accuracy of the word representations learnt using the proposed method, we use the learnt word representations to solve semantic word analogy problems. Our experimental results show that it is possible to learn better word representations by using semantic semantics between words. △ Less","7 December, 2014",https://arxiv.org/pdf/1412.2378
"Genetic Algorithms in Wireless Networking: Techniques, Applications, and Issues",Usama Mehboob;Junaid Qadir;Salman Ali;Athanasios Vasilakos,"In recent times, wireless access technology is becoming increasingly commonplace due to the ease of operation and installation of untethered wireless media. The design of wireless networking is challenging due to the highly dynamic environmental condition that makes parameter optimization a complex task. Due to the dynamic, and often unknown, operating conditions, modern wireless networking standards increasingly rely on machine learning and artificial intelligence algorithms. Genetic algorithms (GAs) provide a well-established framework for implementing artificial intelligence tasks such as classification, learning, and optimization. GAs are well-known for their remarkable generality and versatility, and have been applied in a wide variety of settings in wireless networks. In this paper, we provide a comprehensive survey of the applications of GAs in wireless networks. We provide both an exposition of common GA models and configuration and provide a broad ranging survey of GA techniques in wireless networks. We also point out open research issues and define potential future work. While various surveys on GAs exist in literature, our paper is the first paper, to the best of our knowledge, which focuses on their application in wireless networks. △ Less","19 November, 2014",https://arxiv.org/pdf/1411.5323
ROSS User's Guide and Reference Manual (Version 1.0),Glenn R. Hofford,"The ROSS method is a new approach in the area of knowledge representation that is useful for many artificial intelligence and natural language understanding representation and reasoning tasks. (ROSS stands for ""Representation"", ""Ontology"", ""Structure"", ""Star"" language). ROSS is a physical symbol-based representational scheme. ROSS provides a complex model for the declarative representation of physical structure and for the representation of processes and causality. From the metaphysical perspective, the ROSS view of external reality involves a 4D model, wherein discrete single-time-point unit-sized locations with states are the basis for all objects, processes and aspects that can be modeled. ROSS includes a language called ""Star"" for the specification of ontology classes. The ROSS method also includes a formal scheme called the ""instance model"". Instance models are used in the area of natural language meaning representation to represent situations. This document is an in-depth specification of the ROSS method. △ Less","15 November, 2014",https://arxiv.org/pdf/1411.4194
Logical Limitations to Machine Ethics with Consequences to Lethal Autonomous Weapons,Matthias Englert;Sandra Siebert;Martin Ziegler,"Lethal Autonomous Weapons promise to revolutionize warfare -- and raise a multitude of ethical and legal questions. It has thus been suggested to program values and principles of conduct (such as the Geneva Conventions) into the machines' control, thereby rendering them both physically and morally superior to human combatants. We employ mathematical logic and theoretical computer science to explore fundamental limitations to the moral behaviour of intelligent machines in a series of ""Gedankenexperiments"": Refining and sharpening variants of the Trolley Problem leads us to construct an (admittedly artificial but) fully deterministic situation where a robot is presented with two choices: one morally clearly preferable over the other -- yet, based on the undecidability of the Halting problem, it provably cannot decide algorithmically which one. Our considerations have surprising implications to the question of responsibility and liability for an autonomous system's actions and lead to specific technical recommendations. △ Less","11 November, 2014",https://arxiv.org/pdf/1411.2842
Do Artificial Reinforcement-Learning Agents Matter Morally?,Brian Tomasik,"Artificial reinforcement learning (RL) is a widely used technique in artificial intelligence that provides a general method for training agents to perform a wide variety of behaviours. RL as used in computer science has striking parallels to reward and punishment learning in animal and human brains. I argue that present-day artificial RL agents have a very small but nonzero degree of ethical importance. This is particularly plausible for views according to which sentience comes in degrees based on the abilities and complexities of minds, but even binary views on consciousness should assign nonzero probability to RL programs having morally relevant experiences. While RL programs are not a top ethical priority today, they may become more significant in the coming decades as RL is increasingly applied to industry, robotics, video games, and other areas. I encourage scientists, philosophers, and citizens to begin a conversation about our ethical duties to reduce the harm that we inflict on powerless, voiceless RL agents. △ Less","29 October, 2014",https://arxiv.org/pdf/1410.8233
A World of Views: A World of Interacting Post-human Intelligences,Viktoras Veitas;David Weinbaum,"What would a human hundreds or thousands times more intelligent than the brightest human ever born be like? We must admit we can hardly guess. A human being of such intelligence will be so radically different from us that it can hardly, if at all, be recognized as human. If we had to go back along the evolutionary tree to identify a creature 1000 times less intelligent than the average contemporary human, we will have to go really far back. Would it be a kind of a lizard? An insect perhaps? Considering this, how can we possibly aspire to have a grasp of something a thousand times more intelligent than us? When it comes to intelligence, even the very attempt to quantify it is highly misleading. Now if we attend to a seemingly adjacent question, what would a machine with such capacity for intelligence be like? Just coming up with an approximate metaphor requires a huge stretch of the imagination, meaning that almost anything goes... What would a society of such super intelligent agents, be they human, machines or an amalgam of both, be like? Well, here we are transported into the realm of pure speculation. Technological Singularity is referred to as the event of artificial intelligence surpassing the intelligence of humans and shortly after augmenting itself far beyond that. It is no wonder that the mathematical concept of singularity has become the symbol of an event so disruptive and so far reaching that it is impossible to conceptually or even metaphorically grasp, much less to predict. △ Less","25 October, 2014",https://arxiv.org/pdf/1410.6915
Mobility Enhancement for Elderly,Ramviyas Parasuraman,"Loss of Mobility is a common handicap to senior citizens. It denies them the ease of movement they would like to have like outdoor visits, movement in hospitals, social outgoings, but more seriously in the day to day in-house routine functions necessary for living etc. Trying to overcome this handicap by means of servant or domestic help and simple wheel chairs is not only costly in the long run, but forces the senior citizen to be at the mercy of sincerity of domestic helps and also the consequent loss of dignity. In order to give a dignified life, the mobility obtained must be at the complete discretion, will and control of the senior citizen. This can be provided only by a reasonably sophisticated and versatile wheel chair, giving enhanced ability of vision, hearing through man-machine interface, and sensor aided navigation and control. More often than not senior people have poor vision which makes it difficult for them to maker visual judgement and so calls for the use of Artificial Intelligence in visual image analysis and guided navigation systems. In this project, we deal with two important enhancement features for mobility enhancement, Audio command and Vision aided obstacle detection and navigation. We have implemented speech recognition algorithm using template of stored words for identifying the voice command given by the user. This frees the user of an agile hand to operate joystick or mouse control. Also, we have developed a new appearance based obstacle detection system using stereo-vision cameras which estimates the distance of nearest obstacle to the wheel chair and takes necessary action. This helps user in making better judgement of route and navigate obstacles. The main challenge in this project is how to navigate in an unknown/unfamiliar environment by avoiding obstacles. △ Less","21 October, 2014",https://arxiv.org/pdf/1410.5600
eTutor: Online Learning for Personalized Education,Cem Tekin;Mihaela van der Schaar,"Given recent advances in information technology and artificial intelligence, web-based education systems have became complementary and, in some cases, viable alternatives to traditional classroom teaching. The popularity of these systems stems from their ability to make education available to a large demographics (see MOOCs). However, existing systems do not take advantage of the personalization which becomes possible when web-based education is offered: they continue to be one-size-fits-all. In this paper, we aim to provide a first systematic method for designing a personalized web-based education system. Personalizing education is challenging: (i) students need to be provided personalized teaching and training depending on their contexts (e.g. classes already taken, methods of learning preferred, etc.), (ii) for each specific context, the best teaching and training method (e.g type and order of teaching materials to be shown) must be learned, (iii) teaching and training should be adapted online, based on the scores/feedback (e.g. tests, quizzes, final exam, likes/dislikes etc.) of the students. Our personalized online system, e-Tutor, is able to address these challenges by learning how to adapt the teaching methodology (in this case what sequence of teaching material to present to a student) to maximize her performance in the final exam, while minimizing the time spent by the students to learn the course (and possibly dropouts). We illustrate the efficiency of the proposed method on a real-world eTutor platform which is used for remedial training for a Digital Signal Processing (DSP) course. △ Less","14 October, 2014",https://arxiv.org/pdf/1410.3617
Computational Beauty: Aesthetic Judgment at the Intersection of Art and Science,Emily L. Spratt;Ahmed Elgammal,"In part one of the Critique of Judgment, Immanuel Kant wrote that ""the judgment of taste...is not a cognitive judgment, and so not logical, but is aesthetic.""\cite{Kant} While the condition of aesthetic discernment has long been the subject of philosophical discourse, the role of the arbiters of that judgment has more often been assumed than questioned. The art historian, critic, connoisseur, and curator have long held the esteemed position of the aesthetic judge, their training, instinct, and eye part of the inimitable subjective processes that Kant described as occurring upon artistic evaluation. Although the concept of intangible knowledge in regard to aesthetic theory has been much explored, little discussion has arisen in response to the development of new types of artificial intelligence as a challenge to the seemingly ineffable abilities of the human observer. This paper examines the developments in the field of computer vision analysis of paintings from canonical movements with the history of Western art and the reaction of art historians to the application of this technology in the field. Through an investigation of the ethical consequences of this innovative technology, the unquestioned authority of the art expert is challenged and the subjective nature of aesthetic judgment is brought to philosophical scrutiny once again. △ Less","29 September, 2014",https://arxiv.org/pdf/1410.2488
An Aerial Image Recognition Framework using Discrimination and Redundancy Quality Measure,Yuxin Hu;Luming Zhang,"Aerial image categorization plays an indispensable role in remote sensing and artificial intelligence. In this paper, we propose a new aerial image categorization framework, focusing on organizing the local patches of each aerial image into multiple discriminative subgraphs. The subgraphs reflect both the geometric property and the color distribution of an aerial image. First, each aerial image is decomposed into a collection of regions in terms of their color intensities. Thereby region connected graph (RCG), which models the connection between the spatial neighboring regions, is constructed to encode the spatial context of an aerial image. Second, a subgraph mining technique is adopted to discover the frequent structures in the RCGs constructed from the training aerial images. Thereafter, a set of refined structures are selected among the frequent ones toward being highly discriminative and low redundant. Lastly, given a new aerial image, its sub-RCGs corresponding to the refined structures are extracted. They are further quantized into a discriminative vector for SVM classification. Thorough experimental results validate the effectiveness of the proposed method. In addition, the visualized mined subgraphs show that the discriminative topologies of each aerial image are discovered. △ Less","6 October, 2014",https://arxiv.org/pdf/1410.2188
Software & Systems Engineering Process and Tools for the Development of Autonomous Driving Intelligence,Christian Basarke;Christian Berger;Bernhard Rumpe,"When a large number of people with heterogeneous knowledge and skills run a project together, it is important to use a sensible engineering process. This especially holds for a project building an intelligent autonomously driving car to participate in the 2007 DARPA Urban Challenge. In this article, we present essential elements of a software and system engineering process for the development of artificial intelligence capable of driving autonomously in complex urban situations. The process includes agile concepts, like test first approach, continuous integration of every software module and a reliable release and configuration management assisted by software tools in integrated development environments. However, the most important ingredients for an efficient and stringent development are the ability to efficiently test the behavior of the developed system in a flexible and modular simulator for urban situations. △ Less","22 September, 2014",https://arxiv.org/pdf/1409.7121
Engineering Autonomous Driving Software,Christian Berger;Bernhard Rumpe,"A larger number of people with heterogeneous knowledge and skills running a project together needs an adaptable, target, and skill-specific engineering process. This especially holds for a project to develop a highly innovative, autonomously driving vehicle to participate in the 2007 DARPA Urban Challenge. In this contribution, we present essential elements of a software and systems engineering process to develop a so-called artificial intelligence capable of driving autonomously in complex urban situations. The process itself includes agile concepts, like a test first approach, continuous integration of all software modules, and a reliable release and configuration management assisted by software tools in integrated development environments. However, one of the most important elements for an efficient and stringent development is the ability to efficiently test the behavior of the developed system in a flexible and modular system simulation for urban situations both interactively and unattendedly. We call this the simulate first approach. △ Less","22 September, 2014",https://arxiv.org/pdf/1409.6579
Performance analysis of a 240 thread tournament level MCTS Go program on the Intel Xeon Phi,S. Ali Mirsoleimani;Aske Plaat;Jos Vermaseren;Jaap van den Herik,"In 2013 Intel introduced the Xeon Phi, a new parallel co-processor board. The Xeon Phi is a cache-coherent many-core shared memory architecture claiming CPU-like versatility, programmability, high performance, and power efficiency. The first published micro-benchmark studies indicate that many of Intel's claims appear to be true. The current paper is the first study on the Phi of a complex artificial intelligence application. It contains an open source MCTS application for playing tournament quality Go (an oriental board game). We report the first speedup figures for up to 240 parallel threads on a real machine, allowing a direct comparison to previous simulation studies. After a substantial amount of work, we observed that performance scales well up to 32 threads, largely confirming previous simulation results of this Go program, although the performance surprisingly deteriorates between 32 and 240 threads. Furthermore, we report (1) unexpected performance anomalies between the Xeon Phi and Xeon CPU for small problem sizes and small numbers of threads, and (2) that performance is sensitive to scheduling choices. Achieving good performance on the Xeon Phi for complex programs is not straightforward; it requires a deep understanding of (1) search patterns, (2) of scheduling, and (3) of the architecture and its many cores and caches. In practice, the Xeon Phi is less straightforward to program for than originally envisioned by Intel. △ Less","6 November, 2014",https://arxiv.org/pdf/1409.4297
Probabilistic Selection in AgentSpeak(L),Francisco Coelho;Vitor Nogueira,"Agent programming is mostly a symbolic discipline and, as such, draws little benefits from probabilistic areas as machine learning and graphical models. However, the greatest objective of agent research is the achievement of autonomy in dynamical and complex environments --- a goal that implies embracing uncertainty and therefore the entailed representations, algorithms and techniques. This paper proposes an innovative and conflict free two layer approach to agent programming that uses already established methods and tools from both symbolic and probabilistic artificial intelligence. Moreover, this framework is illustrated by means of a widely used agent programming example, GoldMiners. △ Less","12 September, 2014",https://arxiv.org/pdf/1409.3717
Building Program Vector Representations for Deep Learning,Lili Mou;Ge Li;Yuxuan Liu;Hao Peng;Zhi Jin;Yan Xu;Lu Zhang,"Deep learning has made significant breakthroughs in various fields of artificial intelligence. Advantages of deep learning include the ability to capture highly complicated features, weak involvement of human engineering, etc. However, it is still virtually impossible to use deep learning to analyze programs since deep architectures cannot be trained effectively with pure back propagation. In this pioneering paper, we propose the ""coding criterion"" to build program vector representations, which are the premise of deep learning for program analysis. Our representation learning approach directly makes deep learning a reality in this new field. We evaluate the learned vector representations both qualitatively and quantitatively. We conclude, based on the experiments, the coding criterion is successful in building program representations. To evaluate whether deep learning is beneficial for program analysis, we feed the representations to deep neural networks, and achieve higher accuracy in the program classification task than ""shallow"" methods, such as logistic regression and the support vector machine. This result confirms the feasibility of deep learning to analyze programs. It also gives primary evidence of its success in this new field. We believe deep learning will become an outstanding technique for program analysis in the near future. △ Less","11 September, 2014",https://arxiv.org/pdf/1409.3358
Rapid Integration and Calibration of New Sensors Using the Berkeley Aachen Robotics Toolkit (BART),Jan O. Biermeyer;Todd R. Templeton;Christian Berger;Humberto Gonzalez;Nikhil Naikal;Bernhard Rumpe;S. Shankar Sastry,"After the three DARPA Grand Challenge contests many groups around the world have continued to actively research and work toward an autonomous vehicle capable of accomplishing a mission in a given context (e.g. desert, city) while following a set of prescribed rules, but none has been completely successful in uncontrolled environments, a task that many people trivially fulfill every day. We believe that, together with improving the sensors used in cars and the artificial intelligence algorithms used to process the information, the community should focus on the systems engineering aspects of the problem, i.e. the limitations of the car (in terms of space, power, or heat dissipation) and the limitations of the software development cycle. This paper explores these issues and our experiences overcoming them. △ Less","8 September, 2014",https://arxiv.org/pdf/1409.2373
Visual Speech Recognition,Ahmad B. A. Hassanat,"Lip reading is used to understand or interpret speech without hearing it, a technique especially mastered by people with hearing difficulties. The ability to lip read enables a person with a hearing impairment to communicate with others and to engage in social activities, which otherwise would be difficult. Recent advances in the fields of computer vision, pattern recognition, and signal processing has led to a growing interest in automating this challenging task of lip reading. Indeed, automating the human ability to lip read, a process referred to as visual speech recognition (VSR) (or sometimes speech reading), could open the door for other novel related applications. VSR has received a great deal of attention in the last decade for its potential use in applications such as human-computer interaction (HCI), audio-visual speech recognition (AVSR), speaker recognition, talking heads, sign language recognition and video surveillance. Its main aim is to recognise spoken word(s) by using only the visual signal that is produced during speech. Hence, VSR deals with the visual domain of speech and involves image processing, artificial intelligence, object detection, pattern recognition, statistical modelling, etc. △ Less","2 September, 2014",https://arxiv.org/pdf/1409.1411
Hybrid Systems Knowledge Representation Using Modelling Environment System Techniques Artificial Intelligence,Kamran Latif,"Knowledge-based or Artificial Intelligence techniques are used increasingly as alternatives to more classical techniques to model ENVIRONMENTAL SYSTEMS. Use of Artificial Intelligence (AI) in environmental modelling has increased with recognition of its potential. In this paper we examine the DIFFERENT TECHNIQUES of Artificial intelligence with profound examples of human perception, learning and reasoning to solve complex problems. However with the increase of complexity better methods are required. Keeping in view of the above some researchers introduced the idea of hybrid mechanism in which two or more methods can be combined which seems to be a positive effort for creating a more complex; advanced and intelligent system which has the capability to in- cooperate human decisions thus driving the landscape changes. △ Less","13 September, 2014",https://arxiv.org/pdf/1409.1170
Friendly Artificial Intelligence: the Physics Challenge,Max Tegmark,"Relentless progress in artificial intelligence (AI) is increasingly raising concerns that machines will replace humans on the job market, and perhaps altogether. Eliezer Yudkowski and others have explored the possibility that a promising future for humankind could be guaranteed by a superintelligent ""Friendly AI"", designed to safeguard humanity and its values. I argue that, from a physics perspective where everything is simply an arrangement of elementary particles, this might be even harder than it appears. Indeed, it may require thinking rigorously about the meaning of life: What is ""meaning"" in a particle arrangement? What is ""life""? What is the ultimate ethical imperative, i.e., how should we strive to rearrange the particles of our Universe and shape its future? If we fail to answer the last question rigorously, this future is unlikely to contain humans. △ Less","3 September, 2014",https://arxiv.org/pdf/1409.0813
An Information Retrieval Approach to Short Text Conversation,Zongcheng Ji;Zhengdong Lu;Hang Li,"Human computer conversation is regarded as one of the most difficult problems in artificial intelligence. In this paper, we address one of its key sub-problems, referred to as short text conversation, in which given a message from human, the computer returns a reasonable response to the message. We leverage the vast amount of short conversation data available on social media to study the issue. We propose formalizing short text conversation as a search problem at the first step, and employing state-of-the-art information retrieval (IR) techniques to carry out the task. We investigate the significance as well as the limitation of the IR approach. Our experiments demonstrate that the retrieval-based model can make the system behave rather ""intelligently"", when combined with a huge repository of conversation data from social media. △ Less","29 August, 2014",https://arxiv.org/pdf/1408.6988
Definition and properties to assess multi-agent environments as social intelligence tests,Javier Insa-Cabrera;José Hernández-Orallo,"Social intelligence in natural and artificial systems is usually measured by the evaluation of associated traits or tasks that are deemed to represent some facets of social behaviour. The amalgamation of these traits is then used to configure the intuitive notion of social intelligence. Instead, in this paper we start from a parametrised definition of social intelligence as the expected performance in a set of environments with several agents, and we assess and derive tests from it. This definition makes several dependencies explicit: (1) the definition depends on the choice (and weight) of environments and agents, (2) the definition may include both competitive and cooperative behaviours depending on how agents and rewards are arranged into teams, (3) the definition mostly depends on the abilities of other agents, and (4) the actual difference between social intelligence and general intelligence (or other abilities) depends on these choices. As a result, we address the problem of converting this definition into a more precise one where some fundamental properties ensuring social behaviour (such as action and reward dependency and anticipation on competitive/cooperative behaviours) are met as well as some other more instrumental properties (such as secernment, boundedness, symmetry, validity, reliability, efficiency), which are convenient to convert the definition into a practical test. From the definition and the formalised properties, we take a look at several representative multi-agent environments, tests and games to see whether they meet these properties. △ Less","27 August, 2014",https://arxiv.org/pdf/1408.6350
Using Learned Predictions as Feedback to Improve Control and Communication with an Artificial Limb: Preliminary Findings,Adam S. R. Parker;Ann L. Edwards;Patrick M. Pilarski,"Many people suffer from the loss of a limb. Learning to get by without an arm or hand can be very challenging, and existing prostheses do not yet fulfil the needs of individuals with amputations. One promising solution is to provide greater communication between a prosthesis and its user. Towards this end, we present a simple machine learning interface to supplement the control of a robotic limb with feedback to the user about what the limb will be experiencing in the near future. A real-time prediction learner was implemented to predict impact-related electrical load experienced by a robot limb; the learning system's predictions were then communicated to the device's user to aid in their interactions with a workspace. We tested this system with five able-bodied subjects. Each subject manipulated the robot arm while receiving different forms of vibrotactile feedback regarding the arm's contact with its workspace. Our trials showed that communicable predictions could be learned quickly during human control of the robot arm. Using these predictions as a basis for feedback led to a statistically significant improvement in task performance when compared to purely reactive feedback from the device. Our study therefore contributes initial evidence that prediction learning and machine intelligence can benefit not just control, but also feedback from an artificial limb. We expect that a greater level of acceptance and ownership can be achieved if the prosthesis itself takes an active role in transmitting learned knowledge about its state and its situation of use. △ Less","8 August, 2014",https://arxiv.org/pdf/1408.1913
Robust Feature Selection by Mutual Information Distributions,Marco Zaffalon;Marcus Hutter,"Mutual information is widely used in artificial intelligence, in a descriptive way, to measure the stochastic dependence of discrete random variables. In order to address questions such as the reliability of the empirical value, one must consider sample-to-population inferential approaches. This paper deals with the distribution of mutual information, as obtained in a Bayesian framework by a second-order Dirichlet prior distribution. The exact analytical expression for the mean and an analytical approximation of the variance are reported. Asymptotic approximations of the distribution are proposed. The results are applied to the problem of selecting features for incremental learning and classification of the naive Bayes classifier. A fast, newly defined method is shown to outperform the traditional approach based on empirical mutual information on a number of real data sets. Finally, a theoretical development is reported that allows one to efficiently extend the above methods to incomplete samples in an easy and effective way. △ Less","7 August, 2014",https://arxiv.org/pdf/1408.1487
Competitive performance analysis of two evolutionary algorithms for routing optimization in graded network,Kavitha Sooda;T. R. Gopalakrishnan Nair,"In this paper we compare the two intelligent route generation system and its performance capability in graded networks using Artificial Bee Colony (ABC) algorithm and Genetic Algorithm (GA). Both ABC and GA have found its importance in optimization technique for determining optimal path while routing operations in the network. The paper shows how ABC approach has been utilized for determining the optimal path based on bandwidth availability of the links and determines better quality paths over GA. Here the nodes participating in the routing are evaluated for their QoS metric. The nodes which satisfy the minimum threshold value of the metric are chosen and enabled to participate in routing. A quadrant is synthesized on the source as the centre and depending on which quadrant the destination node belongs to, a search for optimal path is performed. The simulation results show that ABC speeds up local minimum search convergence by around 60% as compared to GA with respect to traffic intensity, and opens the possibility for cognitive routing in future intelligent networks. △ Less","5 August, 2014",https://arxiv.org/pdf/1408.1087
Modular Belief Updates and Confusion about Measures of Certainty in Artificial Intelligence Research,Eric J. Horvitz;David Heckerman,"Over the last decade, there has been growing interest in the use or measures or change in belief for reasoning with uncertainty in artificial intelligence research. An important characteristic of several methodologies that reason with changes in belief or belief updates, is a property that we term modularity. We call updates that satisfy this property modular updates. Whereas probabilistic measures of belief update - which satisfy the modularity property were first discovered in the nineteenth century, knowledge and discussion of these quantities remains obscure in artificial intelligence research. We define modular updates and discuss their inappropriate use in two influential expert systems. △ Less","27 July, 2014",https://arxiv.org/pdf/1407.7281
A Novel Hybrid Crossover based Artificial Bee Colony Algorithm for Optimization Problem,Sandeep Kumar;Vivek Kumar Sharma;Rajani Kumari,Artificial bee colony (ABC) algorithm has proved its importance in solving a number of problems including engineering optimization problems. ABC algorithm is one of the most popular and youngest member of the family of population based nature inspired meta-heuristic swarm intelligence method. ABC has been proved its superiority over some other Nature Inspired Algorithms (NIA) when applied for both benchmark functions and real world problems. The performance of search process of ABC depends on a random value which tries to balance exploration and exploitation phase. In order to increase the performance it is required to balance the exploration of search space and exploitation of optimal solution of the ABC. This paper outlines a new hybrid of ABC algorithm with Genetic Algorithm. The proposed method integrates crossover operation from Genetic Algorithm (GA) with original ABC algorithm. The proposed method is named as Crossover based ABC (CbABC). The CbABC strengthens the exploitation phase of ABC as crossover enhances exploration of search space. The CbABC tested over four standard benchmark functions and a popular continuous optimization problem. △ Less,"21 July, 2014",https://arxiv.org/pdf/1407.5574
Context Aware Dynamic Traffic Signal Optimization,Kandarp Khandwala;Rudra Sharma;Snehal Rao,"Conventional urban traffic control systems have been based on historical traffic data. Later advancements made use of detectors, which enabled the gathering of real time traffic data, in order to reorganize and calibrate traffic signalization programs. Further evolvement provided the ability to forecast traffic conditions, in order to develop traffic signalization programs and strategies precomputed and applied at the most appropriate time frame for the optimal control of the current traffic conditions. We, propose the next generation of traffic control systems based on principles of Artificial Intelligence and Context Awareness. Most of the existing algorithms use average waiting time or length of the queue to assess an algorithms performance. However, a low average waiting time may come at the cost of delaying other vehicles indefinitely. In our algorithm, besides the vehicle queue, we use fairness also as an important performance metric to assess an algorithms performance. △ Less","19 July, 2014",https://arxiv.org/pdf/1407.5212
Flow for Meta Control,Vadim Bulitko,The psychological state of flow has been linked to optimizing human performance. A key condition of flow emergence is a match between the human abilities and complexity of the task. We propose a simple computational model of flow for Artificial Intelligence (AI) agents. The model factors the standard agent-environment state into a self-reflective set of the agent's abilities and a socially learned set of the environmental complexity. Maximizing the flow serves as a meta control for the agent. We show how to apply the meta-control policy to a broad class of AI control policies and illustrate our approach with a specific implementation. Results in a synthetic testbed are promising and open interesting directions for future work. △ Less,"17 July, 2014",https://arxiv.org/pdf/1407.4709
XML Matchers: approaches and challenges,Santa Agreste;Pasquale De Meo;Emilio Ferrara;Domenico Ursino,"Schema Matching, i.e. the process of discovering semantic correspondences between concepts adopted in different data source schemas, has been a key topic in Database and Artificial Intelligence research areas for many years. In the past, it was largely investigated especially for classical database models (e.g., E/R schemas, relational databases, etc.). However, in the latest years, the widespread adoption of XML in the most disparate application fields pushed a growing number of researchers to design XML-specific Schema Matching approaches, called XML Matchers, aiming at finding semantic matchings between concepts defined in DTDs and XSDs. XML Matchers do not just take well-known techniques originally designed for other data models and apply them on DTDs/XSDs, but they exploit specific XML features (e.g., the hierarchical structure of a DTD/XSD) to improve the performance of the Schema Matching process. The design of XML Matchers is currently a well-established research area. The main goal of this paper is to provide a detailed description and classification of XML Matchers. We first describe to what extent the specificities of DTDs/XSDs impact on the Schema Matching task. Then we introduce a template, called XML Matcher Template, that describes the main components of an XML Matcher, their role and behavior. We illustrate how each of these components has been implemented in some popular XML Matchers. We consider our XML Matcher Template as the baseline for objectively comparing approaches that, at first glance, might appear as unrelated. The introduction of this template can be useful in the design of future XML Matchers. Finally, we analyze commercial tools implementing XML Matchers and introduce two challenging issues strictly related to this topic, namely XML source clustering and uncertainty management in XML Matchers. △ Less","10 July, 2014",https://arxiv.org/pdf/1407.2845
Réseaux de radio cognitive : Allocation des ressources radio et accès dynamique au spectre,Badr Benmammar;Asma Amraoui,"In the first chapter of this report, we provide an overview on mobile and wireless networks, with special focus on the IEEE 802.22 norm, which is a norm dedicated to cognitive radio (CR). Chapter 2 goes into detail about CR and Chapter 3 is devoted to the presentation of the concept of agents and in particular the concept of multi-agent systems (MAS). Finally, Chapter 4 provides a state of the art on the use of artificial intelligence techniques, particularly MAS for radio resource allocation and dynamic spectrum access in the field of CR. △ Less","10 July, 2014",https://arxiv.org/pdf/1407.2705
Meteorological time series forecasting with pruned multi-layer perceptron and 2-stage Levenberg-Marquardt method,Cyril Voyant;Wani W. Tamas;Marie Laure Nivet;Gilles Notton;Christophe Paoli;Aurélia Balu;Marc Muselli,"A Multi-Layer Perceptron (MLP) defines a family of artificial neural networks often used in TS modeling and forecasting. Because of its ""black box"" aspect, many researchers refuse to use it. Moreover, the optimization (often based on the exhaustive approach where ""all"" configurations are tested) and learning phases of this artificial intelligence tool (often based on the Levenberg-Marquardt algorithm; LMA) are weaknesses of this approach (exhaustively and local minima). These two tasks must be repeated depending on the knowledge of each new problem studied, making the process, long, laborious and not systematically robust. In this paper a pruning process is proposed. This method allows, during the training phase, to carry out an inputs selecting method activating (or not) inter-nodes connections in order to verify if forecasting is improved. We propose to use iteratively the popular damped least-squares method to activate inputs and neurons. A first pass is applied to 10% of the learning sample to determine weights significantly different from 0 and delete other. Then a classical batch process based on LMA is used with the new MLP. The validation is done using 25 measured meteorological TS and cross-comparing the prediction results of the classical LMA and the 2-stage LMA. △ Less","8 July, 2014",https://arxiv.org/pdf/1407.2169
Parameterized Algorithmics for Computational Social Choice: Nine Research Challenges,Robert Bredereck;Jiehua Chen;Piotr Faliszewski;Jiong Guo;Rolf Niedermeier;Gerhard J. Woeginger,"Computational Social Choice is an interdisciplinary research area involving Economics, Political Science, and Social Science on the one side, and Mathematics and Computer Science (including Artificial Intelligence and Multiagent Systems) on the other side. Typical computational problems studied in this field include the vulnerability of voting procedures against attacks, or preference aggregation in multi-agent systems. Parameterized Algorithmics is a subfield of Theoretical Computer Science seeking to exploit meaningful problem-specific parameters in order to identify tractable special cases of in general computationally hard problems. In this paper, we propose nine of our favorite research challenges concerning the parameterized complexity of problems appearing in this context. △ Less","8 July, 2014",https://arxiv.org/pdf/1407.2143
Discovering New Sentiments from the Social Web,Juan Galan-Paez;Joaquín Borrego-Díaz,"A persistent challenge in Complex Systems (CS) research is the phenomenological reconstruction of systems from raw data. In order to face the problem, the use of sound features to reason on the system from data processing is a key step. In the specific case of complex societal systems, sentiment analysis allows to mirror (part of) the affective dimension. However it is not reasonable to think that individual sentiment categorization can encompass the new affective phenomena in digital social networks. The present papers addresses the problem of isolating sentiment concepts which emerge in social networks. In an analogy to Artificial Intelligent Singularity, we propose the study and analysis of these new complex sentiment structures and how they are similar to or diverge from classic conceptual structures associated to sentiment lexicons. The conjecture is that it is highly probable that hypercomplex sentiment structures -not explained with human categorizations- emerge from high dynamic social information networks. Roughly speaking, new sentiment can emerge from the new global nervous systems as it occurs in humans. △ Less","29 June, 2014",https://arxiv.org/pdf/1407.0374
Hands-on experiments on intelligent behavior for mobile robots,Erik Cuevas;Daniel Zaldivar;Marco Perez-;Marte Ramirez,"In recent years, Artificial Intelligence techniques have emerged as useful tools for solving various engineering problems that were not possible or convenient to handle by traditional methods. AI has directly influenced many areas of computer science and becomes an important part of the engineering curriculum. However, determining the important topics for a single semester AI course is a nontrivial task, given the lack of a general methodology. AI concepts commonly overlap with many other disciplines involving a wide range of subjects, including applied approaches to more formal mathematical issues. This paper presents the use of a simple robotic platform to assist the learning of basic AI concepts. The study is guided through some simple experiments using autonomous mobile robots. The central algorithm is the Learning Automata. Using LA, each robot action is applied to an environment to be evaluated by means of a fitness value. The response of the environment is used by the automata to select its next action. This procedure holds until the goal task is reached. The proposal addresses the AI study by offering in LA a unifying context to draw together several of the topics of AI and motivating the students to learn by building some hands on laboratory exercises. The presented material has been successfully tested as AI teaching aide in the University of Guadalajara robotics group as it motivates students and increases enrolment and retention while educating better computer engineers. △ Less","30 June, 2014",https://arxiv.org/pdf/1407.0051
Dispersion and Line Formation in Artificial Swarm Intelligence,Donghwa Jeong;Kiju Lee,"One of the major motifs in collective or swarm intelligence is that, even though individuals follow simple rules, the resulting global behavior can be complex and intelligent. In artificial swarm systems, such as swarm robots, the goal is to use systems that are as simple and cheap as possible, deploy many of them, and coordinate them to conduct complex tasks that each individual cannot accomplish. Shape formation in artificial intelligence systems is usually required for specific task-oriented performance, including 1) forming sensing grids, 2) exploring and mapping in space, underwater, or hazardous environments, and 3) forming a barricade for surveillance or protecting an area or a person. This paper presents a dynamic model of an artificial swarm system based on a virtual spring damper model and algorithms for dispersion without a leader and line formation with an interim leader using only the distance estimation among the neighbors. △ Less","30 June, 2014",https://arxiv.org/pdf/1407.0014
Multi Circle Detection on Images Using Artificial Bee Colony (ABC) Optimization,Erik Cuevas;Felipe Sencion-Echauri;Daniel Zaldivar;Marco Perez Cisneros,"Hough transform (HT) has been the most common method for circle detection, exhibiting robustness, but adversely demanding considerable computational effort and large memory requirements. Alternative approaches include heuristic methods that employ iterative optimization procedures for detecting multiple circles. Since only one circle can be marked at each optimization cycle, multiple executions must be enforced in order to achieve multi detection. This paper presents an algorithm for automatic detection of multiple circular shapes that considers the overall process as a multi-modal optimization problem. The approach is based on the artificial bee colony (ABC) algorithm, a swarm optimization algorithm inspired by the intelligent foraging behavior of honey bees. Unlike the original ABC algorithm, the proposed approach presents the addition of a memory for discarded solutions. Such memory allows holding important information regarding other local optima which might have emerged during the optimization process. The detector uses a combination of three non-collinear edge points as parameters to determine circle candidates. A matching function (nectar- amount) determines if such circle candidates (bee-food-sources) are actually present in the image. Guided by the values of such matching functions, the set of encoded candidate circles are evolved through the ABC algorithm so that the best candidate (global optimum) can be fitted into an actual circle within the edge only image. Then, an analysis of the incorporated memory is executed in order to identify potential local optima, i.e., other circles. △ Less","25 June, 2014",https://arxiv.org/pdf/1406.6560
Multi-objective Reinforcement Learning with Continuous Pareto Frontier Approximation Supplementary Material,Matteo Pirotta;Simone Parisi;Marcello Restelli,"This document contains supplementary material for the paper ""Multi-objective Reinforcement Learning with Continuous Pareto Frontier Approximation"", published at the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15). The paper is about learning a continuous approximation of the Pareto frontier in Multi-Objective Markov Decision Problems (MOMDPs). We propose a policy-based approach that exploits gradient information to generate solutions close to the Pareto ones. Differently from previous policy-gradient multi-objective algorithms, where n optimization routines are use to have n solutions, our approach performs a single gradient-ascent run that at each step generates an improved continuous approximation of the Pareto frontier. The idea is to exploit a gradient-based approach to optimize the parameters of a function that defines a manifold in the policy parameter space so that the corresponding image in the objective space gets as close as possible to the Pareto frontier. Besides deriving how to compute and estimate such gradient, we will also discuss the non-trivial issue of defining a metric to assess the quality of the candidate Pareto frontiers. Finally, the properties of the proposed approach are empirically evaluated on two interesting MOMDPs. △ Less","18 November, 2014",https://arxiv.org/pdf/1406.3497
Evolutionary Search in the Space of Rules for Creation of New Two-Player Board Games,Zahid Halim,"Games have always been a popular test bed for artificial intelligence techniques. Game developers are always in constant search for techniques that can automatically create computer games minimizing the developer's task. In this work we present an evolutionary strategy based solution towards the automatic generation of two player board games. To guide the evolutionary process towards games, which are entertaining, we propose a set of metrics. These metrics are based upon different theories of entertainment in computer games. This work also compares the entertainment value of the evolved games with the existing popular board based games. Further to verify the entertainment value of the evolved games with the entertainment value of the human user a human user survey is conducted. In addition to the user survey we check the learnability of the evolved games using an artificial neural network based controller. The proposed metrics and the evolutionary process can be employed for generating new and entertaining board games, provided an initial search space is given to the evolutionary algorithm. △ Less","1 June, 2014",https://arxiv.org/pdf/1406.0175
A Multi-threshold Segmentation Approach Based on Artificial Bee Colony Optimization,Erik Cuevas;Felipe Sencion;Daniel Zaldivar;Marco Perez;Humberto Sossa,"This paper explores the use of the Artificial Bee Colony (ABC) algorithm to compute threshold selection for image segmentation. ABC is a heuristic algorithm motivated by the intelligent behavior of honey-bees which has been successfully employed to solve complex optimization problems. In this approach, an image 1D histogram is approximated through a Gaussian mixture model whose parameters are calculated by the ABC algorithm. For the approximation scheme, each Gaussian function represents a pixel class and therefore a threshold. Unlike the Expectation Maximization (EM) algorithm, the ABC based method shows fast convergence and low sensitivity to initial conditions. Remarkably, it also improves complex time consuming computations commonly required by gradient-based methods. Experimental results demonstrate the algorithms ability to perform automatic multi threshold selection yet showing interesting advantages by comparison to other well known algorithms. △ Less","28 May, 2014",https://arxiv.org/pdf/1405.7229
A Comparison of Monte Carlo Tree Search and Mathematical Optimization for Large Scale Dynamic Resource Allocation,Dimitris Bertsimas;J. Daniel Griffith;Vishal Gupta;Mykel J. Kochenderfer;Velibor V. Mišić;Robert Moss,"Dynamic resource allocation (DRA) problems are an important class of dynamic stochastic optimization problems that arise in a variety of important real-world applications. DRA problems are notoriously difficult to solve to optimality since they frequently combine stochastic elements with intractably large state and action spaces. Although the artificial intelligence and operations research communities have independently proposed two successful frameworks for solving dynamic stochastic optimization problems---Monte Carlo tree search (MCTS) and mathematical optimization (MO), respectively---the relative merits of these two approaches are not well understood. In this paper, we adapt both MCTS and MO to a problem inspired by tactical wildfire and management and undertake an extensive computational study comparing the two methods on large scale instances in terms of both the state and the action spaces. We show that both methods are able to greatly improve on a baseline, problem-specific heuristic. On smaller instances, the MCTS and MO approaches perform comparably, but the MO approach outperforms MCTS as the size of the problem increases for a fixed computational budget. △ Less","21 May, 2014",https://arxiv.org/pdf/1405.5498
Projective simulation applied to the grid-world and the mountain-car problem,Alexey A. Melnikov;Adi Makmal;Hans J. Briegel,"We study the model of projective simulation (PS) which is a novel approach to artificial intelligence (AI). Recently it was shown that the PS agent performs well in a number of simple task environments, also when compared to standard models of reinforcement learning (RL). In this paper we study the performance of the PS agent further in more complicated scenarios. To that end we chose two well-studied benchmarking problems, namely the ""grid-world"" and the ""mountain-car"" problem, which challenge the model with large and continuous input space. We compare the performance of the PS agent model with those of existing models and show that the PS agent exhibits competitive performance also in such scenarios. △ Less","21 May, 2014",https://arxiv.org/pdf/1405.5459
Model revision inference for extensions of first order logic,Joachim Jansen,"I am Joachim Jansen and this is my research summary, part of my application to the Doctoral Consortium at ICLP'14. I am a PhD student in the Knowledge Representation and Reasoning (KRR) research group, a subgroup of the Declarative Languages and Artificial Intelligence (DTAI) group at the department of Computer Science at KU Leuven. I started my PhD in September 2012. My promotor is prof. dr. ir. Gerda Janssens and my co-promotor is prof. dr. Marc Denecker. I can be contacted at joachim.jansen@cs.kuleuven.be or at: Room 01.167 Celestijnenlaan 200A 3001 Heverlee Belgium An extended abstract / full version of a paper accepted to be presented at the Doctoral Consortium of the 30th International Conference on Logic Programming (ICLP 2014), July 19-22, Vienna, Austria △ Less","16 May, 2014",https://arxiv.org/pdf/1405.4206
Empirical Study of Artificial Fish Swarm Algorithm,Reza Azizi,"Artificial fish swarm algorithm (AFSA) is one of the swarm intelligence optimization algorithms that works based on population and stochastic search. In order to achieve acceptable result, there are many parameters needs to be adjusted in AFSA. Among these parameters, visual and step are very significant in view of the fact that artificial fish basically move based on these parameters. In standard AFSA, these two parameters remain constant until the algorithm termination. Large values of these parameters increase the capability of algorithm in global search, while small values improve the local search ability of the algorithm. In this paper, we empirically study the performance of the AFSA and different approaches to balance between local and global exploration have been tested based on the adaptive modification of visual and step during algorithm execution. The proposed approaches have been evaluated based on the four well-known benchmark functions. Experimental results show considerable positive impact on the performance of AFSA. △ Less","16 May, 2014",https://arxiv.org/pdf/1405.4138
A Novel Method for Developing Robotics via Artificial Intelligence and Internet of Things,Aadhityan A,"This paper describe about a new methodology for developing and improving the robotics field via artificial intelligence and internet of things. Now a day, we can say Artificial Intelligence take the world into robotics. Almost all industries use robots for lot of works. They are use co-operative robots to make different kind of works. But there was some problem to make robot for multi tasks. So there was a necessary new methodology to made multi tasking robots. It will be done only by artificial intelligence and internet of things. △ Less","12 May, 2014",https://arxiv.org/pdf/1405.3939
Structured Learning Modulo Theories,Stefano Teso;Roberto Sebastiani;Andrea Passerini,"Modelling problems containing a mixture of Boolean and numerical variables is a long-standing interest of Artificial Intelligence. However, performing inference and learning in hybrid domains is a particularly daunting task. The ability to model this kind of domains is crucial in ""learning to design"" tasks, that is, learning applications where the goal is to learn from examples how to perform automatic {\em de novo} design of novel objects. In this paper we present Structured Learning Modulo Theories, a max-margin approach for learning in hybrid domains based on Satisfiability Modulo Theories, which allows to combine Boolean reasoning and optimization over continuous linear arithmetical constraints. The main idea is to leverage a state-of-the-art generalized Satisfiability Modulo Theory solver for implementing the inference and separation oracles of Structured Output SVMs. We validate our method on artificial and real world scenarios. △ Less","18 December, 2014",https://arxiv.org/pdf/1405.1675
Learning in Repeated Games: Human Versus Machine,Fatimah Ishowo-Oloko;Jacob Crandall;Manuel Cebrian;Sherief Abdallah;Iyad Rahwan,"While Artificial Intelligence has successfully outperformed humans in complex combinatorial games (such as chess and checkers), humans have retained their supremacy in social interactions that require intuition and adaptation, such as cooperation and coordination games. Despite significant advances in learning algorithms, most algorithms adapt at times scales which are not relevant for interactions with humans, and therefore the advances in AI on this front have remained of a more theoretical nature. This has also hindered the experimental evaluation of how these algorithms perform against humans, as the length of experiments needed to evaluate them is beyond what humans are reasonably expected to endure (max 100 repetitions). This scenario is rapidly changing, as recent algorithms are able to converge to their functional regimes in shorter time-scales. Additionally, this shift opens up possibilities for experimental investigation: where do humans stand compared with these new algorithms? We evaluate humans experimentally against a representative element of these fast-converging algorithms. Our results indicate that the performance of at least one of these algorithms is comparable to, and even exceeds, the performance of people. △ Less","19 April, 2014",https://arxiv.org/pdf/1404.4985
Open Question Answering with Weakly Supervised Embedding Models,Antoine Bordes;Jason Weston;Nicolas Usunier,"Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data. △ Less","16 April, 2014",https://arxiv.org/pdf/1404.4326
Is it morally acceptable for a system to lie to persuade me?,Marco Guerini;Fabio Pianesi;Oliviero Stock,"Given the fast rise of increasingly autonomous artificial agents and robots, a key acceptability criterion will be the possible moral implications of their actions. In particular, intelligent persuasive systems (systems designed to influence humans via communication) constitute a highly sensitive topic because of their intrinsically social nature. Still, ethical studies in this area are rare and tend to focus on the output of the required action. Instead, this work focuses on the persuasive acts themselves (e.g. ""is it morally acceptable that a machine lies or appeals to the emotions of a person to persuade her, even if for a good end?""). Exploiting a behavioral approach, based on human assessment of moral dilemmas -- i.e. without any prior assumption of underlying ethical theories -- this paper reports on a set of experiments. These experiments address the type of persuader (human or machine), the strategies adopted (purely argumentative, appeal to positive emotions, appeal to negative emotions, lie) and the circumstances. Findings display no differences due to the agent, mild acceptability for persuasion and reveal that truth-conditional reasoning (i.e. argument validity) is a significant dimension affecting subjects' judgment. Some implications for the design of intelligent persuasive systems are discussed. △ Less","15 April, 2014",https://arxiv.org/pdf/1404.3959
An Overview of Hierarchical Task Network Planning,Ilche Georgievski;Marco Aiello,"Hierarchies are the most common structure used to understand the world better. In galaxies, for instance, multiple-star systems are organised in a hierarchical system. Then, governmental and company organisations are structured using a hierarchy, while the Internet, which is used on a daily basis, has a space of domain names arranged hierarchically. Since Artificial Intelligence (AI) planning portrays information about the world and reasons to solve some of world's problems, Hierarchical Task Network (HTN) planning has been introduced almost 40 years ago to represent and deal with hierarchies. Its requirement for rich domain knowledge to characterise the world enables HTN planning to be very useful, but also to perform well. However, the history of almost 40 years obfuscates the current understanding of HTN planning in terms of accomplishments, planning models, similarities and differences among hierarchical planners, and its current and objective image. On top of these issues, attention attracts the ability of hierarchical planning to truly cope with the requirements of applications from the real world. We propose a framework-based approach to remedy this situation. First, we provide a basis for defining different formal models of hierarchical planning, and define two models that comprise a large portion of HTN planners. Second, we provide a set of concepts that helps to interpret HTN planners from the aspect of their search space. Then, we analyse and compare the planners based on a variety of properties organised in five segments, namely domain authoring, expressiveness, competence, performance and applicability. Furthermore, we select Web service composition as a real-world and current application, and classify and compare the approaches that employ HTN planning to solve the problem of service composition. Finally, we conclude with our findings and present directions for future work. △ Less","28 March, 2014",https://arxiv.org/pdf/1403.7426
Evaluation of Image Segmentation and Filtering With ANN in the Papaya Leaf,Maicon A. Sartin;Alexandre C. R. da Silva,"Precision agriculture is area with lack of cheap technology. The refinement of the production system brings large advantages to the producer and the use of images makes the monitoring a more cheap methodology. Macronutrients monitoring can to determine the health and vulnerability of the plant in specific stages. In this paper is analyzed the method based on computational intelligence to work with image segmentation in the identification of symptoms of plant nutrient deficiency. Artificial neural networks are evaluated for image segmentation and filtering, several variations of parameters and insertion impulsive noise were evaluated too. Satisfactory results are achieved with artificial neural for segmentation same with high noise levels. △ Less","12 March, 2014",https://arxiv.org/pdf/1403.3057
"Turing: Then, Now and Still Key",Kieran Greer,"This paper looks at Turing's postulations about Artificial Intelligence in his paper 'Computing Machinery and Intelligence', published in 1950. It notes how accurate they were and how relevant they still are today. This paper notes the arguments and mechanisms that he suggested and tries to expand on them further. The paper however is mostly about describing the essential ingredients for building an intelligent model and the problems related with that. The discussion includes recent work by the author himself, who adds his own thoughts on the matter that come from a purely technical investigation into the problem. These are personal and quite speculative, but provide an interesting insight into the mechanisms that might be used for building an intelligent system. △ Less","11 March, 2014",https://arxiv.org/pdf/1403.2541
Application of Asynchronous Weak Commitment Search in Autonomous Quality of Service Provision in Cognitive Radio Networks,Shabnam Sodagari,"This article presents a distributed solution to autonomous quality of service provision in cognitive radio networks. Specifically, cognitive STDMA and CDMA communication networks are studied. Based on asynchronous weak commitment search the task of QoS provision is distributed among different network nodes. Simulation results verify this scheme converges very fast to optimal solution, which makes it suitable for practical real time systems. This application of artificial intelligence in wireless and mobile communications can be used in home automation and networking, and vehicular technology. The generalizations and extensions of this approach can be used in Long Term Evolution Self Organizing Networks (LTE-SONs). In addition, it can pave the way for decentralized and autonomous QoS provision in capillary networks that reach end nodes at Internet of Things, where central management is either unavailable or not efficient. △ Less","14 March, 2014",https://arxiv.org/pdf/1403.2077
Approximation Models of Combat in StarCraft 2,Ian Helmke;Daniel Kreymer;Karl Wiegand,"Real-time strategy (RTS) games make heavy use of artificial intelligence (AI), especially in the design of computerized opponents. Because of the computational complexity involved in managing all aspects of these games, many AI opponents are designed to optimize only a few areas of playing style. In games like StarCraft 2, a very popular and recently released RTS, most AI strategies revolve around economic and building efficiency: AI opponents try to gather and spend all resources as quickly and effectively as possible while ensuring that no units are idle. The aim of this work was to help address the need for AI combat strategies that are not computationally intensive. Our goal was to produce a computationally efficient model that is accurate at predicting the results of complex battles between diverse armies, including which army will win and how many units will remain. Our results suggest it may be possible to develop a relatively simple approximation model of combat that can accurately predict many battles that do not involve micromanagement. Future designs of AI opponents may be able to incorporate such an approximation model into their decision and planning systems to provide a challenge that is strategically balanced across all aspects of play. △ Less","6 March, 2014",https://arxiv.org/pdf/1403.1521
Enaction-Based Artificial Intelligence: Toward Coevolution with Humans in the Loop,Pierre De Loor;Kristen Manach;Jacques Tisseau,"This article deals with the links between the enaction paradigm and artificial intelligence. Enaction is considered a metaphor for artificial intelligence, as a number of the notions which it deals with are deemed incompatible with the phenomenal field of the virtual. After explaining this stance, we shall review previous works regarding this issue in terms of artifical life and robotics. We shall focus on the lack of recognition of co-evolution at the heart of these approaches. We propose to explicitly integrate the evolution of the environment into our approach in order to refine the ontogenesis of the artificial system, and to compare it with the enaction paradigm. The growing complexity of the ontogenetic mechanisms to be activated can therefore be compensated by an interactive guidance system emanating from the environment. This proposition does not however resolve that of the relevance of the meaning created by the machine (sense-making). Such reflections lead us to integrate human interaction into this environment in order to construct relevant meaning in terms of participative artificial intelligence. This raises a number of questions with regards to setting up an enactive interaction. The article concludes by exploring a number of issues, thereby enabling us to associate current approaches with the principles of morphogenesis, guidance, the phenomenology of interactions and the use of minimal enactive interfaces in setting up experiments which will deal with the problem of artificial intelligence in a variety of enaction-based ways. △ Less","26 February, 2014",https://arxiv.org/pdf/1402.6663
Evolutionary solving of the debts' clearing problem,Csaba Patcas;Attila Bartha,"The debts' clearing problem is about clearing all the debts in a group of n entities (persons, companies etc.) using a minimal number of money transaction operations. The problem is known to be NP-hard in the strong sense. As for many intractable problems, techniques from the field of artificial intelligence are useful in finding solutions close to optimum for large inputs. An evolutionary algorithm for solving the debts' clearing problem is proposed. △ Less","26 February, 2014",https://arxiv.org/pdf/1402.6556
LSSVM-ABC Algorithm for Stock Price prediction,Osman Hegazy;Omar S. Soliman;Mustafa Abdul Salam,"In this paper, Artificial Bee Colony (ABC) algorithm which inspired from the behavior of honey bees swarm is presented. ABC is a stochastic population-based evolutionary algorithm for problem solving. ABC algorithm, which is considered one of the most recently swarm intelligent techniques, is proposed to optimize least square support vector machine (LSSVM) to predict the daily stock prices. The proposed model is based on the study of stocks historical data, technical indicators and optimizing LSSVM with ABC algorithm. ABC selects best free parameters combination for LSSVM to avoid over-fitting and local minima problems and improve prediction accuracy. LSSVM optimized by Particle swarm optimization (PSO) algorithm, LSSVM, and ANN techniques are used for comparison with proposed model. Proposed model tested with twenty datasets representing different sectors in S&P 500 stock market. Results presented in this paper show that the proposed model has fast convergence speed, and it also achieves better accuracy than compared techniques in most cases. △ Less","25 February, 2014",https://arxiv.org/pdf/1402.6366
Extended Breadth-First Search Algorithm,Tamás Kádek;János Pánovics,"The task of artificial intelligence is to provide representation techniques for describing problems, as well as search algorithms that can be used to answer our questions. A widespread and elaborated model is state-space representation, which, however, has some shortcomings. Classical search algorithms are not applicable in practice when the state space contains even only a few tens of thousands of states. We can give remedy to this problem by defining some kind of heuristic knowledge. In case of classical state-space representation, heuristic must be defined so that it qualifies an arbitrary state based on its ""goodness,"" which is obviously not trivial. In our paper, we introduce an algorithm that gives us the ability to handle huge state spaces and to use a heuristic concept which is easier to embed into search algorithms. △ Less","21 February, 2014",https://arxiv.org/pdf/1402.5358
Inequity aversion and the evolution of cooperation,Asrar Ahmed;Kamalakar Karlapalem,"Evolution of cooperation is a widely studied problem in biology, social science, economics, and artificial intelligence. Most of the existing approaches that explain cooperation rely on some notion of direct or indirect reciprocity. These reciprocity based models assume agents recognize their partner and know their previous interactions, which requires advanced cognitive abilities. In this paper we are interested in developing a model that produces cooperation without requiring any explicit memory of previous game plays. Our model is based on the notion of, a concept introduced within behavioral economics, whereby individuals care about payoff equality in outcomes. Here we explore the effect of using income inequality to guide partner selection and interaction. We study our model by considering both the well-mixed and the spatially structured population and present the conditions under which cooperation becomes dominant. Our results support the hypothesis that inequity aversion promotes cooperative relationship among nonkin. △ Less","20 February, 2014",https://arxiv.org/pdf/1402.4946
Does the D.C. Response of Memristors Allow Robotic Short-Term Memory and a Possible Route to Artificial Time Perception?,Ella Gale;Ben de Lacy Costello;Andrew Adamatzky,"Time perception is essential for task switching, and in the mammalian brain appears alongside other processes. Memristors are electronic components used as synapses and as models for neurons. The d.c. response of memristors can be considered as a type of short-term memory. Interactions of the memristor d.c. response within networks of memristors leads to the emergence of oscillatory dynamics and intermittent spike trains, which are similar to neural dynamics. Based on this data, the structure of a memristor network control for a robot as it undergoes task switching is discussed and it is suggested that these emergent network dynamics could improve the performance of role switching and learning in an artificial intelligence and perhaps create artificial time perception. △ Less","17 February, 2014",https://arxiv.org/pdf/1402.4007
A Hybrid Modified Semantic Matching Algorithm Based on Instances Detection With Case Study on Renewable Energy,Ahmad Khader Haboush,"This Matching input keywords with historical or information domain is an important point in modern computations in order to find the best match information domain for specific input queries. Matching algorithms represents hot area of researches in computer science and artificial intelligence. In the area of text matching, it is more reliable to study semantics of the pattern and query in terms of semantic matching. This paper improves the semantic matching results between input queries and information ontology domain. The contributed algorithm is a hybrid technique that is based on matching extracted instances from booth, the queries and in information domain. The instances extraction algorithm that is presented in this paper are contributed which is based on mathematical and statistical analysis of objects with respect to each other and also with respect to marked objects. The instances that are instances from the queries and information domain are subjected to semantic matching to find the best match, match percentage, and to improve the decision making process. An application case was studied in this paper which is related to renewable energy, where the input queries represents the customer requirements input and the knowledge domain is renewable energy vendors profiles. The comparison was made with most known recent matching researches. △ Less","17 February, 2014",https://arxiv.org/pdf/1402.3937
Machine Learning of Phonologically Conditioned Noun Declensions For Tamil Morphological Generators,K. Rajan;Dr. V. Ramalingam;Dr. M. Ganesan,"This paper presents machine learning solutions to a practical problem of Natural Language Generation (NLG), particularly the word formation in agglutinative languages like Tamil, in a supervised manner. The morphological generator is an important component of Natural Language Processing in Artificial Intelligence. It generates word forms given a root and affixes. The morphophonemic changes like addition, deletion, alternation etc., occur when two or more morphemes or words joined together. The Sandhi rules should be explicitly specified in the rule based morphological analyzers and generators. In machine learning framework, these rules can be learned automatically by the system from the training samples and subsequently be applied for new inputs. In this paper we proposed the machine learning models which learn the morphophonemic rules for noun declensions from the given training data. These models are trained to learn sandhi rules using various learning algorithms and the performance of those algorithms are presented. From this we conclude that machine learning of morphological processing such as word form generation can be successfully learned in a supervised manner, without explicit description of rules. The performance of Decision trees and Bayesian machine learning algorithms on noun declensions are discussed. △ Less","14 February, 2014",https://arxiv.org/pdf/1402.3382
Intelligent User Interface in Fuzzy Environment,Ben Khayut;Lina Fabri;Maya Abukhana,"Human-Computer Interaction with the traditional User Interface is done using a specified in advance script dialog menu, mainly based on human intellect and unproductive use of navigation. This approach does not lead to making qualitative decision in control systems, where the situations and processes cannot be structured in advance. Any dynamic changes in the controlled business process (as example, in organizational unit of the information fuzzy control system) make it necessary to modify the script dialogue in User Interface. This circumstance leads to a redesign of the components of the User Interface and of the entire control system. In the Intelligent User Interface, where the dialog situations are unknown in advance, fuzzy structured and artificial intelligence is crucial, the redesign described above is impossible. To solve this and other problems, we propose the data, information and knowledge based technology of Smart/ Intelligent User Interface (IUI) design, which interacts with users and systems in natural and other languages, utilizing the principles of Situational Control and Fuzzy Logic theories, Artificial Intelligence, Linguistics, Knowledge Base technologies and others. The proposed technology of IUI design is defined by multi-agents of Situational Control and of data, information and knowledge, modelling of Fuzzy Logic Inference, Generalization, Representation and Explanation of knowledge, Planning and Decision-making, Dialog Control, Reasoning and Systems Thinking, Fuzzy Control of organizational unit in real-time, fuzzy conditions, heterogeneous domains, and multi-lingual communication under uncertainty and in Fuzzy Environment. △ Less","10 February, 2014",https://arxiv.org/pdf/1402.2149
In-Memory Database Systems - A Paradigm Shift,Mohit Kumar Gupta;Vishal Verma;Megha Singh Verma,"In today world, organizations like Google, Yahoo, Amazon, Facebook etc. are facing drastic increase in data. This leads to the problem of capturing, storing, managing and analyzing terabytes or petabytes of data, stored in multiple formats, from different internal and external sources. Moreover, new applications scenarios like weather forecasting, trading, artificial intelligence etc. need huge data processing in real time. These requirements exceed the processing capacity of traditional on-disk database management systems to manage this data and to give speedy real time results. Therefore, data management needs new solutions for coping with the challenges of data volumes and processing data in real-time. An in-memory database system (IMDS) is a latest breed of database management system which is becoming answer to above challenges with other supporting technologies. IMDS is capable to process massive data distinctly faster. This paper explores IMDS approach and its associated design issues and challenges. It also investigates some famous commercial and open-source IMDS solutions available in the market. △ Less","6 February, 2014",https://arxiv.org/pdf/1402.1258
Quantum Cybernetics and Complex Quantum Systems Science - A Quantum Connectionist Exploration,Carlos Pedro Gonçalves,"Quantum cybernetics and its connections to complex quantum systems science is addressed from the perspective of complex quantum computing systems. In this way, the notion of an autonomous quantum computing system is introduced in regards to quantum artificial intelligence, and applied to quantum artificial neural networks, considered as autonomous quantum computing systems, which leads to a quantum connectionist framework within quantum cybernetics for complex quantum computing systems. Several examples of quantum feedforward neural networks are addressed in regards to Boolean functions' computation, multilayer quantum computation dynamics, entanglement and quantum complementarity. The examples provide a framework for a reflection on the role of quantum artificial neural networks as a general framework for addressing complex quantum systems that perform network-based quantum computation, possible consequences are drawn regarding quantum technologies, as well as fundamental research in complex quantum systems science and quantum biology. △ Less","5 February, 2014",https://arxiv.org/pdf/1402.1141
AI Methods in Algorithmic Composition: A Comprehensive Survey,Jose David Fernandez;Francisco Vico,"Algorithmic composition is the partial or total automation of the process of music composition by using computers. Since the 1950s, different computational techniques related to Artificial Intelligence have been used for algorithmic composition, including grammatical representations, probabilistic methods, neural networks, symbolic rule-based systems, constraint programming and evolutionary algorithms. This survey aims to be a comprehensive account of research on algorithmic composition, presenting a thorough view of the field for researchers in Artificial Intelligence. △ Less","3 February, 2014",https://arxiv.org/pdf/1402.0585
Riffled Independence for Efficient Inference with Partial Rankings,Jonathan Huang;Ashish Kapoor;Carlos Guestrin,"Distributions over rankings are used to model data in a multitude of real world settings such as preference analysis and political elections. Modeling such distributions presents several computational challenges, however, due to the factorial size of the set of rankings over an item set. Some of these challenges are quite familiar to the artificial intelligence community, such as how to compactly represent a distribution over a combinatorially large space, and how to efficiently perform probabilistic inference with these representations. With respect to ranking, however, there is the additional challenge of what we refer to as human task complexity users are rarely willing to provide a full ranking over a long list of candidates, instead often preferring to provide partial ranking information. Simultaneously addressing all of these challenges i.e., designing a compactly representable model which is amenable to efficient inference and can be learned using partial ranking data is a difficult task, but is necessary if we would like to scale to problems with nontrivial size. In this paper, we show that the recently proposed riffled independence assumptions cleanly and efficiently address each of the above challenges. In particular, we establish a tight mathematical connection between the concepts of riffled independence and of partial rankings. This correspondence not only allows us to then develop efficient and exact algorithms for performing inference tasks using riffled independence based represen- tations with partial rankings, but somewhat surprisingly, also shows that efficient inference is not possible for riffle independent models (in a certain sense) with observations which do not take the form of partial rankings. Finally, using our inference algorithm, we introduce the first method for learning riffled independence based models from partially ranked data. △ Less","22 January, 2014",https://arxiv.org/pdf/1401.6421
Online Speedup Learning for Optimal Planning,Carmel Domshlak;Erez Karpas;Shaul Markovitch,"Domain-independent planning is one of the foundational areas in the field of Artificial Intelligence. A description of a planning task consists of an initial world state, a goal, and a set of actions for modifying the world state. The objective is to find a sequence of actions, that is, a plan, that transforms the initial world state into a goal state. In optimal planning, we are interested in finding not just a plan, but one of the cheapest plans. A prominent approach to optimal planning these days is heuristic state-space search, guided by admissible heuristic functions. Numerous admissible heuristics have been developed, each with its own strengths and weaknesses, and it is well known that there is no single ""best heuristic for optimal planning in general. Thus, which heuristic to choose for a given planning task is a difficult question. This difficulty can be avoided by combining several heuristics, but that requires computing numerous heuristic estimates at each state, and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high. We present a novel method that reduces the cost of combining admissible heuristics for optimal planning, while maintaining its benefits. Using an idealized search space model, we formulate a decision rule for choosing the best heuristic to compute at each state. We then present an active online learning approach for learning a classifier with that decision rule as the target concept, and employ the learned classifier to decide which heuristic to compute at each state. We evaluate this technique empirically, and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum. △ Less","22 January, 2014",https://arxiv.org/pdf/1401.5861
A Market-Inspired Approach for Intersection Management in Urban Road Traffic Networks,Matteo Vasirani;Sascha Ossowski,"Traffic congestion in urban road networks is a costly problem that affects all major cities in developed countries. To tackle this problem, it is possible (i) to act on the supply side, increasing the number of roads or lanes in a network, (ii) to reduce the demand, restricting the access to urban areas at specific hours or to specific vehicles, or (iii) to improve the efficiency of the existing network, by means of a widespread use of so-called Intelligent Transportation Systems (ITS). In line with the recent advances in smart transportation management infrastructures, ITS has turned out to be a promising field of application for artificial intelligence techniques. In particular, multiagent systems seem to be the ideal candidates for the design and implementation of ITS. In fact, drivers can be naturally modelled as autonomous agents that interact with the transportation management infrastructure, thereby generating a large-scale, open, agent-based system. To regulate such a system and maintain a smooth and efficient flow of traffic, decentralised mechanisms for the management of the transportation infrastructure are needed. In this article we propose a distributed, market-inspired, mechanism for the management of a future urban road network, where intelligent autonomous vehicles, operated by software agents on behalf of their human owners, interact with the infrastructure in order to travel safely and efficiently through the road network. Building on the reservation-based intersection control model proposed by Dresner and Stone, we consider two different scenarios: one with a single intersection and one with a network of intersections. In the former, we analyse the performance of a novel policy based on combinatorial auctions for the allocation of reservations. In the latter, we analyse the impact that a traffic assignment strategy inspired by competitive markets has on the drivers route choices. Finally we propose an adaptive management mechanism that integrates the auction-based traffic control policy with the competitive traffic assignment strategy. △ Less","22 January, 2014",https://arxiv.org/pdf/1401.5851
Causal Discovery in a Binary Exclusive-or Skew Acyclic Model: BExSAM,Takanori Inazumi;Takashi Washio;Shohei Shimizu;Joe Suzuki;Akihiro Yamamoto;Yoshinobu Kawahara,"Discovering causal relations among observed variables in a given data set is a major objective in studies of statistics and artificial intelligence. Recently, some techniques to discover a unique causal model have been explored based on non-Gaussianity of the observed data distribution. However, most of these are limited to continuous data. In this paper, we present a novel causal model for binary data and propose an efficient new approach to deriving the unique causal model governing a given binary data set under skew distributions of external binary noises. Experimental evaluation shows excellent performance for both artificial and real world data sets. △ Less","22 January, 2014",https://arxiv.org/pdf/1401.5636
Real Time Strategy Language,Roy Hayes;Peter Beling;William Scherer,"Real Time Strategy (RTS) games provide complex domain to test the latest artificial intelligence (AI) research. In much of the literature, AI systems have been limited to playing one game. Although, this specialization has resulted in stronger AI gaming systems it does not address the key concerns of AI researcher. AI researchers seek the development of AI agents that can autonomously interpret learn, and apply new knowledge. To achieve human level performance, current AI systems rely on game specific knowledge of an expert. The paper presents the full RTS language in hopes of shifting the current research focus to the development of general RTS agents. General RTS agents are AI gaming systems that can play any RTS games, defined in the RTS language. This prevents game specific knowledge from being hard coded into the system, thereby facilitating research that addresses the fundamental concerns of artificial intelligence. △ Less","21 January, 2014",https://arxiv.org/pdf/1401.5424
Combining Evaluation Metrics via the Unanimous Improvement Ratio and its Application to Clustering Tasks,Enrique Amigó;Julio Gonzalo;Javier Artiles;Felisa Verdejo,"Many Artificial Intelligence tasks cannot be evaluated with a single quality criterion and some sort of weighted combination is needed to provide system rankings. A problem of weighted combination measures is that slight changes in the relative weights may produce substantial changes in the system rankings. This paper introduces the Unanimous Improvement Ratio (UIR), a measure that complements standard metric combination criteria (such as van Rijsbergen's F-measure) and indicates how robust the measured differences are to changes in the relative weights of the individual metrics. UIR is meant to elucidate whether a perceived difference between two systems is an artifact of how individual metrics are weighted. Besides discussing the theoretical foundations of UIR, this paper presents empirical results that confirm the validity and usefulness of the metric for the Text Clustering problem, where there is a tradeoff between precision and recall based metrics and results are particularly sensitive to the weighting scheme used to combine them. Remarkably, our experiments show that UIR can be used as a predictor of how well differences between systems measured on a given test bed will also hold in a different test bed. △ Less","18 January, 2014",https://arxiv.org/pdf/1401.4590
The Complexity of Integer Bound Propagation,Lucas Bordeaux;George Katsirelos;Nina Narodytska;Moshe Y. Vardi,"Bound propagation is an important Artificial Intelligence technique used in Constraint Programming tools to deal with numerical constraints. It is typically embedded within a search procedure (""branch and prune"") and used at every node of the search tree to narrow down the search space, so it is critical that it be fast. The procedure invokes constraint propagators until a common fixpoint is reached, but the known algorithms for this have a pseudo-polynomial worst-case time complexity: they are fast indeed when the variables have a small numerical range, but they have the well-known problem of being prohibitively slow when these ranges are large. An important question is therefore whether strongly-polynomial algorithms exist that compute the common bound consistent fixpoint of a set of constraints. This paper answers this question. In particular we show that this fixpoint computation is in fact NP-complete, even when restricted to binary linear constraints. △ Less","16 January, 2014",https://arxiv.org/pdf/1401.3887
On-line Planning and Scheduling: An Application to Controlling Modular Printers,Wheeler Ruml;Minh Binh Do;Rong Zhou;Markus P. J. Fromherz,"We present a case study of artificial intelligence techniques applied to the control of production printing equipment. Like many other real-world applications, this complex domain requires high-speed autonomous decision-making and robust continual operation. To our knowledge, this work represents the first successful industrial application of embedded domain-independent temporal planning. Our system handles execution failures and multi-objective preferences. At its heart is an on-line algorithm that combines techniques from state-space planning and partial-order scheduling. We suggest that this general architecture may prove useful in other applications as more intelligent systems operate in continual, on-line settings. Our system has been used to drive several commercial prototypes and has enabled a new product architecture for our industrial partner. When compared with state-of-the-art off-line planners, our system is hundreds of times faster and often finds better plans. Our experience demonstrates that domain-independent AI planning based on heuristic search can flexibly handle time, resources, replanning, and multiple objectives in a high-speed practical application without requiring hand-coded control knowledge. △ Less","16 January, 2014",https://arxiv.org/pdf/1401.3875
Case-Based Subgoaling in Real-Time Heuristic Search for Video Game Pathfinding,Vadim Bulitko;Yngvi Björnsson;Ramon Lawrence,"Real-time heuristic search algorithms satisfy a constant bound on the amount of planning per action, independent of problem size. As a result, they scale up well as problems become larger. This property would make them well suited for video games where Artificial Intelligence controlled agents must react quickly to user commands and to other agents actions. On the downside, real-time search algorithms employ learning methods that frequently lead to poor solution quality and cause the agent to appear irrational by re-visiting the same problem states repeatedly. The situation changed recently with a new algorithm, D LRTA*, which attempted to eliminate learning by automatically selecting subgoals. D LRTA* is well poised for video games, except it has a complex and memory-demanding pre-computation phase during which it builds a database of subgoals. In this paper, we propose a simpler and more memory-efficient way of pre-computing subgoals thereby eliminating the main obstacle to applying state-of-the-art real-time search methods in video games. The new algorithm solves a number of randomly chosen problems off-line, compresses the solutions into a series of subgoals and stores them in a database. When presented with a novel problem on-line, it queries the database for the most similar previously solved case and uses its subgoals to solve the problem. In the domain of pathfinding on four large video game maps, the new algorithm delivers solutions eight times better while using 57 times less memory and requiring 14% less pre-computation time. △ Less","16 January, 2014",https://arxiv.org/pdf/1401.3857
Prime Implicates and Prime Implicants: From Propositional to Modal Logic,Meghyn Bienvenu,"Prime implicates and prime implicants have proven relevant to a number of areas of artificial intelligence, most notably abductive reasoning and knowledge compilation. The purpose of this paper is to examine how these notions might be appropriately extended from propositional logic to the modal logic K. We begin the paper by considering a number of potential definitions of clauses and terms for K. The different definitions are evaluated with respect to a set of syntactic, semantic, and complexity-theoretic properties characteristic of the propositional definition. We then compare the definitions with respect to the properties of the notions of prime implicates and prime implicants that they induce. While there is no definition that perfectly generalizes the propositional notions, we show that there does exist one definition which satisfies many of the desirable properties of the propositional case. In the second half of the paper, we consider the computational properties of the selected definition. To this end, we provide sound and complete algorithms for generating and recognizing prime implicates, and we show the prime implicate recognition task to be PSPACE-complete. We also prove upper and lower bounds on the size and number of prime implicates. While the paper focuses on the logic K, all of our results hold equally well for multi-modal K and for concept expressions in the description logic ALC. △ Less","15 January, 2014",https://arxiv.org/pdf/1401.3475
An ANN Based Call Handoff Management Scheme for Mobile Cellular Network,P. P. Bhattacharya;Ananya Sarkar;IndranilSarkar;Subhajit Chatterjee,"Handoff decisions are usually signal strength based because of simplicity and effectiveness. Apart from the conventional techniques, such as threshold and hysteresis based schemes, recently many artificial intelligent techniques such as Fuzzy Logic, Artificial Neural Network (ANN) etc. are also used for taking handoff decision. In this paper, an Artificial Neural Network based handoff algorithm is proposed and its performance is studied. We have used ANN here for taking fast and accurate handoff decision. In our proposed handoff algorithm, Backpropagation Neural Network model is used.The advantages of Back propagation method are its simplicity and reasonable speed. The algorithm is designed, tested and found to give optimum results. △ Less","10 January, 2014",https://arxiv.org/pdf/1401.2230
Emotional Responses in Artificial Agent-Based Systems: Reflexivity and Adaptation in Artificial Life,Carlos Pedro Gonçalves,"The current work addresses a virtual environment with self-replicating agents whose decisions are based on a form of ""somatic computation"" (soma - body) in which basic emotional responses, taken in parallelism to actual living organisms, are introduced as a way to provide the agents with greater reflexive abilities. The work provides a contribution to the field of Artificial Intelligence (AI) and Artificial Life (ALife) in connection to a neurobiology-based cognitive framework for artificial systems and virtual environments' simulations. The performance of the agents capable of emotional responses is compared with that of self-replicating automata, and the implications of research on emotions and AI, in connection to both virtual agents as well as robots, is addressed regarding possible future directions and applications. △ Less","9 January, 2014",https://arxiv.org/pdf/1401.2121
Proposta di nuovi strumenti per comprendere come funziona la cognizione (Novel tools to understand how cognition works),Devis Pantano,"I think that the main reason why we do not understand the general principles of how knowledge works (and probably also the reason why we have not yet designed and built efficient machines capable of artificial intelligence), is not the excessive complexity of cognitive phenomena, but the lack of the conceptual and methodological tools to properly address the problem. It is like trying to build up Physics without the concept of number, or to understand the origin of species without including the mechanism of natural selection. In this paper I propose some new conceptual and methodological tools, which seem to offer a real opportunity to understand the logic of cognitive processes. I propose a new method to properly treat the concepts of structure and schema, and to perform on them operations of structural analysis. These operations allow to move straightforwardly from concrete to more abstract representations. With these tools I will suggest a definition for the concept of rule, of regularity and of emergent phenomena. From the analysis of some important aspects of the rules, I suggest to distinguish them in operational and associative rules. I propose that associative rules assume a dominant role in cognition. I also propose a definition for the concept of problem. At the end I will briefly illustrate a possible general model for cognitive systems. △ Less","18 April, 2014",https://arxiv.org/pdf/1401.1533
Research on the mobile robots intelligent path planning based on ant colony algorithm application in manufacturing logistics,Yue Guo;Xuelian Shen;Zhanfeng Zhu,"With the development of robotics and artificial intelligence field unceasingly thorough, path planning as an important field of robot calculation has been widespread concern. This paper analyzes the current development of robot and path planning algorithm and focuses on the advantages and disadvantages of the traditional intelligent path planning as well as the path planning. The problem of mobile robot path planning is studied by using ant colony algorithm, and it also provides some solving methods. △ Less","7 January, 2014",https://arxiv.org/pdf/1401.0889
Fighting Sample Degeneracy and Impoverishment in Particle Filters: A Review of Intelligent Approaches,Tiancheng Li;Shudong Sun;Tariq P. Sattar;Juan M. Corchado,"During the last two decades there has been a growing interest in Particle Filtering (PF). However, PF suffers from two long-standing problems that are referred to as sample degeneracy and impoverishment. We are investigating methods that are particularly efficient at Particle Distribution Optimization (PDO) to fight sample degeneracy and impoverishment, with an emphasis on intelligence choices. These methods benefit from such methods as Markov Chain Monte Carlo methods, Mean-shift algorithms, artificial intelligence algorithms (e.g., Particle Swarm Optimization, Genetic Algorithm and Ant Colony Optimization), machine learning approaches (e.g., clustering, splitting and merging) and their hybrids, forming a coherent standpoint to enhance the particle filter. The working mechanism, interrelationship, pros and cons of these approaches are provided. In addition, Approaches that are effective for dealing with high-dimensionality are reviewed. While improving the filter performance in terms of accuracy, robustness and convergence, it is noted that advanced techniques employed in PF often causes additional computational requirement that will in turn sacrifice improvement obtained in real life filtering. This fact, hidden in pure simulations, deserves the attention of the users and designers of new filters. △ Less","8 January, 2014",https://arxiv.org/pdf/1308.2443
Affect Control Processes: Intelligent Affective Interaction using a Partially Observable Markov Decision Process,Jesse Hoey;Tobias Schroeder;Areej Alhothali,"This paper describes a novel method for building affectively intelligent human-interactive agents. The method is based on a key sociological insight that has been developed and extensively verified over the last twenty years, but has yet to make an impact in artificial intelligence. The insight is that resource bounded humans will, by default, act to maintain affective consistency. Humans have culturally shared fundamental affective sentiments about identities, behaviours, and objects, and they act so that the transient affective sentiments created during interactions confirm the fundamental sentiments. Humans seek and create situations that confirm or are consistent with, and avoid and supress situations that disconfirm or are inconsistent with, their culturally shared affective sentiments. This ""affect control principle"" has been shown to be a powerful predictor of human behaviour. In this paper, we present a probabilistic and decision-theoretic generalisation of this principle, and we demonstrate how it can be leveraged to build affectively intelligent artificial agents. The new model, called BayesAct, can maintain multiple hypotheses about sentiments simultaneously as a probability distribution, and can make use of an explicit utility function to make value-directed action choices. This allows the model to generate affectively intelligent interactions with people by learning about their identity, predicting their behaviours using the affect control principle, and taking actions that are simultaneously goal-directed and affect-sensitive. We demonstrate this generalisation with a set of simulations. We then show how our model can be used as an emotional ""plug-in"" for artificially intelligent systems that interact with humans in two different settings: an exam practice assistant (tutor) and an assistive device for persons with a cognitive disability. △ Less","3 April, 2014",https://arxiv.org/pdf/1306.5279
Projective simulation for classical learning agents: a comprehensive investigation,Julian Mautner;Adi Makmal;Daniel Manzano;Markus Tiersch;Hans J. Briegel,"We study the model of projective simulation (PS), a novel approach to artificial intelligence based on stochastic processing of episodic memory which was recently introduced [H.J. Briegel and G. De las Cuevas. Sci. Rep. 2, 400, (2012)]. Here we provide a detailed analysis of the model and examine its performance, including its achievable efficiency, its learning times and the way both properties scale with the problems' dimension. In addition, we situate the PS agent in different learning scenarios, and study its learning abilities. A variety of new scenarios are being considered, thereby demonstrating the model's flexibility. Furthermore, to put the PS scheme in context, we compare its performance with those of Q-learning and learning classifier systems, two popular models in the field of reinforcement learning. It is shown that PS is a competitive artificial intelligence model of unique properties and strengths. △ Less","1 December, 2014",https://arxiv.org/pdf/1305.1578
The tractability of CSP classes defined by forbidden patterns,David A. Cohen;Martin C. Cooper;Páidí Creed;András Z. Salamon,"The constraint satisfaction problem (CSP) is a general problem central to computer science and artificial intelligence. Although the CSP is NP-hard in general, considerable effort has been spent on identifying tractable subclasses. The main two approaches consider structural properties (restrictions on the hypergraph of constraint scopes) and relational properties (restrictions on the language of constraint relations). Recently, some authors have considered hybrid properties that restrict the constraint hypergraph and the relations simultaneously. Our key contribution is the novel concept of a CSP pattern and classes of problems defined by forbidden patterns (which can be viewed as forbidding generic subproblems). We describe the theoretical framework which can be used to reason about classes of problems defined by forbidden patterns. We show that this framework generalises relational properties and allows us to capture known hybrid tractable classes. Although we are not close to obtaining a dichotomy concerning the tractability of general forbidden patterns, we are able to make some progress in a special case: classes of problems that arise when we can only forbid binary negative patterns (generic subproblems in which only inconsistent tuples are specified). In this case we are able to characterise very large classes of tractable and NP-hard forbidden patterns. This leaves the complexity of just one case unresolved and we conjecture that this last case is tractable. △ Less","8 July, 2014",https://arxiv.org/pdf/1103.1542
